{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/2019-03-25_180320.png","path":"images/2019-03-25_180320.png","modified":1,"renderable":0},{"_id":"source/images/container-layers.jpg","path":"images/container-layers.jpg","modified":1,"renderable":0},{"_id":"source/images/docker_versions.png","path":"images/docker_versions.png","modified":1,"renderable":0},{"_id":"source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":0},{"_id":"source/images/hostnetwork.jpg","path":"images/hostnetwork.jpg","modified":1,"renderable":0},{"_id":"source/images/kube-proxy-mode iptables .png","path":"images/kube-proxy-mode iptables .png","modified":1,"renderable":0},{"_id":"source/images/metallb.jpg","path":"images/metallb.jpg","modified":1,"renderable":0},{"_id":"source/images/node.png","path":"images/node.png","modified":1,"renderable":0},{"_id":"source/images/nodeport.jpg","path":"images/nodeport.jpg","modified":1,"renderable":0},{"_id":"source/images/sharing-layers.jpg","path":"images/sharing-layers.jpg","modified":1,"renderable":0},{"_id":"source/images/swarmcluster.png","path":"images/swarmcluster.png","modified":1,"renderable":0},{"_id":"source/images/user_edge.jpg","path":"images/user_edge.jpg","modified":1,"renderable":0},{"_id":"source/images/2018-03-27_115251.png","path":"images/2018-03-27_115251.png","modified":1,"renderable":0},{"_id":"source/images/2018061310290292.jpg","path":"images/2018061310290292.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.png","path":"images/avatar.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"source/images/service_nodeport.jpg","path":"images/service_nodeport.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1553168509298},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1553168509298},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1553168509298},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1553168509298},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1553168509298},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1553168509298},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1553168509298},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1553168509298},{"_id":"themes/next/README.en.md","hash":"32d6cdfec1447f54aae1d7f1365ce6733dfcec8f","modified":1553168509298},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1553168509299},{"_id":"themes/next/_config.yml","hash":"9c6bed25aa6ca6a25b69c82eaaaa07de024d541f","modified":1553248133953},{"_id":"themes/next/bower.json","hash":"7d7938f9da896fe710aa0e9120140e528bf058df","modified":1553168509299},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1553168509299},{"_id":"themes/next/package.json","hash":"193dad6f59a588908fac082cc46fe067dac1b84d","modified":1553168509302},{"_id":"source/_posts/2019-03-21-docker-network-overlay.md","hash":"346ca36c8a1c9997842fa341267bd890c9c2bb0c","modified":1553171146633},{"_id":"source/_posts/2019-03-21-docker-storage.md","hash":"b2ebbc7a94cdfae5e0742068cf965b9c1e07fbc7","modified":1553170768918},{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found.md","hash":"232f08a06fc42a1294a2717a50f6ca163ba0893d","modified":1553170380218},{"_id":"source/_posts/2019-03-21-pull-docker-images-failed.md","hash":"cb3753d027e783ed9d9407378f2789dd1f45bb4d","modified":1553168509289},{"_id":"source/_posts/2019-03-21-python-mulit-thread.md","hash":"39f7012a9a9ad5647a25fc252b1c97583628f514","modified":1553168509289},{"_id":"source/_posts/2019-03-25-algorithm-two-order-list-merge.md","hash":"11c41468e06e2753788acf767961e09a37063a7c","modified":1553502873291},{"_id":"source/_posts/2019-03-25-docker-network-bridge.md","hash":"f3ecda19ba989562572c90810742a8eeb7336586","modified":1553492706757},{"_id":"source/_posts/2019-03-25-grpc-introduction.md","hash":"41ebd2f1a00e98e9dead0b343d4946167440b29a","modified":1553508289228},{"_id":"source/_posts/2019-03-25-install-docker-yum.md","hash":"78a5bf98f7c4237527b11aafa78b57a568786dd4","modified":1553492222708},{"_id":"source/_posts/2019-03-25-nginx-ingress-controller-introduct.md","hash":"66661c5b12fa45e77a561b637e3ec8d685927417","modified":1553503041935},{"_id":"source/_posts/2019-03-25-oracle-sql-second-version-note.md","hash":"ba06bf418fd9f579eb571bb2c7b1d89755cb7486","modified":1553505673093},{"_id":"source/_posts/2019-03-25-oracle-sql-seconds-notes-sec-2-sql-exec.md","hash":"853d0f96bc4253845092b2587802448ea3769802","modified":1553493605626},{"_id":"source/_posts/2019-03-25-private-registry-docker.md","hash":"af7c6d9cdb57069e2531cd47f462f6774380fefb","modified":1553493039000},{"_id":"source/about/index.md","hash":"eb6ffa20e19dbcff21f70669a732c18d1228990e","modified":1553168509289},{"_id":"source/archives/index.md","hash":"67a4aab57d1119d6efc0fb93cac2a54410c10497","modified":1553168509289},{"_id":"source/categories/index.md","hash":"42e2a5053a5afe11bb23e35b98b873cf9bbe74d9","modified":1553168509289},{"_id":"source/images/2019-03-25_180320.png","hash":"a80c974fc0071094aeb8ff013cbf3f18e224ac36","modified":1553508346318},{"_id":"source/images/container-layers.jpg","hash":"c6354991c7892a38207dddf9f07b4328d3dbeed3","modified":1553502583851},{"_id":"source/images/docker_versions.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553502584120},{"_id":"source/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553171567836},{"_id":"source/images/hostnetwork.jpg","hash":"b0478a0fd5086c6a1452920252dca60069b73962","modified":1553502584995},{"_id":"source/images/kube-proxy-mode iptables .png","hash":"d91b3164dff6e387721fedf99cf3b3edb7050a1a","modified":1553502588291},{"_id":"source/images/metallb.jpg","hash":"1f9f9e9f8685321d9329716b2c11ebcf188e1d9e","modified":1553502589902},{"_id":"source/images/node.png","hash":"c1399721d686508989b821d65ccca33eea7c489e","modified":1553502590309},{"_id":"source/images/nodeport.jpg","hash":"9f9383454db303f5e60d23ba32c89ddb05f87d93","modified":1553502590711},{"_id":"source/images/sharing-layers.jpg","hash":"82b3e992947958d7935aeb52753c9e6a2f07e171","modified":1553502593130},{"_id":"source/images/swarmcluster.png","hash":"e8bfdf7b46713fff7c63fdda89bc0f4a754c70fb","modified":1553502593402},{"_id":"source/images/user_edge.jpg","hash":"309d632e807ba54ec13cad7e6c122eaa07956f49","modified":1553502593940},{"_id":"source/tags/index.md","hash":"682c04efc90349264811e4b400e19eb9f46aa67a","modified":1553168509289},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1553168509299},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1553168509299},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1553168509299},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1553168509299},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1553168509299},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1553168509299},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1553168509299},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1553168509299},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1553168509299},{"_id":"themes/next/languages/ru.yml","hash":"1549a7c2fe23caa7cbedcd0aa2b77c46e57caf27","modified":1553168509299},{"_id":"themes/next/languages/zh-Hans.yml","hash":"e85ea999bac9ed7f9b9482b9d6f7c6b6eb5ec737","modified":1553218375034},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1553168509299},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1553168509299},{"_id":"themes/next/layout/_layout.swig","hash":"06b1eab2e00273e0b94bd32dc682bd92c1e0a747","modified":1553168509299},{"_id":"themes/next/layout/archive.swig","hash":"383f64deab105724fd5512371963bd9e9aafbffd","modified":1553168509301},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1553168509301},{"_id":"themes/next/layout/index.swig","hash":"03e8a2cda03bad42ac0cb827025eb81f95d496a2","modified":1553168509301},{"_id":"themes/next/layout/page.swig","hash":"37c874cd720acf0eda8d26e063278f2b6ae8d3a6","modified":1553168509302},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1553483072403},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1553168509302},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1553168509302},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1553168509302},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1553168509302},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1553168509322},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1553168509322},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1553168509322},{"_id":"source/images/2018-03-27_115251.png","hash":"691c7fa5be387e11f7ab8faea59ea06124090272","modified":1553502581366},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509306},{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found/example.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553170044266},{"_id":"source/images/2018061310290292.jpg","hash":"eda3d80ff692b0b59edf7d10d4ef46ae7332308f","modified":1553502583310},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1553168509299},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1553168509299},{"_id":"themes/next/layout/_macro/google_adsense.swig","hash":"03601ea39f4933e21b57214e5c9a6fce8aebeb25","modified":1553484268966},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1553168509299},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"53d4f83b2b7fb4387dfc9fe81519abd56fbce4ae","modified":1553168509299},{"_id":"themes/next/layout/_macro/post.swig","hash":"84f3b7da78c4e4fdcf429a0c52eecac352c9b67c","modified":1553484227925},{"_id":"themes/next/layout/_macro/reward.swig","hash":"5d5f70deb6074cb4dd0438463e14ccf89213c282","modified":1553168509300},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"faa7886ccf986890cd776f4e9d70cb89fe9fda5f","modified":1553168509300},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1553168509300},{"_id":"themes/next/layout/_partials/comments.swig","hash":"ce7094ee05878161e7568a6dfae5b56ff3fbd6e1","modified":1553168509300},{"_id":"themes/next/layout/_partials/footer.swig","hash":"2c1756b65b383dfc1d90206bb7ef2a1adcd5dc95","modified":1553218883280},{"_id":"themes/next/layout/_partials/head.swig","hash":"1f14d3f494b2dbbcee802fd6f6d1abd5b7e2304c","modified":1553168509300},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1553168509300},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1553168509300},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1553168509300},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1553168509300},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1553168509300},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1553168509300},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1553168509300},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1553168509301},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1553168509301},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1553168509301},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1553168509301},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1553168509301},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1553168509301},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1553168509302},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1553168509302},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1553168509302},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1553168509302},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1553168509302},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1553168509302},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1553168509302},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1553168509302},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1553168509302},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1553168509306},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1553168509306},{"_id":"themes/next/source/images/avatar.png","hash":"e696f046e8385f0b71c71aaca7f61141b5893510","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1553168509306},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1553168509306},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1553168509306},{"_id":"themes/next/source/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553168509306},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553168509306},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553168509306},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1553168509306},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1553168509306},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1553168509306},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1553168509306},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509300},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509306},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1553168509300},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1553168509300},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1553168509300},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1553168509300},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"ee63aa2e49507b884a2d56778479cf01c723d751","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1553168509301},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1553168509301},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"eaedfaf06dae94ba77a8f4893e2e434bf8859bac","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"49b5210fa62d6cbc6a98f57d89d5067a06ab3561","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cfee25d790e4f9b7d57f0dc7e2ea9c1649f08f11","modified":1553168509306},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d477196c5699c8261b08e993a77ef67054d86166","modified":1553168509306},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1553168509306},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1553168509307},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1553168509307},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1553168509307},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1553168509307},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1553168509307},{"_id":"themes/next/source/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1553168509307},{"_id":"themes/next/source/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1553168509307},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1553168509307},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1553168509307},{"_id":"themes/next/source/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1553168509307},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1553168509308},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1553168509311},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1553168509312},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1553168509312},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1553168509317},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1553168509317},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1553168509317},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1553168509317},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1553168509320},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1553168509320},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1553168509321},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1553168509321},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1553168509321},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1553168509316},{"_id":"source/images/service_nodeport.jpg","hash":"15d79cd10d5e82d1ca2011bea7e92193af3fbcbe","modified":1553502592591},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1553168509301},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"d026c8489f66ab6c12ad04bd37f1d5b6f2f3f0d1","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1553168509304},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"2915df7152ea095a6290ef69157fd67669e0e793","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"86b6fd7f1b1be3ae98f8af6b23a6b1299c670ce9","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1553168509305},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1553168509305},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"bc8c388553bbcf95897459a466ba35bffd5ec5f0","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1553168509305},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1553168509308},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1553168509312},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1553168509312},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1553168509320},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1553168509320},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1553168509308},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1553168509315},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1553168509316},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1553168509321},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"ed88c8b51d0517759c777e71a6bfbe2907bcd994","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ee554b1031ef0070a5916477939021800e3c9d27","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-wordcount.styl","hash":"4fda5d38c6c8d910e3bf5c74a48a8d4a3f3dc73d","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"51eca243220cf57133a4becae9b78514bcfdc723","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"65a64d5662637b66e2f039a5f58217afe7a6e800","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"57d2c8a060f5e4e1a0aef9aae11a0016cf7ac5ba","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"45df0cf4c97b47e05573bcd41028ee50f3fdf432","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"aeff0e6e23725e8baea27c890ccbbf466024f767","modified":1553168509304},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1553168509305},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1553168509308},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1553168509311},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1553168509313},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1553168509314},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1553168509315},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1553168509307},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1553168509310},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1553168509320},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1553168509315},{"_id":"public/atom.xml","hash":"c6b5d1285038756fcb7f79e27c3fe96eee9c7cfc","modified":1553508370000},{"_id":"public/about/index.html","hash":"6bfc5760f80e5cc27d3e08897f099d98448daca8","modified":1553508370039},{"_id":"public/categories/index.html","hash":"e281e1212baa9ec5b2cba765bcd8abb589de53cf","modified":1553508370039},{"_id":"public/tags/index.html","hash":"7d39ca0ec59ad6024bd686eb116bc73fe72a4a98","modified":1553508370039},{"_id":"public/archives/2016/index.html","hash":"1b0354ade0f1e925bd8c015e8a2a4c8e343e57dc","modified":1553508370039},{"_id":"public/archives/2016/12/index.html","hash":"fd09869281503b7d38f9be8ab014c95274394784","modified":1553508370039},{"_id":"public/archives/2017/index.html","hash":"b02e21710fac51505e00e85c69084819accde75f","modified":1553508370039},{"_id":"public/archives/2017/08/index.html","hash":"dc78baff3ae65f9c1c0596b97cf57a99055f983d","modified":1553508370039},{"_id":"public/archives/2018/index.html","hash":"53385005a7954e932c179d667a6e9ede4bffbe6b","modified":1553508370039},{"_id":"public/archives/2018/03/index.html","hash":"c9897e2d16585211b0fe0d78b692e897992ccd83","modified":1553508370040},{"_id":"public/archives/2018/09/index.html","hash":"91bc196056b5dd7d47c51ba2d43f1469c2b8f890","modified":1553508370040},{"_id":"public/archives/2019/01/index.html","hash":"4a57af7e013c786b0e9161a944c52ebb8288e226","modified":1553508370040},{"_id":"public/categories/常见算法/index.html","hash":"0cb3ca3c61188de966df07471dd7352bea210391","modified":1553508370040},{"_id":"public/categories/gRPC/index.html","hash":"27632f84603d4054801234531dc19c995ce7fabb","modified":1553508370040},{"_id":"public/categories/Oracle/index.html","hash":"7bd17e8a688d6733205f01c13157003d5e69304b","modified":1553508370040},{"_id":"public/categories/运维/kubernetes/index.html","hash":"e3a4749e432e7cd9b3ca9a5168458ee361e19327","modified":1553508370040},{"_id":"public/tags/jenkins/index.html","hash":"fb108f287f5bf38863e7197d21088771e936f47b","modified":1553508370040},{"_id":"public/tags/Python/index.html","hash":"8fa3df3c147c402f11832205fd179c75e3831f84","modified":1553508370040},{"_id":"public/tags/thread/index.html","hash":"46e85e90c05bb13169e077251eb071d7f6c3103e","modified":1553508370040},{"_id":"public/tags/算法/index.html","hash":"cd20ac6a87efed3c88fee3b328715f6c862a9ddc","modified":1553508370040},{"_id":"public/tags/gRPC/index.html","hash":"0d4e915bc98c32d05810f834262fefe7261249bf","modified":1553508370040},{"_id":"public/tags/Oracle/index.html","hash":"dc80baf1b16d2ebe821856e195e6c91d1f339264","modified":1553508370040},{"_id":"public/tags/storage/index.html","hash":"3a9ba69b82377364ce91612d080afedfd57fe955","modified":1553508370040},{"_id":"public/tags/kubernetes/index.html","hash":"d9f9f52bcc442400f82d23cba00a18c98d8b3d98","modified":1553508370040},{"_id":"public/archives/index.html","hash":"0358012113a3878f364f2fb127b45f51448571c9","modified":1553508370040},{"_id":"public/2019/03/26/grpc-introduction/index.html","hash":"0c485223556a98231e0399e04f86cecbc4459921","modified":1553508370040},{"_id":"public/2019/03/25/algorithm-two-order-list-merge/index.html","hash":"bf8bfb60c9faf687bdae81a4d0a2884f0d70ffe5","modified":1553508370040},{"_id":"public/2019/03/25/install-docker-yum/index.html","hash":"045fadd6d71bbdb290406a39f4527a775202b9b3","modified":1553508370040},{"_id":"public/2019/03/25/docker-network-bridge/index.html","hash":"3dba6b34364d3c36b6a6a7027441e80945d2a25b","modified":1553508370040},{"_id":"public/2019/03/22/docker-network-overlay/index.html","hash":"5041aa40604e377b8c2f63ada9b2ac488d938c1f","modified":1553508370040},{"_id":"public/2019/03/21/python-mulit-thread/index.html","hash":"ddd433262102d8b2838af7b263fbec429f98dcfe","modified":1553508370041},{"_id":"public/2019/03/21/pull-docker-images-failed/index.html","hash":"beb77b8750d4643c136021c9d718a5e603319601","modified":1553508370041},{"_id":"public/2019/03/21/docker-storage/index.html","hash":"fdf87c9a9887b60b1b3a0c1855e2c98ab19a942b","modified":1553508370041},{"_id":"public/2019/01/26/nginx-ingress-controller-introduct/index.html","hash":"bf89cc0d3b592e12ec1d87b2535b1488b896c7c3","modified":1553508370041},{"_id":"public/2018/09/13/private-registry-docker/index.html","hash":"f859164116ba5ef86a3015bd881e9665c910da05","modified":1553508370041},{"_id":"public/2018/03/22/jenkins-docker-command-not-found/index.html","hash":"de775f71a3e42bfc5543584ac6a73b74b7545701","modified":1553508370041},{"_id":"public/2017/08/17/oracle-sql-seconds-notes-sec-2-sql-exec/index.html","hash":"ae096443d45aa1902a6b86f835d1d70a063e1c46","modified":1553508370041},{"_id":"public/2016/12/05/oracle-sql-second-version-note/index.html","hash":"565fda54976f05fbff66cd01369391f3c9fa767b","modified":1553508370041},{"_id":"public/archives/page/2/index.html","hash":"d3b83750172c55dffafc09f756f9c8484149b79f","modified":1553508370041},{"_id":"public/archives/2019/index.html","hash":"a9360d2d0a5aaf78f569d32b23ca8704fc00f4e9","modified":1553508370041},{"_id":"public/archives/2019/03/index.html","hash":"56c21ddc2ed9f2d2b6a8830378c6ffd5555badce","modified":1553508370041},{"_id":"public/categories/运维/index.html","hash":"b1c70543b6fd1786884822bf7f797d3cab616e5d","modified":1553508370041},{"_id":"public/categories/运维/docker/index.html","hash":"0ed31587fd337cb9800c15420f8d476841527313","modified":1553508370041},{"_id":"public/index.html","hash":"28fc0bbff2e69b17aefd8b264eaa8c5111c8135c","modified":1553508370041},{"_id":"public/page/2/index.html","hash":"3a95e05040fe863e55657bc5eef66d22e6297fe5","modified":1553508370041},{"_id":"public/tags/docker/index.html","hash":"e66be148d674e4ce24e9418febe1566615357fad","modified":1553508370041},{"_id":"public/images/docker_versions.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553508370041},{"_id":"public/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553508370041},{"_id":"public/images/2019-03-25_180320.png","hash":"a80c974fc0071094aeb8ff013cbf3f18e224ac36","modified":1553508370059},{"_id":"public/images/container-layers.jpg","hash":"c6354991c7892a38207dddf9f07b4328d3dbeed3","modified":1553508370059},{"_id":"public/images/hostnetwork.jpg","hash":"b0478a0fd5086c6a1452920252dca60069b73962","modified":1553508370059},{"_id":"public/images/kube-proxy-mode iptables .png","hash":"d91b3164dff6e387721fedf99cf3b3edb7050a1a","modified":1553508370059},{"_id":"public/images/metallb.jpg","hash":"1f9f9e9f8685321d9329716b2c11ebcf188e1d9e","modified":1553508370059},{"_id":"public/images/node.png","hash":"c1399721d686508989b821d65ccca33eea7c489e","modified":1553508370059},{"_id":"public/images/nodeport.jpg","hash":"9f9383454db303f5e60d23ba32c89ddb05f87d93","modified":1553508370059},{"_id":"public/images/sharing-layers.jpg","hash":"82b3e992947958d7935aeb52753c9e6a2f07e171","modified":1553508370059},{"_id":"public/images/swarmcluster.png","hash":"e8bfdf7b46713fff7c63fdda89bc0f4a754c70fb","modified":1553508370059},{"_id":"public/images/user_edge.jpg","hash":"309d632e807ba54ec13cad7e6c122eaa07956f49","modified":1553508370059},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1553508370059},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1553508370059},{"_id":"public/images/avatar.png","hash":"e696f046e8385f0b71c71aaca7f61141b5893510","modified":1553508370060},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1553508370060},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1553508370060},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1553508370060},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1553508370060},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1553508370060},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1553508370060},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1553508370060},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553508370060},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553508370060},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1553508370060},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1553508370060},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1553508370060},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1553508370060},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1553508370060},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1553508370060},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1553508370060},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1553508370060},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1553508370060},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1553508370060},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1553508370060},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1553508370060},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1553508370060},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1553508370060},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1553508370060},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1553508370060},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1553508370061},{"_id":"public/2018/03/22/jenkins-docker-command-not-found/example.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553508370061},{"_id":"public/images/2018-03-27_115251.png","hash":"691c7fa5be387e11f7ab8faea59ea06124090272","modified":1553508370617},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1553508370620},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1553508370622},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1553508370639},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1553508370639},{"_id":"public/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1553508370640},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1553508370640},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1553508370640},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1553508370640},{"_id":"public/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1553508370640},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1553508370640},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1553508370640},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1553508370640},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1553508370640},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1553508370640},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1553508370640},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1553508370640},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1553508370640},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1553508370640},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1553508370640},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1553508370640},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1553508370640},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1553508370640},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1553508370640},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1553508370640},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1553508370641},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1553508370641},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1553508370641},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1553508370641},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1553508370641},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1553508370641},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1553508370641},{"_id":"public/css/main.css","hash":"171a3f8b5613015d8821e7d08637662a18032bb8","modified":1553508370641},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1553508370641},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1553508370641},{"_id":"public/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1553508370643},{"_id":"public/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1553508370644},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1553508370644},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1553508370644},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1553508370644},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1553508370644},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1553508370644},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1553508370644},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1553508370644},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1553508370651},{"_id":"public/images/2018061310290292.jpg","hash":"eda3d80ff692b0b59edf7d10d4ef46ae7332308f","modified":1553508370651},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1553508370654},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1553508370656},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1553508370656},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1553508370659},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1553508370659},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1553508370659},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1553508370659},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1553508370659},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1553508370666},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1553508370667},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1553508370674},{"_id":"public/images/service_nodeport.jpg","hash":"15d79cd10d5e82d1ca2011bea7e92193af3fbcbe","modified":1553508370674},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1553508370678},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1553508370684},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1553508370684},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1553508370700},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1553508370703},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1553508370710},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1553508370713}],"Category":[{"name":"运维","_id":"cjto6rqkr0004hqxunbffcjgv"},{"name":"常见算法","_id":"cjto6rqle000fhqxup4x5rdrs"},{"name":"docker","parent":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqli000lhqxuwzld3nbc"},{"name":"gRPC","_id":"cjto6rqlk000qhqxuj0bh420y"},{"name":"Oracle","_id":"cjto6rqlp0013hqxug51q5hdp"},{"name":"kubernetes","parent":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqtd001shqxumd5pk0om"}],"Data":[],"Page":[{"title":"about","date":"2019-03-21T15:51:19.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-03-21 15:51:19\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjto6rqko0001hqxu1sr7yfc0","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"archives","date":"2019-03-21T15:50:07.000Z","type":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-03-21 15:50:07\ntype: \"archives\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"archives/index.html","comments":1,"layout":"page","_id":"cjto6rqkq0003hqxugbbhmxpj","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-03-21T15:51:42.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-03-21 15:51:42\ntype: \"categories\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjto6rqku0007hqxurjf0s3x0","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-03-21T15:49:53.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-03-21 15:49:53\ntype: \"tags\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjto6rqkx0009hqxun731a0g4","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Docker中启动jenkins容器，并在jenkins中使用docker 命令，解决docker command not found","date":"2018-03-21T20:04:07.000Z","_content":"\n\n首先，制作支持docker的jenkins镜像，基础镜像是`jenkins:2.60.3`\n参考[Running Docker in Jenkins (in Docker)](https://container-solutions.com/running-docker-in-jenkins-in-docker/)\n\n编辑Dockerfile，内容如下：\n```\nFROM jenkins:2.60.3\n\nUSER root\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n\nRUN apt-get update       && apt-get install -y sudo       && apt-get install -y libltdl7       && rm -rf /var/lib/apt/lists/*\nRUN echo \"jenkins ALL=NOPASSWD: ALL\" >> /etc/sudoers\n\nUSER jenkins\nCOPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt\n\n```\n\n\n\n出现在执行docker命令时报：`docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory`错误[解决办法，参考](https://www.cnblogs.com/leolztang/p/6934694.html)\n加入如下代码后，问题解决：\n```\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n```\n预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。\n```\n\nscm-api:latest\ngit-client:latest\ngit:latest\ngreenballs:latest\n\n```\n启动jenkins容器，执行如下命令，启动jenkins容器\n\n```\ndocker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6\n```\n注意挂载`-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker`，才可以共享宿主机的docker资源\n指定工作目录：`-v $PWD:/var/jenkins_home`，将当前目录作为jenkins的工作目录。\n此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。\n首先，我们新建一个pipeline构建计划，Jenkinsfile内容：\n\n```\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'docker images'\n            }\n        }\n    }\n}\n```\n，执行立即构建，当执行pipeline中的`docker images`命令时，报错：\n```\n+ docker images\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied\n```\n这是jenkinsfile中的命令在访问宿主机的`unix:///var/run/docker.sock`守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加`sudo `，便成功执行：\n\n```\n[test_pipeline] Running shell script\n+ sudo docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB\njenkins             v2.6                bb042102b598        3 hours ago         705MB\njenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB\nbusybox             latest              22c2dd5ee85d        3 days ago          1.16MB\n```\n","source":"_posts/2019-03-21-jenkins-docker-command-not-found.md","raw":"---\ntitle: Docker中启动jenkins容器，并在jenkins中使用docker 命令，解决docker command not found\ndate: 2018-03-21 20:04:07\ntags:\n  - docker\n  - jenkins\ncategories:\n  - 运维\n  - docker\n---\n\n\n首先，制作支持docker的jenkins镜像，基础镜像是`jenkins:2.60.3`\n参考[Running Docker in Jenkins (in Docker)](https://container-solutions.com/running-docker-in-jenkins-in-docker/)\n\n编辑Dockerfile，内容如下：\n```\nFROM jenkins:2.60.3\n\nUSER root\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n\nRUN apt-get update       && apt-get install -y sudo       && apt-get install -y libltdl7       && rm -rf /var/lib/apt/lists/*\nRUN echo \"jenkins ALL=NOPASSWD: ALL\" >> /etc/sudoers\n\nUSER jenkins\nCOPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt\n\n```\n\n\n\n出现在执行docker命令时报：`docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory`错误[解决办法，参考](https://www.cnblogs.com/leolztang/p/6934694.html)\n加入如下代码后，问题解决：\n```\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n```\n预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。\n```\n\nscm-api:latest\ngit-client:latest\ngit:latest\ngreenballs:latest\n\n```\n启动jenkins容器，执行如下命令，启动jenkins容器\n\n```\ndocker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6\n```\n注意挂载`-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker`，才可以共享宿主机的docker资源\n指定工作目录：`-v $PWD:/var/jenkins_home`，将当前目录作为jenkins的工作目录。\n此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。\n首先，我们新建一个pipeline构建计划，Jenkinsfile内容：\n\n```\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'docker images'\n            }\n        }\n    }\n}\n```\n，执行立即构建，当执行pipeline中的`docker images`命令时，报错：\n```\n+ docker images\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied\n```\n这是jenkinsfile中的命令在访问宿主机的`unix:///var/run/docker.sock`守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加`sudo `，便成功执行：\n\n```\n[test_pipeline] Running shell script\n+ sudo docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB\njenkins             v2.6                bb042102b598        3 hours ago         705MB\njenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB\nbusybox             latest              22c2dd5ee85d        3 days ago          1.16MB\n```\n","slug":"jenkins-docker-command-not-found","published":1,"updated":"2019-03-21T12:13:00.218Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqkj0000hqxucsmeexuw","content":"<p>首先，制作支持docker的jenkins镜像，基础镜像是<code>jenkins:2.60.3</code><br>参考<a href=\"https://container-solutions.com/running-docker-in-jenkins-in-docker/\" target=\"_blank\" rel=\"noopener\">Running Docker in Jenkins (in Docker)</a></p>\n<p>编辑Dockerfile，内容如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM jenkins:2.60.3</span><br><span class=\"line\"></span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">RUN apt-get update       &amp;&amp; apt-get install -y sudo       &amp;&amp; apt-get install -y libltdl7       &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">RUN echo &quot;jenkins ALL=NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</span><br><span class=\"line\"></span><br><span class=\"line\">USER jenkins</span><br><span class=\"line\">COPY plugins.txt /usr/share/jenkins/plugins.txt</span><br><span class=\"line\">RUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt</span><br></pre></td></tr></table></figure></p>\n<p>出现在执行docker命令时报：<code>docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory</code>错误<a href=\"https://www.cnblogs.com/leolztang/p/6934694.html\" target=\"_blank\" rel=\"noopener\">解决办法，参考</a><br>加入如下代码后，问题解决：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scm-api:latest</span><br><span class=\"line\">git-client:latest</span><br><span class=\"line\">git:latest</span><br><span class=\"line\">greenballs:latest</span><br></pre></td></tr></table></figure></p>\n<p>启动jenkins容器，执行如下命令，启动jenkins容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6</span><br></pre></td></tr></table></figure>\n<p>注意挂载<code>-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker</code>，才可以共享宿主机的docker资源<br>指定工作目录：<code>-v $PWD:/var/jenkins_home</code>，将当前目录作为jenkins的工作目录。<br>此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。<br>首先，我们新建一个pipeline构建计划，Jenkinsfile内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent any</span><br><span class=\"line\">    stages &#123;</span><br><span class=\"line\">        stage(&apos;Test&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                sh &apos;docker images&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>，执行立即构建，当执行pipeline中的<code>docker images</code>命令时，报错：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ docker images</span><br><span class=\"line\">Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></p>\n<p>这是jenkinsfile中的命令在访问宿主机的<code>unix:///var/run/docker.sock</code>守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加<code>sudo</code>，便成功执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[test_pipeline] Running shell script</span><br><span class=\"line\">+ sudo docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">jenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB</span><br><span class=\"line\">jenkins             v2.6                bb042102b598        3 hours ago         705MB</span><br><span class=\"line\">jenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB</span><br><span class=\"line\">busybox             latest              22c2dd5ee85d        3 days ago          1.16MB</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>首先，制作支持docker的jenkins镜像，基础镜像是<code>jenkins:2.60.3</code><br>参考<a href=\"https://container-solutions.com/running-docker-in-jenkins-in-docker/\" target=\"_blank\" rel=\"noopener\">Running Docker in Jenkins (in Docker)</a></p>\n<p>编辑Dockerfile，内容如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM jenkins:2.60.3</span><br><span class=\"line\"></span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">RUN apt-get update       &amp;&amp; apt-get install -y sudo       &amp;&amp; apt-get install -y libltdl7       &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">RUN echo &quot;jenkins ALL=NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</span><br><span class=\"line\"></span><br><span class=\"line\">USER jenkins</span><br><span class=\"line\">COPY plugins.txt /usr/share/jenkins/plugins.txt</span><br><span class=\"line\">RUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt</span><br></pre></td></tr></table></figure></p>\n<p>出现在执行docker命令时报：<code>docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory</code>错误<a href=\"https://www.cnblogs.com/leolztang/p/6934694.html\" target=\"_blank\" rel=\"noopener\">解决办法，参考</a><br>加入如下代码后，问题解决：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scm-api:latest</span><br><span class=\"line\">git-client:latest</span><br><span class=\"line\">git:latest</span><br><span class=\"line\">greenballs:latest</span><br></pre></td></tr></table></figure></p>\n<p>启动jenkins容器，执行如下命令，启动jenkins容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6</span><br></pre></td></tr></table></figure>\n<p>注意挂载<code>-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker</code>，才可以共享宿主机的docker资源<br>指定工作目录：<code>-v $PWD:/var/jenkins_home</code>，将当前目录作为jenkins的工作目录。<br>此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。<br>首先，我们新建一个pipeline构建计划，Jenkinsfile内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent any</span><br><span class=\"line\">    stages &#123;</span><br><span class=\"line\">        stage(&apos;Test&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                sh &apos;docker images&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>，执行立即构建，当执行pipeline中的<code>docker images</code>命令时，报错：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ docker images</span><br><span class=\"line\">Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></p>\n<p>这是jenkinsfile中的命令在访问宿主机的<code>unix:///var/run/docker.sock</code>守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加<code>sudo</code>，便成功执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[test_pipeline] Running shell script</span><br><span class=\"line\">+ sudo docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">jenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB</span><br><span class=\"line\">jenkins             v2.6                bb042102b598        3 hours ago         705MB</span><br><span class=\"line\">jenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB</span><br><span class=\"line\">busybox             latest              22c2dd5ee85d        3 days ago          1.16MB</span><br></pre></td></tr></table></figure>\n"},{"title":"gcr.io和quay.io拉取镜像失败","date":"2019-03-21T11:17:18.000Z","_content":"\nk8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中`spec.containers.image`包含：\n```\nquay.io/coreos/example_\ngcr.io/google_containers/example_\n```\n也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com\n- 例如\n    **下拉镜像**：`quay.io/coreos/flannel:v0.10.0-s390x`\n    如果拉取较慢，可以改为：`quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x`\n    \n    **下拉镜像**：`gcr.io/google_containers/kube-proxy`\n    可以改为： `registry.aliyuncs.com/google_containers/kube-proxy`\n\n\n\n","source":"_posts/2019-03-21-pull-docker-images-failed.md","raw":"---\ntitle: gcr.io和quay.io拉取镜像失败\ndate: 2019-03-21 11:17:18\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\nk8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中`spec.containers.image`包含：\n```\nquay.io/coreos/example_\ngcr.io/google_containers/example_\n```\n也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com\n- 例如\n    **下拉镜像**：`quay.io/coreos/flannel:v0.10.0-s390x`\n    如果拉取较慢，可以改为：`quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x`\n    \n    **下拉镜像**：`gcr.io/google_containers/kube-proxy`\n    可以改为： `registry.aliyuncs.com/google_containers/kube-proxy`\n\n\n\n","slug":"pull-docker-images-failed","published":1,"updated":"2019-03-21T11:41:49.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqko0002hqxuomxpid3y","content":"<p>k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中<code>spec.containers.image</code>包含：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quay.io/coreos/example_</span><br><span class=\"line\">gcr.io/google_containers/example_</span><br></pre></td></tr></table></figure></p>\n<p>也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com</p>\n<ul>\n<li><p>例如<br>  <strong>下拉镜像</strong>：<code>quay.io/coreos/flannel:v0.10.0-s390x</code><br>  如果拉取较慢，可以改为：<code>quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x</code></p>\n<p>  <strong>下拉镜像</strong>：<code>gcr.io/google_containers/kube-proxy</code><br>  可以改为： <code>registry.aliyuncs.com/google_containers/kube-proxy</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中<code>spec.containers.image</code>包含：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quay.io/coreos/example_</span><br><span class=\"line\">gcr.io/google_containers/example_</span><br></pre></td></tr></table></figure></p>\n<p>也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com</p>\n<ul>\n<li><p>例如<br>  <strong>下拉镜像</strong>：<code>quay.io/coreos/flannel:v0.10.0-s390x</code><br>  如果拉取较慢，可以改为：<code>quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x</code></p>\n<p>  <strong>下拉镜像</strong>：<code>gcr.io/google_containers/kube-proxy</code><br>  可以改为： <code>registry.aliyuncs.com/google_containers/kube-proxy</code></p>\n</li>\n</ul>\n"},{"title":"python 多线程锁机制介绍","date":"2019-03-21T15:56:07.000Z","_content":"\n### Lock\n- 说明：\n\n对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。\n\n- 使用：\n\n```\nimport threading\n_lock = threading.lock() # 定义锁 _local\n\n_lock.accquire()  # 获取锁\n# TODO do something\ndo_somthing(share_var)   # 操作共享资源\n_lock.release()  #释放锁\n\n```\n\n- 缺点：\n  \n  死锁\n\n  当有多个共享资源（比如：`R_A`, `R_B`），多个线程（比如：`T_A`, `T_B`），每个线程都需要操作共享资源。假如线程 `T_A` 已经获取了共享资源 `R_A`，`T_B` 获取了共享资源 `R_B` ， 而线程 `T_A` 等待 `T_B` 释放共享资源 `R_B` 。 同时，线程 `T_B` 等待 `T_A` 释放共享资源 `R_A` ，此时就陷入死锁状态。\n\n\n### RLock\n\n- 说明：\n\n  RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 `Lock` 有是四个特点：\n  1. 谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 `Lock` 锁，可以被另外一个线程所释放。\n  2. 同一线程可以多次获取到该锁，即可以acquire多次；\n  3. 如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）\n  4. 相对 `Rlock` ， `Lock` 速度更快。\n- 使用：\n  \n  使用 `Rlock` 锁\n  ```\n  import threading  \n  rLock = threading.RLock()  #RLock对象  \n  rLock.acquire()  \n  rLock.acquire() #在同一线程内，程序不会堵塞。  \n  rLock.release()  \n  rLock.release()  \n\n  ```\n  \n  使用 `Lock` 锁：\n\n  ```\n  import threading  \n  lock = threading.Lock() #Lock对象  \n  lock.acquire()  \n  lock.acquire()  #产生了死琐。  \n  lock.release()  \n  lock.release()  \n  ```\n  \n\n- 缺点：\n \n  \n### semaphore（信号量）\n\n- 说明：\n\n  信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为**负值**时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成**非负值**时。\n\n  本质上，信号量就是一个计数器，当计数器的值为 **非负值** 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 **负值** 时，所有待获取共享资源的线程挂起状态。\n\n\n- 使用：\n\n  ```\n  semaphore = threading.Semaphore(0)\n\n  # Thread1:\n  def thread1_method():\n      semaphore.acquire()  # 线程1 对信号量进行获取操作\n  \n\n  # Thread2:\n  def thread2_method():\n    semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器\n\n  ```\n  \n  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。\n  \n\n- 缺点：\n  \n  导致死锁\n\n  有多个线程（比如：`t1` ， `t2`），竞争多个信号量（比如：`s1` , `s2`）。 假如，现在有一个线程 `t1` 先等待信号量 `s1` ，然后等待信号量 `s2` ，而线程 `t2` 会先等待信号量 `s2` ，然后再等待信号量 `s1` ，这样就可能会发生死锁，导致 `t1` 等待 `s2` ，但是 `t2` 在等待 `s1` 。\n\n\n### Condition - 条件同步\n\n- 说明：\n  \n  当多个线程**等待**同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。\n\n- 使用：\n\n  ```\n  import threading\n\n  condition = threading.Condition()\n  \n  #  生产者\n  def thread1_method():\n    condition.acquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n        condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n    \n    # TODO do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()  # 释放资源\n\n  # 消费者\n  def thread2_method():\n     \n    condition.accquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n         condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n\n    # 条件满足\n    # TODO  do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()   # 释放资源\n\n  ```\n  `wait` 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。\n  \n  `notify` 唤醒一个挂起的线程（如果存在挂起的线程）。注意：`notify()`方法不会释放所占用的琐。需要通过 `release()` 方法释放锁。\n\n\n- 缺点：\n  \n\n### Event - 事件\n\n- 说明：\n- 使用：\n\n  ```\n  import threading\n  event = threading.Event()\n  \n\n  ```\n\n- 缺点：\n\n\n\n\n\n**参考：**\n\n- [基于线程的并行](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html)\n\n- [What is the difference between Lock and RLock\n](https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock)\n\n\n","source":"_posts/2019-03-21-python-mulit-thread.md","raw":"---\ntitle: python 多线程锁机制介绍\ndate: 2019-03-21 15:56:07\ntags:\n  - Python\n  - thread\n---\n\n### Lock\n- 说明：\n\n对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。\n\n- 使用：\n\n```\nimport threading\n_lock = threading.lock() # 定义锁 _local\n\n_lock.accquire()  # 获取锁\n# TODO do something\ndo_somthing(share_var)   # 操作共享资源\n_lock.release()  #释放锁\n\n```\n\n- 缺点：\n  \n  死锁\n\n  当有多个共享资源（比如：`R_A`, `R_B`），多个线程（比如：`T_A`, `T_B`），每个线程都需要操作共享资源。假如线程 `T_A` 已经获取了共享资源 `R_A`，`T_B` 获取了共享资源 `R_B` ， 而线程 `T_A` 等待 `T_B` 释放共享资源 `R_B` 。 同时，线程 `T_B` 等待 `T_A` 释放共享资源 `R_A` ，此时就陷入死锁状态。\n\n\n### RLock\n\n- 说明：\n\n  RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 `Lock` 有是四个特点：\n  1. 谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 `Lock` 锁，可以被另外一个线程所释放。\n  2. 同一线程可以多次获取到该锁，即可以acquire多次；\n  3. 如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）\n  4. 相对 `Rlock` ， `Lock` 速度更快。\n- 使用：\n  \n  使用 `Rlock` 锁\n  ```\n  import threading  \n  rLock = threading.RLock()  #RLock对象  \n  rLock.acquire()  \n  rLock.acquire() #在同一线程内，程序不会堵塞。  \n  rLock.release()  \n  rLock.release()  \n\n  ```\n  \n  使用 `Lock` 锁：\n\n  ```\n  import threading  \n  lock = threading.Lock() #Lock对象  \n  lock.acquire()  \n  lock.acquire()  #产生了死琐。  \n  lock.release()  \n  lock.release()  \n  ```\n  \n\n- 缺点：\n \n  \n### semaphore（信号量）\n\n- 说明：\n\n  信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为**负值**时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成**非负值**时。\n\n  本质上，信号量就是一个计数器，当计数器的值为 **非负值** 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 **负值** 时，所有待获取共享资源的线程挂起状态。\n\n\n- 使用：\n\n  ```\n  semaphore = threading.Semaphore(0)\n\n  # Thread1:\n  def thread1_method():\n      semaphore.acquire()  # 线程1 对信号量进行获取操作\n  \n\n  # Thread2:\n  def thread2_method():\n    semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器\n\n  ```\n  \n  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。\n  \n\n- 缺点：\n  \n  导致死锁\n\n  有多个线程（比如：`t1` ， `t2`），竞争多个信号量（比如：`s1` , `s2`）。 假如，现在有一个线程 `t1` 先等待信号量 `s1` ，然后等待信号量 `s2` ，而线程 `t2` 会先等待信号量 `s2` ，然后再等待信号量 `s1` ，这样就可能会发生死锁，导致 `t1` 等待 `s2` ，但是 `t2` 在等待 `s1` 。\n\n\n### Condition - 条件同步\n\n- 说明：\n  \n  当多个线程**等待**同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。\n\n- 使用：\n\n  ```\n  import threading\n\n  condition = threading.Condition()\n  \n  #  生产者\n  def thread1_method():\n    condition.acquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n        condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n    \n    # TODO do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()  # 释放资源\n\n  # 消费者\n  def thread2_method():\n     \n    condition.accquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n         condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n\n    # 条件满足\n    # TODO  do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()   # 释放资源\n\n  ```\n  `wait` 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。\n  \n  `notify` 唤醒一个挂起的线程（如果存在挂起的线程）。注意：`notify()`方法不会释放所占用的琐。需要通过 `release()` 方法释放锁。\n\n\n- 缺点：\n  \n\n### Event - 事件\n\n- 说明：\n- 使用：\n\n  ```\n  import threading\n  event = threading.Event()\n  \n\n  ```\n\n- 缺点：\n\n\n\n\n\n**参考：**\n\n- [基于线程的并行](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html)\n\n- [What is the difference between Lock and RLock\n](https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock)\n\n\n","slug":"python-mulit-thread","published":1,"updated":"2019-03-21T11:41:49.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqkt0006hqxulpkpfwp0","content":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><ul>\n<li>说明：</li>\n</ul>\n<p>对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。</p>\n<ul>\n<li>使用：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">_lock = threading.lock() # 定义锁 _local</span><br><span class=\"line\"></span><br><span class=\"line\">_lock.accquire()  # 获取锁</span><br><span class=\"line\"># TODO do something</span><br><span class=\"line\">do_somthing(share_var)   # 操作共享资源</span><br><span class=\"line\">_lock.release()  #释放锁</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>缺点：</p>\n<p>死锁</p>\n<p>当有多个共享资源（比如：<code>R_A</code>, <code>R_B</code>），多个线程（比如：<code>T_A</code>, <code>T_B</code>），每个线程都需要操作共享资源。假如线程 <code>T_A</code> 已经获取了共享资源 <code>R_A</code>，<code>T_B</code> 获取了共享资源 <code>R_B</code> ， 而线程 <code>T_A</code> 等待 <code>T_B</code> 释放共享资源 <code>R_B</code> 。 同时，线程 <code>T_B</code> 等待 <code>T_A</code> 释放共享资源 <code>R_A</code> ，此时就陷入死锁状态。</p>\n</li>\n</ul>\n<h3 id=\"RLock\"><a href=\"#RLock\" class=\"headerlink\" title=\"RLock\"></a>RLock</h3><ul>\n<li><p>说明：</p>\n<p>RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 <code>Lock</code> 有是四个特点：</p>\n<ol>\n<li>谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 <code>Lock</code> 锁，可以被另外一个线程所释放。</li>\n<li>同一线程可以多次获取到该锁，即可以acquire多次；</li>\n<li>如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）</li>\n<li>相对 <code>Rlock</code> ， <code>Lock</code> 速度更快。</li>\n</ol>\n</li>\n<li><p>使用：</p>\n<p>使用 <code>Rlock</code> 锁</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">rLock = threading.RLock()  #RLock对象  </span><br><span class=\"line\">rLock.acquire()  </span><br><span class=\"line\">rLock.acquire() #在同一线程内，程序不会堵塞。  </span><br><span class=\"line\">rLock.release()  </span><br><span class=\"line\">rLock.release()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  使用 <code>Lock</code> 锁：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">lock = threading.Lock() #Lock对象  </span><br><span class=\"line\">lock.acquire()  </span><br><span class=\"line\">lock.acquire()  #产生了死琐。  </span><br><span class=\"line\">lock.release()  </span><br><span class=\"line\">lock.release()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"semaphore（信号量）\"><a href=\"#semaphore（信号量）\" class=\"headerlink\" title=\"semaphore（信号量）\"></a>semaphore（信号量）</h3><ul>\n<li><p>说明：</p>\n<p>信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为<strong>负值</strong>时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成<strong>非负值</strong>时。</p>\n<p>本质上，信号量就是一个计数器，当计数器的值为 <strong>非负值</strong> 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 <strong>负值</strong> 时，所有待获取共享资源的线程挂起状态。</p>\n</li>\n</ul>\n<ul>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">semaphore = threading.Semaphore(0)</span><br><span class=\"line\"></span><br><span class=\"line\"># Thread1:</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">    semaphore.acquire()  # 线程1 对信号量进行获取操作</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># Thread2:</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">  semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。</p>\n<ul>\n<li><p>缺点：</p>\n<p>导致死锁</p>\n<p>有多个线程（比如：<code>t1</code> ， <code>t2</code>），竞争多个信号量（比如：<code>s1</code> , <code>s2</code>）。 假如，现在有一个线程 <code>t1</code> 先等待信号量 <code>s1</code> ，然后等待信号量 <code>s2</code> ，而线程 <code>t2</code> 会先等待信号量 <code>s2</code> ，然后再等待信号量 <code>s1</code> ，这样就可能会发生死锁，导致 <code>t1</code> 等待 <code>s2</code> ，但是 <code>t2</code> 在等待 <code>s1</code> 。</p>\n</li>\n</ul>\n<h3 id=\"Condition-条件同步\"><a href=\"#Condition-条件同步\" class=\"headerlink\" title=\"Condition - 条件同步\"></a>Condition - 条件同步</h3><ul>\n<li><p>说明：</p>\n<p>当多个线程<strong>等待</strong>同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。</p>\n</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\"></span><br><span class=\"line\">condition = threading.Condition()</span><br><span class=\"line\"></span><br><span class=\"line\">#  生产者</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">  condition.acquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">      condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\">  </span><br><span class=\"line\">  # TODO do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()  # 释放资源</span><br><span class=\"line\"></span><br><span class=\"line\"># 消费者</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">   </span><br><span class=\"line\">  condition.accquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">       condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\"></span><br><span class=\"line\">  # 条件满足</span><br><span class=\"line\">  # TODO  do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()   # 释放资源</span><br></pre></td></tr></table></figure>\n<p><code>wait</code> 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。</p>\n<p><code>notify</code> 唤醒一个挂起的线程（如果存在挂起的线程）。注意：<code>notify()</code>方法不会释放所占用的琐。需要通过 <code>release()</code> 方法释放锁。</p>\n</li>\n</ul>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"Event-事件\"><a href=\"#Event-事件\" class=\"headerlink\" title=\"Event - 事件\"></a>Event - 事件</h3><ul>\n<li>说明：</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">event = threading.Event()</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺点：</p>\n</li>\n</ul>\n<p><strong>参考：</strong></p>\n<ul>\n<li><p><a href=\"https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html\" target=\"_blank\" rel=\"noopener\">基于线程的并行</a></p>\n</li>\n<li><p><a href=\"https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock\" target=\"_blank\" rel=\"noopener\">What is the difference between Lock and RLock\n</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><ul>\n<li>说明：</li>\n</ul>\n<p>对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。</p>\n<ul>\n<li>使用：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">_lock = threading.lock() # 定义锁 _local</span><br><span class=\"line\"></span><br><span class=\"line\">_lock.accquire()  # 获取锁</span><br><span class=\"line\"># TODO do something</span><br><span class=\"line\">do_somthing(share_var)   # 操作共享资源</span><br><span class=\"line\">_lock.release()  #释放锁</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>缺点：</p>\n<p>死锁</p>\n<p>当有多个共享资源（比如：<code>R_A</code>, <code>R_B</code>），多个线程（比如：<code>T_A</code>, <code>T_B</code>），每个线程都需要操作共享资源。假如线程 <code>T_A</code> 已经获取了共享资源 <code>R_A</code>，<code>T_B</code> 获取了共享资源 <code>R_B</code> ， 而线程 <code>T_A</code> 等待 <code>T_B</code> 释放共享资源 <code>R_B</code> 。 同时，线程 <code>T_B</code> 等待 <code>T_A</code> 释放共享资源 <code>R_A</code> ，此时就陷入死锁状态。</p>\n</li>\n</ul>\n<h3 id=\"RLock\"><a href=\"#RLock\" class=\"headerlink\" title=\"RLock\"></a>RLock</h3><ul>\n<li><p>说明：</p>\n<p>RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 <code>Lock</code> 有是四个特点：</p>\n<ol>\n<li>谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 <code>Lock</code> 锁，可以被另外一个线程所释放。</li>\n<li>同一线程可以多次获取到该锁，即可以acquire多次；</li>\n<li>如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）</li>\n<li>相对 <code>Rlock</code> ， <code>Lock</code> 速度更快。</li>\n</ol>\n</li>\n<li><p>使用：</p>\n<p>使用 <code>Rlock</code> 锁</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">rLock = threading.RLock()  #RLock对象  </span><br><span class=\"line\">rLock.acquire()  </span><br><span class=\"line\">rLock.acquire() #在同一线程内，程序不会堵塞。  </span><br><span class=\"line\">rLock.release()  </span><br><span class=\"line\">rLock.release()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  使用 <code>Lock</code> 锁：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">lock = threading.Lock() #Lock对象  </span><br><span class=\"line\">lock.acquire()  </span><br><span class=\"line\">lock.acquire()  #产生了死琐。  </span><br><span class=\"line\">lock.release()  </span><br><span class=\"line\">lock.release()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"semaphore（信号量）\"><a href=\"#semaphore（信号量）\" class=\"headerlink\" title=\"semaphore（信号量）\"></a>semaphore（信号量）</h3><ul>\n<li><p>说明：</p>\n<p>信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为<strong>负值</strong>时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成<strong>非负值</strong>时。</p>\n<p>本质上，信号量就是一个计数器，当计数器的值为 <strong>非负值</strong> 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 <strong>负值</strong> 时，所有待获取共享资源的线程挂起状态。</p>\n</li>\n</ul>\n<ul>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">semaphore = threading.Semaphore(0)</span><br><span class=\"line\"></span><br><span class=\"line\"># Thread1:</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">    semaphore.acquire()  # 线程1 对信号量进行获取操作</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># Thread2:</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">  semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。</p>\n<ul>\n<li><p>缺点：</p>\n<p>导致死锁</p>\n<p>有多个线程（比如：<code>t1</code> ， <code>t2</code>），竞争多个信号量（比如：<code>s1</code> , <code>s2</code>）。 假如，现在有一个线程 <code>t1</code> 先等待信号量 <code>s1</code> ，然后等待信号量 <code>s2</code> ，而线程 <code>t2</code> 会先等待信号量 <code>s2</code> ，然后再等待信号量 <code>s1</code> ，这样就可能会发生死锁，导致 <code>t1</code> 等待 <code>s2</code> ，但是 <code>t2</code> 在等待 <code>s1</code> 。</p>\n</li>\n</ul>\n<h3 id=\"Condition-条件同步\"><a href=\"#Condition-条件同步\" class=\"headerlink\" title=\"Condition - 条件同步\"></a>Condition - 条件同步</h3><ul>\n<li><p>说明：</p>\n<p>当多个线程<strong>等待</strong>同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。</p>\n</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\"></span><br><span class=\"line\">condition = threading.Condition()</span><br><span class=\"line\"></span><br><span class=\"line\">#  生产者</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">  condition.acquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">      condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\">  </span><br><span class=\"line\">  # TODO do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()  # 释放资源</span><br><span class=\"line\"></span><br><span class=\"line\"># 消费者</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">   </span><br><span class=\"line\">  condition.accquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">       condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\"></span><br><span class=\"line\">  # 条件满足</span><br><span class=\"line\">  # TODO  do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()   # 释放资源</span><br></pre></td></tr></table></figure>\n<p><code>wait</code> 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。</p>\n<p><code>notify</code> 唤醒一个挂起的线程（如果存在挂起的线程）。注意：<code>notify()</code>方法不会释放所占用的琐。需要通过 <code>release()</code> 方法释放锁。</p>\n</li>\n</ul>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"Event-事件\"><a href=\"#Event-事件\" class=\"headerlink\" title=\"Event - 事件\"></a>Event - 事件</h3><ul>\n<li>说明：</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">event = threading.Event()</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺点：</p>\n</li>\n</ul>\n<p><strong>参考：</strong></p>\n<ul>\n<li><p><a href=\"https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html\" target=\"_blank\" rel=\"noopener\">基于线程的并行</a></p>\n</li>\n<li><p><a href=\"https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock\" target=\"_blank\" rel=\"noopener\">What is the difference between Lock and RLock\n</a></p>\n</li>\n</ul>\n"},{"title":"合并两个有序数组——java实现","date":"2019-03-25T14:03:49.000Z","_content":"### 合并有序数组\n\n将两个有序数组合并成一个数组\n\n\n```\n/**\n * @function 合并两个有序数组arr1[] arr2[]\n * @author PC\n *\n */\npublic class MergeOrderList {\n\tpublic static void merge(int [] arr1,int [] arr2){\n\t\tint len1 = arr1.length;//数组1长度\n\t\tint len2 = arr2.length;//数组2长度\n\t\tint len = len1 + len2;//合并后数组长度\n\t\tint arr[] = new int[len];//合并后的数组\n\t\tint j = len1-1;\n\t\tint i = len2-1;\n\t\tlen--;\n\t\twhile(i>=0&&j>=0){//从后向前比较\n\t\t\tif(arr2[i]>arr1[j]){//将第二个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr2[i];\n\t\t\t\ti--;//“指针”后移一位\n\t\t\t}else if(arr2[i]<=arr1[j]){//将第一个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr1[j];\n\t\t\t\tj--;//“指针”后移一位\n\t\t\t}\n\t\t}\n\t\tif(i>j){//将剩余的数组1或者数组2的元素全部追加到数组arr\n\t\t\twhile(i>=0){\n\t\t\t\tarr[len--] = arr2[i--];\n\t\t\t}\n\t\t}else{\n\t\t\twhile(j>=0){\n\t\t\t\tarr[len--] = arr1[j--];\n\t\t\t}\n\t\t}\n\t\tfor (int k = 0; k < arr.length; k++) {\n\t\t\tSystem.out.print(arr[k]+\" \");\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint arr1[] = {1,4,5,7,10,11,15};\n\t\tint arr2[] = {2,3,6,8,9,13,14,17};\n\t\tmerge(arr1,arr2);\n\t}\n}\n\n```\n","source":"_posts/2019-03-25-algorithm-two-order-list-merge.md","raw":"---\ntitle: 合并两个有序数组——java实现\ndate: 2019-03-25 14:03:49\ntags:\n  - 算法\ncategories:\n  - 常见算法\n---\n### 合并有序数组\n\n将两个有序数组合并成一个数组\n\n\n```\n/**\n * @function 合并两个有序数组arr1[] arr2[]\n * @author PC\n *\n */\npublic class MergeOrderList {\n\tpublic static void merge(int [] arr1,int [] arr2){\n\t\tint len1 = arr1.length;//数组1长度\n\t\tint len2 = arr2.length;//数组2长度\n\t\tint len = len1 + len2;//合并后数组长度\n\t\tint arr[] = new int[len];//合并后的数组\n\t\tint j = len1-1;\n\t\tint i = len2-1;\n\t\tlen--;\n\t\twhile(i>=0&&j>=0){//从后向前比较\n\t\t\tif(arr2[i]>arr1[j]){//将第二个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr2[i];\n\t\t\t\ti--;//“指针”后移一位\n\t\t\t}else if(arr2[i]<=arr1[j]){//将第一个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr1[j];\n\t\t\t\tj--;//“指针”后移一位\n\t\t\t}\n\t\t}\n\t\tif(i>j){//将剩余的数组1或者数组2的元素全部追加到数组arr\n\t\t\twhile(i>=0){\n\t\t\t\tarr[len--] = arr2[i--];\n\t\t\t}\n\t\t}else{\n\t\t\twhile(j>=0){\n\t\t\t\tarr[len--] = arr1[j--];\n\t\t\t}\n\t\t}\n\t\tfor (int k = 0; k < arr.length; k++) {\n\t\t\tSystem.out.print(arr[k]+\" \");\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint arr1[] = {1,4,5,7,10,11,15};\n\t\tint arr2[] = {2,3,6,8,9,13,14,17};\n\t\tmerge(arr1,arr2);\n\t}\n}\n\n```\n","slug":"algorithm-two-order-list-merge","published":1,"updated":"2019-03-25T08:34:33.291Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqkv0008hqxubomg75xx","content":"<h3 id=\"合并有序数组\"><a href=\"#合并有序数组\" class=\"headerlink\" title=\"合并有序数组\"></a>合并有序数组</h3><p>将两个有序数组合并成一个数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * @function 合并两个有序数组arr1[] arr2[]</span><br><span class=\"line\"> * @author PC</span><br><span class=\"line\"> *</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class MergeOrderList &#123;</span><br><span class=\"line\">\tpublic static void merge(int [] arr1,int [] arr2)&#123;</span><br><span class=\"line\">\t\tint len1 = arr1.length;//数组1长度</span><br><span class=\"line\">\t\tint len2 = arr2.length;//数组2长度</span><br><span class=\"line\">\t\tint len = len1 + len2;//合并后数组长度</span><br><span class=\"line\">\t\tint arr[] = new int[len];//合并后的数组</span><br><span class=\"line\">\t\tint j = len1-1;</span><br><span class=\"line\">\t\tint i = len2-1;</span><br><span class=\"line\">\t\tlen--;</span><br><span class=\"line\">\t\twhile(i&gt;=0&amp;&amp;j&gt;=0)&#123;//从后向前比较</span><br><span class=\"line\">\t\t\tif(arr2[i]&gt;arr1[j])&#123;//将第二个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i];</span><br><span class=\"line\">\t\t\t\ti--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;else if(arr2[i]&lt;=arr1[j])&#123;//将第一个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j];</span><br><span class=\"line\">\t\t\t\tj--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif(i&gt;j)&#123;//将剩余的数组1或者数组2的元素全部追加到数组arr</span><br><span class=\"line\">\t\t\twhile(i&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;else&#123;</span><br><span class=\"line\">\t\t\twhile(j&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfor (int k = 0; k &lt; arr.length; k++) &#123;</span><br><span class=\"line\">\t\t\tSystem.out.print(arr[k]+&quot; &quot;);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpublic static void main(String[] args) &#123;</span><br><span class=\"line\">\t\tint arr1[] = &#123;1,4,5,7,10,11,15&#125;;</span><br><span class=\"line\">\t\tint arr2[] = &#123;2,3,6,8,9,13,14,17&#125;;</span><br><span class=\"line\">\t\tmerge(arr1,arr2);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"合并有序数组\"><a href=\"#合并有序数组\" class=\"headerlink\" title=\"合并有序数组\"></a>合并有序数组</h3><p>将两个有序数组合并成一个数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * @function 合并两个有序数组arr1[] arr2[]</span><br><span class=\"line\"> * @author PC</span><br><span class=\"line\"> *</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class MergeOrderList &#123;</span><br><span class=\"line\">\tpublic static void merge(int [] arr1,int [] arr2)&#123;</span><br><span class=\"line\">\t\tint len1 = arr1.length;//数组1长度</span><br><span class=\"line\">\t\tint len2 = arr2.length;//数组2长度</span><br><span class=\"line\">\t\tint len = len1 + len2;//合并后数组长度</span><br><span class=\"line\">\t\tint arr[] = new int[len];//合并后的数组</span><br><span class=\"line\">\t\tint j = len1-1;</span><br><span class=\"line\">\t\tint i = len2-1;</span><br><span class=\"line\">\t\tlen--;</span><br><span class=\"line\">\t\twhile(i&gt;=0&amp;&amp;j&gt;=0)&#123;//从后向前比较</span><br><span class=\"line\">\t\t\tif(arr2[i]&gt;arr1[j])&#123;//将第二个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i];</span><br><span class=\"line\">\t\t\t\ti--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;else if(arr2[i]&lt;=arr1[j])&#123;//将第一个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j];</span><br><span class=\"line\">\t\t\t\tj--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif(i&gt;j)&#123;//将剩余的数组1或者数组2的元素全部追加到数组arr</span><br><span class=\"line\">\t\t\twhile(i&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;else&#123;</span><br><span class=\"line\">\t\t\twhile(j&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfor (int k = 0; k &lt; arr.length; k++) &#123;</span><br><span class=\"line\">\t\t\tSystem.out.print(arr[k]+&quot; &quot;);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpublic static void main(String[] args) &#123;</span><br><span class=\"line\">\t\tint arr1[] = &#123;1,4,5,7,10,11,15&#125;;</span><br><span class=\"line\">\t\tint arr2[] = &#123;2,3,6,8,9,13,14,17&#125;;</span><br><span class=\"line\">\t\tmerge(arr1,arr2);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"gRPC教程——gRPC简介","date":"2019-03-25T18:00:58.000Z","_content":"\n\n## RPC\n\n`RPC` 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。\n\n`RPC`只是描绘了 `Client` 与 `Server` 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 `RPC` 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 `RPC` 框架有： `Thrift` （Facebook捐赠给Apache公司）、 `gRPC`（Google公司）， 国内优秀的 `RPC`框架有：`Dubbo` (Alibaba), `Motan` (sina) 。但是各个框架侧重点并不同，比如 `gRPC` 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 `Dubbo` 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。\n\n下面着重对 `RPC` 代表 `gRPC` 进行介绍：\n\n## gRPC\n`gRPC` 是一种使用`protocol buffer`接口定义语言（`Interface Definition Language, IDL`）定义服务的方法。\n\n在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 `RPC` 系统类似，`gRPC` 也是基于以下理念：定义一个服务(`service`)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 `gRPC` 服务器来处理客户端调用。在客户端拥有一个存根(`Stub`)能够像服务端一样的方法。\n\n`gRPC` 由三部分组成：\n\n - `gRPC Stub`, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口。\n - `gRPC server`, 定义：这是将为远程过程调用提供服务的实际服务器。类似于HTTP服务器\n - `gRPC client`, 定义：使用 `gRPC` 客户端访问远程 `gRPC` 服务器。这就是使用 `gRPC` 简单的原因。调用 `gRPC` 方法就像调用另一个函数一样。\n\n\n![](/images/2019-03-25_180320.png)\n\n\n\n### Protocol Buffer\n\n `gRPC` 不使用 `JSON` 或 `XML` （非常庞大），而是使用Google `ProtocolBuffers` 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。\n\n默认情况下，`gRPC`使用协议缓冲区（`Protocol Buffers`），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。\n\n该协议缓冲区可以理解成**客户端**和**服务器**约定好的通信数据结构。\n\n使用`Protocol Buffers`，首选定义一个数据结构，后续用于序列化为`proto`类型文件——以`.proto`为后缀的文本文件。`Protocol Buffer`数据被结构化为 `messages` 。每个`message`包含一系列 `key-value`对，被称为域（field）：\n\n```\nmessage Person {\n    string name = 1;\n    int32 id = 2;\n    bool has_ponycopter = 3;\n}\n\n```\n\n然后，一旦定义了`Protocol Buffer`数据结构，可以使用`protocol buffer`编译器`protoc` 将定义的`proto file`编译成各个语言的数据访问类。这些方法为每个字段（比如 `name()`、`set_name()`）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择`C++`语言，对上述举例经过编译后，生成一个`Person`类，可以使用该类填充、序列化和检索`Person`协议缓冲区消息。\n\n正如您将在我们的示例中看到的那样，您在普通`proto`文件中定义`grpc`服务，并将 `rpc` 方法参数和返回类型指定为协议缓冲消息：\n\n```\nsyntax=''\n\n// 定义 greeter service\nservice Greeter {\n  // 发送 greeter\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// (请求消息结构)  request message\nmessage HelloRequest {\n  string name = 1;\n}\n\n// (响应消息结构) response  message\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n\n\n\n`gRPC`针对不同的语言，通过插件`protoc`通过`.proto`文件生成对应语言的代码。\n\n**`Protocol buffer` 版本**\n\n通常，虽然您可以使用`proto2`（当前的默认协议缓冲版本），但我们建议您将 `proto3` 与 `gRPC` 一起使用，因为它允许您使用全系列的 `gRPC` 支持的语言，以及避免与 `proto2` 客户端通信时的兼容性问题`proto3`服务器，反之亦然\n\n## RPC vs RESTful\n\n1. RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.\n2. RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的**方法**和**过程**进行调用。而RESTful操作的对象是**资源**，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。\n3. 操作的对象不一样。 `RPC` 操作的是方法和过程，它要操作的是方法对象。 `RESTful` 操作的是资源(resource)，而不是方法。\n4. RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。\n\n\n## 参考：\n - [gRPC官方文档](https://grpc.io/docs/)\n - [gRPC 官方文档中文版](https://doc.oschina.net/grpc)\n - [MicroServices on gRPC](https://technokeeda.com/programming/microservices-on-grpc/)\n","source":"_posts/2019-03-25-grpc-introduction.md","raw":"---\ntitle: gRPC教程——gRPC简介\ndate: 2019-03-25 18:00:58\ntags:\n  - gRPC\ncategories:\n  - gRPC\n---\n\n\n## RPC\n\n`RPC` 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。\n\n`RPC`只是描绘了 `Client` 与 `Server` 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 `RPC` 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 `RPC` 框架有： `Thrift` （Facebook捐赠给Apache公司）、 `gRPC`（Google公司）， 国内优秀的 `RPC`框架有：`Dubbo` (Alibaba), `Motan` (sina) 。但是各个框架侧重点并不同，比如 `gRPC` 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 `Dubbo` 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。\n\n下面着重对 `RPC` 代表 `gRPC` 进行介绍：\n\n## gRPC\n`gRPC` 是一种使用`protocol buffer`接口定义语言（`Interface Definition Language, IDL`）定义服务的方法。\n\n在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 `RPC` 系统类似，`gRPC` 也是基于以下理念：定义一个服务(`service`)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 `gRPC` 服务器来处理客户端调用。在客户端拥有一个存根(`Stub`)能够像服务端一样的方法。\n\n`gRPC` 由三部分组成：\n\n - `gRPC Stub`, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口。\n - `gRPC server`, 定义：这是将为远程过程调用提供服务的实际服务器。类似于HTTP服务器\n - `gRPC client`, 定义：使用 `gRPC` 客户端访问远程 `gRPC` 服务器。这就是使用 `gRPC` 简单的原因。调用 `gRPC` 方法就像调用另一个函数一样。\n\n\n![](/images/2019-03-25_180320.png)\n\n\n\n### Protocol Buffer\n\n `gRPC` 不使用 `JSON` 或 `XML` （非常庞大），而是使用Google `ProtocolBuffers` 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。\n\n默认情况下，`gRPC`使用协议缓冲区（`Protocol Buffers`），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。\n\n该协议缓冲区可以理解成**客户端**和**服务器**约定好的通信数据结构。\n\n使用`Protocol Buffers`，首选定义一个数据结构，后续用于序列化为`proto`类型文件——以`.proto`为后缀的文本文件。`Protocol Buffer`数据被结构化为 `messages` 。每个`message`包含一系列 `key-value`对，被称为域（field）：\n\n```\nmessage Person {\n    string name = 1;\n    int32 id = 2;\n    bool has_ponycopter = 3;\n}\n\n```\n\n然后，一旦定义了`Protocol Buffer`数据结构，可以使用`protocol buffer`编译器`protoc` 将定义的`proto file`编译成各个语言的数据访问类。这些方法为每个字段（比如 `name()`、`set_name()`）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择`C++`语言，对上述举例经过编译后，生成一个`Person`类，可以使用该类填充、序列化和检索`Person`协议缓冲区消息。\n\n正如您将在我们的示例中看到的那样，您在普通`proto`文件中定义`grpc`服务，并将 `rpc` 方法参数和返回类型指定为协议缓冲消息：\n\n```\nsyntax=''\n\n// 定义 greeter service\nservice Greeter {\n  // 发送 greeter\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\n// (请求消息结构)  request message\nmessage HelloRequest {\n  string name = 1;\n}\n\n// (响应消息结构) response  message\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n\n\n\n`gRPC`针对不同的语言，通过插件`protoc`通过`.proto`文件生成对应语言的代码。\n\n**`Protocol buffer` 版本**\n\n通常，虽然您可以使用`proto2`（当前的默认协议缓冲版本），但我们建议您将 `proto3` 与 `gRPC` 一起使用，因为它允许您使用全系列的 `gRPC` 支持的语言，以及避免与 `proto2` 客户端通信时的兼容性问题`proto3`服务器，反之亦然\n\n## RPC vs RESTful\n\n1. RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.\n2. RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的**方法**和**过程**进行调用。而RESTful操作的对象是**资源**，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。\n3. 操作的对象不一样。 `RPC` 操作的是方法和过程，它要操作的是方法对象。 `RESTful` 操作的是资源(resource)，而不是方法。\n4. RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。\n\n\n## 参考：\n - [gRPC官方文档](https://grpc.io/docs/)\n - [gRPC 官方文档中文版](https://doc.oschina.net/grpc)\n - [MicroServices on gRPC](https://technokeeda.com/programming/microservices-on-grpc/)\n","slug":"grpc-introduction","published":1,"updated":"2019-03-25T10:04:49.228Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqky000ahqxu3sr1ye1u","content":"<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p><code>RPC</code> 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。</p>\n<p><code>RPC</code>只是描绘了 <code>Client</code> 与 <code>Server</code> 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 <code>RPC</code> 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 <code>RPC</code> 框架有： <code>Thrift</code> （Facebook捐赠给Apache公司）、 <code>gRPC</code>（Google公司）， 国内优秀的 <code>RPC</code>框架有：<code>Dubbo</code> (Alibaba), <code>Motan</code> (sina) 。但是各个框架侧重点并不同，比如 <code>gRPC</code> 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 <code>Dubbo</code> 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p>\n<p>下面着重对 <code>RPC</code> 代表 <code>gRPC</code> 进行介绍：</p>\n<h2 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a>gRPC</h2><p><code>gRPC</code> 是一种使用<code>protocol buffer</code>接口定义语言（<code>Interface Definition Language, IDL</code>）定义服务的方法。</p>\n<p>在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 <code>RPC</code> 系统类似，<code>gRPC</code> 也是基于以下理念：定义一个服务(<code>service</code>)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 <code>gRPC</code> 服务器来处理客户端调用。在客户端拥有一个存根(<code>Stub</code>)能够像服务端一样的方法。</p>\n<p><code>gRPC</code> 由三部分组成：</p>\n<ul>\n<li><code>gRPC Stub</code>, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口。</li>\n<li><code>gRPC server</code>, 定义：这是将为远程过程调用提供服务的实际服务器。类似于HTTP服务器</li>\n<li><code>gRPC client</code>, 定义：使用 <code>gRPC</code> 客户端访问远程 <code>gRPC</code> 服务器。这就是使用 <code>gRPC</code> 简单的原因。调用 <code>gRPC</code> 方法就像调用另一个函数一样。</li>\n</ul>\n<p><img src=\"/images/2019-03-25_180320.png\" alt></p>\n<h3 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h3><p> <code>gRPC</code> 不使用 <code>JSON</code> 或 <code>XML</code> （非常庞大），而是使用Google <code>ProtocolBuffers</code> 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。</p>\n<p>默认情况下，<code>gRPC</code>使用协议缓冲区（<code>Protocol Buffers</code>），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。</p>\n<p>该协议缓冲区可以理解成<strong>客户端</strong>和<strong>服务器</strong>约定好的通信数据结构。</p>\n<p>使用<code>Protocol Buffers</code>，首选定义一个数据结构，后续用于序列化为<code>proto</code>类型文件——以<code>.proto</code>为后缀的文本文件。<code>Protocol Buffer</code>数据被结构化为 <code>messages</code> 。每个<code>message</code>包含一系列 <code>key-value</code>对，被称为域（field）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message Person &#123;</span><br><span class=\"line\">    string name = 1;</span><br><span class=\"line\">    int32 id = 2;</span><br><span class=\"line\">    bool has_ponycopter = 3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后，一旦定义了<code>Protocol Buffer</code>数据结构，可以使用<code>protocol buffer</code>编译器<code>protoc</code> 将定义的<code>proto file</code>编译成各个语言的数据访问类。这些方法为每个字段（比如 <code>name()</code>、<code>set_name()</code>）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择<code>C++</code>语言，对上述举例经过编译后，生成一个<code>Person</code>类，可以使用该类填充、序列化和检索<code>Person</code>协议缓冲区消息。</p>\n<p>正如您将在我们的示例中看到的那样，您在普通<code>proto</code>文件中定义<code>grpc</code>服务，并将 <code>rpc</code> 方法参数和返回类型指定为协议缓冲消息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syntax=&apos;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">// 定义 greeter service</span><br><span class=\"line\">service Greeter &#123;</span><br><span class=\"line\">  // 发送 greeter</span><br><span class=\"line\">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (请求消息结构)  request message</span><br><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string name = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (响应消息结构) response  message</span><br><span class=\"line\">message HelloReply &#123;</span><br><span class=\"line\">  string message = 1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>gRPC</code>针对不同的语言，通过插件<code>protoc</code>通过<code>.proto</code>文件生成对应语言的代码。</p>\n<p><strong><code>Protocol buffer</code> 版本</strong></p>\n<p>通常，虽然您可以使用<code>proto2</code>（当前的默认协议缓冲版本），但我们建议您将 <code>proto3</code> 与 <code>gRPC</code> 一起使用，因为它允许您使用全系列的 <code>gRPC</code> 支持的语言，以及避免与 <code>proto2</code> 客户端通信时的兼容性问题<code>proto3</code>服务器，反之亦然</p>\n<h2 id=\"RPC-vs-RESTful\"><a href=\"#RPC-vs-RESTful\" class=\"headerlink\" title=\"RPC vs RESTful\"></a>RPC vs RESTful</h2><ol>\n<li>RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.</li>\n<li>RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的<strong>方法</strong>和<strong>过程</strong>进行调用。而RESTful操作的对象是<strong>资源</strong>，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。</li>\n<li>操作的对象不一样。 <code>RPC</code> 操作的是方法和过程，它要操作的是方法对象。 <code>RESTful</code> 操作的是资源(resource)，而不是方法。</li>\n<li>RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。</li>\n</ol>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><ul>\n<li><a href=\"https://grpc.io/docs/\" target=\"_blank\" rel=\"noopener\">gRPC官方文档</a></li>\n<li><a href=\"https://doc.oschina.net/grpc\" target=\"_blank\" rel=\"noopener\">gRPC 官方文档中文版</a></li>\n<li><a href=\"https://technokeeda.com/programming/microservices-on-grpc/\" target=\"_blank\" rel=\"noopener\">MicroServices on gRPC</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p><code>RPC</code> 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。</p>\n<p><code>RPC</code>只是描绘了 <code>Client</code> 与 <code>Server</code> 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 <code>RPC</code> 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 <code>RPC</code> 框架有： <code>Thrift</code> （Facebook捐赠给Apache公司）、 <code>gRPC</code>（Google公司）， 国内优秀的 <code>RPC</code>框架有：<code>Dubbo</code> (Alibaba), <code>Motan</code> (sina) 。但是各个框架侧重点并不同，比如 <code>gRPC</code> 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 <code>Dubbo</code> 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p>\n<p>下面着重对 <code>RPC</code> 代表 <code>gRPC</code> 进行介绍：</p>\n<h2 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a>gRPC</h2><p><code>gRPC</code> 是一种使用<code>protocol buffer</code>接口定义语言（<code>Interface Definition Language, IDL</code>）定义服务的方法。</p>\n<p>在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 <code>RPC</code> 系统类似，<code>gRPC</code> 也是基于以下理念：定义一个服务(<code>service</code>)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 <code>gRPC</code> 服务器来处理客户端调用。在客户端拥有一个存根(<code>Stub</code>)能够像服务端一样的方法。</p>\n<p><code>gRPC</code> 由三部分组成：</p>\n<ul>\n<li><code>gRPC Stub</code>, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口。</li>\n<li><code>gRPC server</code>, 定义：这是将为远程过程调用提供服务的实际服务器。类似于HTTP服务器</li>\n<li><code>gRPC client</code>, 定义：使用 <code>gRPC</code> 客户端访问远程 <code>gRPC</code> 服务器。这就是使用 <code>gRPC</code> 简单的原因。调用 <code>gRPC</code> 方法就像调用另一个函数一样。</li>\n</ul>\n<p><img src=\"/images/2019-03-25_180320.png\" alt></p>\n<h3 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h3><p> <code>gRPC</code> 不使用 <code>JSON</code> 或 <code>XML</code> （非常庞大），而是使用Google <code>ProtocolBuffers</code> 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。</p>\n<p>默认情况下，<code>gRPC</code>使用协议缓冲区（<code>Protocol Buffers</code>），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。</p>\n<p>该协议缓冲区可以理解成<strong>客户端</strong>和<strong>服务器</strong>约定好的通信数据结构。</p>\n<p>使用<code>Protocol Buffers</code>，首选定义一个数据结构，后续用于序列化为<code>proto</code>类型文件——以<code>.proto</code>为后缀的文本文件。<code>Protocol Buffer</code>数据被结构化为 <code>messages</code> 。每个<code>message</code>包含一系列 <code>key-value</code>对，被称为域（field）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message Person &#123;</span><br><span class=\"line\">    string name = 1;</span><br><span class=\"line\">    int32 id = 2;</span><br><span class=\"line\">    bool has_ponycopter = 3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后，一旦定义了<code>Protocol Buffer</code>数据结构，可以使用<code>protocol buffer</code>编译器<code>protoc</code> 将定义的<code>proto file</code>编译成各个语言的数据访问类。这些方法为每个字段（比如 <code>name()</code>、<code>set_name()</code>）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择<code>C++</code>语言，对上述举例经过编译后，生成一个<code>Person</code>类，可以使用该类填充、序列化和检索<code>Person</code>协议缓冲区消息。</p>\n<p>正如您将在我们的示例中看到的那样，您在普通<code>proto</code>文件中定义<code>grpc</code>服务，并将 <code>rpc</code> 方法参数和返回类型指定为协议缓冲消息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syntax=&apos;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">// 定义 greeter service</span><br><span class=\"line\">service Greeter &#123;</span><br><span class=\"line\">  // 发送 greeter</span><br><span class=\"line\">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (请求消息结构)  request message</span><br><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string name = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (响应消息结构) response  message</span><br><span class=\"line\">message HelloReply &#123;</span><br><span class=\"line\">  string message = 1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>gRPC</code>针对不同的语言，通过插件<code>protoc</code>通过<code>.proto</code>文件生成对应语言的代码。</p>\n<p><strong><code>Protocol buffer</code> 版本</strong></p>\n<p>通常，虽然您可以使用<code>proto2</code>（当前的默认协议缓冲版本），但我们建议您将 <code>proto3</code> 与 <code>gRPC</code> 一起使用，因为它允许您使用全系列的 <code>gRPC</code> 支持的语言，以及避免与 <code>proto2</code> 客户端通信时的兼容性问题<code>proto3</code>服务器，反之亦然</p>\n<h2 id=\"RPC-vs-RESTful\"><a href=\"#RPC-vs-RESTful\" class=\"headerlink\" title=\"RPC vs RESTful\"></a>RPC vs RESTful</h2><ol>\n<li>RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.</li>\n<li>RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的<strong>方法</strong>和<strong>过程</strong>进行调用。而RESTful操作的对象是<strong>资源</strong>，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。</li>\n<li>操作的对象不一样。 <code>RPC</code> 操作的是方法和过程，它要操作的是方法对象。 <code>RESTful</code> 操作的是资源(resource)，而不是方法。</li>\n<li>RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。</li>\n</ol>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><ul>\n<li><a href=\"https://grpc.io/docs/\" target=\"_blank\" rel=\"noopener\">gRPC官方文档</a></li>\n<li><a href=\"https://doc.oschina.net/grpc\" target=\"_blank\" rel=\"noopener\">gRPC 官方文档中文版</a></li>\n<li><a href=\"https://technokeeda.com/programming/microservices-on-grpc/\" target=\"_blank\" rel=\"noopener\">MicroServices on gRPC</a></li>\n</ul>\n"},{"title":"Centos 安装 docker","date":"2019-03-25T13:35:59.000Z","_content":"\n>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。\n\n#### 移除旧版本docker\n卸载旧版本docker，如果未安装，可以跳过\n```\n$ yum remove -y docker docker-client \\\n   docker-client-latest  \\\n   docker-common \\\n   docker-latest \\\n   docker-latest-logrotate \\\n   docker-logrotate \\\n   docker-selinux \\\n   docker-engine-selinux \\\n   docker-engine\n```\n#### 安装依赖软件\n```\n$ yum install -y yum-utils \\\n    device-mapper-persistent-data \\\n    lvm2\n```\n#### 配置yum源为阿里云提供的yum源\n```\n$ yum-config-manager \\\n--add-repo \\\nhttps://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n#### 查看该yum源提供的可用docker-ce版本\n```\n$ yum list docker-ce –showduplicates | sort -r\n\ndocker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable\ndocker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable \ndocker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable\n```\n\n 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce\n 安装docker-ce 18.06版本\n\n - 安装docker-ce 18.06版本\n\n   `$ yum install docker-ce-18.06.1.ce -y`\n\n - 启动docker\n\n   `$ systemctl start docker`\n\n - 设置开机启动\n\n   `$ systemctl enable docker`\n\n - 授权用户\n   \n   将用户添加到docker组\n\n   `$ sudo usermod -aG docker $USER`\n\n- 配置镜像仓库加速\n\n  配置镜像加速：使用aliyun提供的镜像加速\n\n  通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\n   ```\n   $ sudo mkdir -p /etc/docker\n   $ sudo tee /etc/docker/daemon.json <<-'EOF' {\n       \"registry-mirrors\":[\"https://xxxxxx.mirror.aliyuncs.com\"] }\n     EOF\n   ```\n\n   注意 https://xxxxxx.mirror.aliyuncs.com 需要注册阿里云申请镜像仓库\n   如果没有，可以使用作者的：https://hjjs2fuv.mirror.aliyuncs.com\n\n- 重新加载docker service使其生效\n\n  `$ systemctl daemon-reload`\n\n  `$ systemctl restart docker`\n\n\n","source":"_posts/2019-03-25-install-docker-yum.md","raw":"---\ntitle: Centos 安装 docker\ndate: 2019-03-25 13:35:59\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\n>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。\n\n#### 移除旧版本docker\n卸载旧版本docker，如果未安装，可以跳过\n```\n$ yum remove -y docker docker-client \\\n   docker-client-latest  \\\n   docker-common \\\n   docker-latest \\\n   docker-latest-logrotate \\\n   docker-logrotate \\\n   docker-selinux \\\n   docker-engine-selinux \\\n   docker-engine\n```\n#### 安装依赖软件\n```\n$ yum install -y yum-utils \\\n    device-mapper-persistent-data \\\n    lvm2\n```\n#### 配置yum源为阿里云提供的yum源\n```\n$ yum-config-manager \\\n--add-repo \\\nhttps://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n#### 查看该yum源提供的可用docker-ce版本\n```\n$ yum list docker-ce –showduplicates | sort -r\n\ndocker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable\ndocker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable \ndocker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable\n```\n\n 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce\n 安装docker-ce 18.06版本\n\n - 安装docker-ce 18.06版本\n\n   `$ yum install docker-ce-18.06.1.ce -y`\n\n - 启动docker\n\n   `$ systemctl start docker`\n\n - 设置开机启动\n\n   `$ systemctl enable docker`\n\n - 授权用户\n   \n   将用户添加到docker组\n\n   `$ sudo usermod -aG docker $USER`\n\n- 配置镜像仓库加速\n\n  配置镜像加速：使用aliyun提供的镜像加速\n\n  通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\n   ```\n   $ sudo mkdir -p /etc/docker\n   $ sudo tee /etc/docker/daemon.json <<-'EOF' {\n       \"registry-mirrors\":[\"https://xxxxxx.mirror.aliyuncs.com\"] }\n     EOF\n   ```\n\n   注意 https://xxxxxx.mirror.aliyuncs.com 需要注册阿里云申请镜像仓库\n   如果没有，可以使用作者的：https://hjjs2fuv.mirror.aliyuncs.com\n\n- 重新加载docker service使其生效\n\n  `$ systemctl daemon-reload`\n\n  `$ systemctl restart docker`\n\n\n","slug":"install-docker-yum","published":1,"updated":"2019-03-25T05:37:02.708Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rql1000dhqxu6tyw14qu","content":"<blockquote>\n<p>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。</p>\n</blockquote>\n<h4 id=\"移除旧版本docker\"><a href=\"#移除旧版本docker\" class=\"headerlink\" title=\"移除旧版本docker\"></a>移除旧版本docker</h4><p>卸载旧版本docker，如果未安装，可以跳过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove -y docker docker-client \\</span><br><span class=\"line\">   docker-client-latest  \\</span><br><span class=\"line\">   docker-common \\</span><br><span class=\"line\">   docker-latest \\</span><br><span class=\"line\">   docker-latest-logrotate \\</span><br><span class=\"line\">   docker-logrotate \\</span><br><span class=\"line\">   docker-selinux \\</span><br><span class=\"line\">   docker-engine-selinux \\</span><br><span class=\"line\">   docker-engine</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"安装依赖软件\"><a href=\"#安装依赖软件\" class=\"headerlink\" title=\"安装依赖软件\"></a>安装依赖软件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y yum-utils \\</span><br><span class=\"line\">    device-mapper-persistent-data \\</span><br><span class=\"line\">    lvm2</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置yum源为阿里云提供的yum源\"><a href=\"#配置yum源为阿里云提供的yum源\" class=\"headerlink\" title=\"配置yum源为阿里云提供的yum源\"></a>配置yum源为阿里云提供的yum源</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum-config-manager \\</span><br><span class=\"line\">--add-repo \\</span><br><span class=\"line\">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看该yum源提供的可用docker-ce版本\"><a href=\"#查看该yum源提供的可用docker-ce版本\" class=\"headerlink\" title=\"查看该yum源提供的可用docker-ce版本\"></a>查看该yum源提供的可用docker-ce版本</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum list docker-ce –showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\">docker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable</span><br><span class=\"line\">docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</span><br></pre></td></tr></table></figure>\n<p> 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce<br> 安装docker-ce 18.06版本</p>\n<ul>\n<li><p>安装docker-ce 18.06版本</p>\n<p><code>$ yum install docker-ce-18.06.1.ce -y</code></p>\n</li>\n<li><p>启动docker</p>\n<p><code>$ systemctl start docker</code></p>\n</li>\n<li><p>设置开机启动</p>\n<p><code>$ systemctl enable docker</code></p>\n</li>\n<li><p>授权用户</p>\n<p>将用户添加到docker组</p>\n<p><code>$ sudo usermod -aG docker $USER</code></p>\n</li>\n</ul>\n<ul>\n<li><p>配置镜像仓库加速</p>\n<p>配置镜像加速：使用aliyun提供的镜像加速</p>\n<p>通过修改daemon配置文件/etc/docker/daemon.json来使用加速器</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir -p /etc/docker</span><br><span class=\"line\">$ sudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos; &#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;:[&quot;https://xxxxxx.mirror.aliyuncs.com&quot;] &#125;</span><br><span class=\"line\">  EOF</span><br></pre></td></tr></table></figure>\n<p> 注意 <a href=\"https://xxxxxx.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://xxxxxx.mirror.aliyuncs.com</a> 需要注册阿里云申请镜像仓库<br> 如果没有，可以使用作者的：<a href=\"https://hjjs2fuv.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://hjjs2fuv.mirror.aliyuncs.com</a></p>\n</li>\n<li><p>重新加载docker service使其生效</p>\n<p><code>$ systemctl daemon-reload</code></p>\n<p><code>$ systemctl restart docker</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。</p>\n</blockquote>\n<h4 id=\"移除旧版本docker\"><a href=\"#移除旧版本docker\" class=\"headerlink\" title=\"移除旧版本docker\"></a>移除旧版本docker</h4><p>卸载旧版本docker，如果未安装，可以跳过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove -y docker docker-client \\</span><br><span class=\"line\">   docker-client-latest  \\</span><br><span class=\"line\">   docker-common \\</span><br><span class=\"line\">   docker-latest \\</span><br><span class=\"line\">   docker-latest-logrotate \\</span><br><span class=\"line\">   docker-logrotate \\</span><br><span class=\"line\">   docker-selinux \\</span><br><span class=\"line\">   docker-engine-selinux \\</span><br><span class=\"line\">   docker-engine</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"安装依赖软件\"><a href=\"#安装依赖软件\" class=\"headerlink\" title=\"安装依赖软件\"></a>安装依赖软件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y yum-utils \\</span><br><span class=\"line\">    device-mapper-persistent-data \\</span><br><span class=\"line\">    lvm2</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置yum源为阿里云提供的yum源\"><a href=\"#配置yum源为阿里云提供的yum源\" class=\"headerlink\" title=\"配置yum源为阿里云提供的yum源\"></a>配置yum源为阿里云提供的yum源</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum-config-manager \\</span><br><span class=\"line\">--add-repo \\</span><br><span class=\"line\">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看该yum源提供的可用docker-ce版本\"><a href=\"#查看该yum源提供的可用docker-ce版本\" class=\"headerlink\" title=\"查看该yum源提供的可用docker-ce版本\"></a>查看该yum源提供的可用docker-ce版本</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum list docker-ce –showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\">docker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable</span><br><span class=\"line\">docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</span><br></pre></td></tr></table></figure>\n<p> 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce<br> 安装docker-ce 18.06版本</p>\n<ul>\n<li><p>安装docker-ce 18.06版本</p>\n<p><code>$ yum install docker-ce-18.06.1.ce -y</code></p>\n</li>\n<li><p>启动docker</p>\n<p><code>$ systemctl start docker</code></p>\n</li>\n<li><p>设置开机启动</p>\n<p><code>$ systemctl enable docker</code></p>\n</li>\n<li><p>授权用户</p>\n<p>将用户添加到docker组</p>\n<p><code>$ sudo usermod -aG docker $USER</code></p>\n</li>\n</ul>\n<ul>\n<li><p>配置镜像仓库加速</p>\n<p>配置镜像加速：使用aliyun提供的镜像加速</p>\n<p>通过修改daemon配置文件/etc/docker/daemon.json来使用加速器</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir -p /etc/docker</span><br><span class=\"line\">$ sudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos; &#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;:[&quot;https://xxxxxx.mirror.aliyuncs.com&quot;] &#125;</span><br><span class=\"line\">  EOF</span><br></pre></td></tr></table></figure>\n<p> 注意 <a href=\"https://xxxxxx.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://xxxxxx.mirror.aliyuncs.com</a> 需要注册阿里云申请镜像仓库<br> 如果没有，可以使用作者的：<a href=\"https://hjjs2fuv.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://hjjs2fuv.mirror.aliyuncs.com</a></p>\n</li>\n<li><p>重新加载docker service使其生效</p>\n<p><code>$ systemctl daemon-reload</code></p>\n<p><code>$ systemctl restart docker</code></p>\n</li>\n</ul>\n"},{"title":"精通Oracle SQL（第二版）读书笔记   -  第一章 SQL核心","date":"2016-12-05T13:52:54.000Z","_content":"\n\nracle SQL（第二版）读书笔记\n## 第一章 SQL核心\n### 数据库接口\n> 1.数据库接口:\n> Oracle数据库的本地接口界面是**OCI**,**OCI** 将由 **Oracle内核**传递而来的查询语句发送到数据库。其他语言对应的接口：*Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动*。\n\n### SQL*Plus\n>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。\n\n\n### 常用命令：\n> * sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。\n\n> * help index： 显示可用的命令\n\n> * help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。\n\n### 在login.sql文件中修改配置\n\n> 在sql* plus启动时默认读取的两个文件，1.**$ORACLE_HOME/sqlplus/admin** 目录下的 **glogin.sql**和**login.sql** 文件。其中，**login.sql**中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。\n\n### 执行命令\n>在sql* plus中执行的是两种命令：**sql语句** 和 **SQL * Plus命令**\n\n>SQL语句用**；** 和 **/** 结束输入\n\n -  1.  可在命令后和另起一行使用；\n -  2.  /只能在下行中被识别。\n>sqlplus缓冲区\n>sqlplus执行 *.sql 文件方式：1.直接输入 *.sql,2.输入@或者START *，可以省略后缀。\n\n### 五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\n#### 1. SELECT 语句\n##### Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\n##### - select语句\n> 处理过程中首先处理的是**From**子句，多个**From**则每个步骤想象成一个临时数据集，每经过一个**FROM**，则进行一步筛选，得最终结果数据集。\n\n##### - From子句\n> 子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。\n\n##### - HAVING子句\n> 将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。\n\n##### - ORDER BY子句\n> Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。\n\n#### 2. INSERT 语句\n##### Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\n\tINSERT ALL WHEN 条件1 THEN INTO table1\n\t\t\t   WHEN 条件2 THEN INTO table2\n\t\t\t   WHEN 条件3 THEN INTO table3\n\t\t\t\t...\n\t\t\t   SELECT ** FROM table4;\n> 当指定**ALL**时，这个语句就会执行无条件的多表插入，可以用**FIRST**替换，此时指定按照**WHEN**子句在语句中的顺序进行判断\t。\n\n#### 3. UPDATE 语句\t\t\n\n##### 该语法由 **UPDATE、SET、WHERE** 组成\t\n\n#### 4. DELETE 语句\n\n##### 由 DELETE、WHERE、FROM 组成\n\n#### 5. MERGE 语句\n\n##### MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\n\n\n","source":"_posts/2019-03-25-oracle-sql-second-version-note.md","raw":"---\ntitle: 精通Oracle SQL（第二版）读书笔记   -  第一章 SQL核心\ndate: 2016-12-05 13:52:54\ntags:\n  - Oracle\ncategories:\n  - Oracle\n---\n\n\nracle SQL（第二版）读书笔记\n## 第一章 SQL核心\n### 数据库接口\n> 1.数据库接口:\n> Oracle数据库的本地接口界面是**OCI**,**OCI** 将由 **Oracle内核**传递而来的查询语句发送到数据库。其他语言对应的接口：*Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动*。\n\n### SQL*Plus\n>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。\n\n\n### 常用命令：\n> * sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。\n\n> * help index： 显示可用的命令\n\n> * help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。\n\n### 在login.sql文件中修改配置\n\n> 在sql* plus启动时默认读取的两个文件，1.**$ORACLE_HOME/sqlplus/admin** 目录下的 **glogin.sql**和**login.sql** 文件。其中，**login.sql**中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。\n\n### 执行命令\n>在sql* plus中执行的是两种命令：**sql语句** 和 **SQL * Plus命令**\n\n>SQL语句用**；** 和 **/** 结束输入\n\n -  1.  可在命令后和另起一行使用；\n -  2.  /只能在下行中被识别。\n>sqlplus缓冲区\n>sqlplus执行 *.sql 文件方式：1.直接输入 *.sql,2.输入@或者START *，可以省略后缀。\n\n### 五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\n#### 1. SELECT 语句\n##### Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\n##### - select语句\n> 处理过程中首先处理的是**From**子句，多个**From**则每个步骤想象成一个临时数据集，每经过一个**FROM**，则进行一步筛选，得最终结果数据集。\n\n##### - From子句\n> 子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。\n\n##### - HAVING子句\n> 将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。\n\n##### - ORDER BY子句\n> Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。\n\n#### 2. INSERT 语句\n##### Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\n\tINSERT ALL WHEN 条件1 THEN INTO table1\n\t\t\t   WHEN 条件2 THEN INTO table2\n\t\t\t   WHEN 条件3 THEN INTO table3\n\t\t\t\t...\n\t\t\t   SELECT ** FROM table4;\n> 当指定**ALL**时，这个语句就会执行无条件的多表插入，可以用**FIRST**替换，此时指定按照**WHEN**子句在语句中的顺序进行判断\t。\n\n#### 3. UPDATE 语句\t\t\n\n##### 该语法由 **UPDATE、SET、WHERE** 组成\t\n\n#### 4. DELETE 语句\n\n##### 由 DELETE、WHERE、FROM 组成\n\n#### 5. MERGE 语句\n\n##### MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\n\n\n","slug":"oracle-sql-second-version-note","published":1,"updated":"2019-03-25T09:21:13.093Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rql3000ehqxuigyvaeu6","content":"<p>racle SQL（第二版）读书笔记</p>\n<h2 id=\"第一章-SQL核心\"><a href=\"#第一章-SQL核心\" class=\"headerlink\" title=\"第一章 SQL核心\"></a>第一章 SQL核心</h2><h3 id=\"数据库接口\"><a href=\"#数据库接口\" class=\"headerlink\" title=\"数据库接口\"></a>数据库接口</h3><blockquote>\n<p>1.数据库接口:<br>Oracle数据库的本地接口界面是<strong>OCI</strong>,<strong>OCI</strong> 将由 <strong>Oracle内核</strong>传递而来的查询语句发送到数据库。其他语言对应的接口：<em>Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动</em>。</p>\n</blockquote>\n<h3 id=\"SQL-Plus\"><a href=\"#SQL-Plus\" class=\"headerlink\" title=\"SQL*Plus\"></a>SQL*Plus</h3><blockquote>\n<p>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。</p>\n</blockquote>\n<h3 id=\"常用命令：\"><a href=\"#常用命令：\" class=\"headerlink\" title=\"常用命令：\"></a>常用命令：</h3><blockquote>\n<ul>\n<li>sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help index： 显示可用的命令</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。</li>\n</ul>\n</blockquote>\n<h3 id=\"在login-sql文件中修改配置\"><a href=\"#在login-sql文件中修改配置\" class=\"headerlink\" title=\"在login.sql文件中修改配置\"></a>在login.sql文件中修改配置</h3><blockquote>\n<p>在sql* plus启动时默认读取的两个文件，1.<strong>$ORACLE_HOME/sqlplus/admin</strong> 目录下的 <strong>glogin.sql</strong>和<strong>login.sql</strong> 文件。其中，<strong>login.sql</strong>中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。</p>\n</blockquote>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><blockquote>\n<p>在sql<em> plus中执行的是两种命令：<strong>sql语句</strong> 和 **SQL </em> Plus命令**</p>\n</blockquote>\n<blockquote>\n<p>SQL语句用<strong>；</strong> 和 <strong>/</strong> 结束输入</p>\n</blockquote>\n<ul>\n<li><ol>\n<li>可在命令后和另起一行使用；</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>/只能在下行中被识别。<blockquote>\n<p>sqlplus缓冲区<br>sqlplus执行 <em>.sql 文件方式：1.直接输入 </em>.sql,2.输入@或者START *，可以省略后缀。</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\"><a href=\"#五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\" class=\"headerlink\" title=\"五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\"></a>五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)</h3><h4 id=\"1-SELECT-语句\"><a href=\"#1-SELECT-语句\" class=\"headerlink\" title=\"1. SELECT 语句\"></a>1. SELECT 语句</h4><h5 id=\"Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\"><a href=\"#Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\" class=\"headerlink\" title=\"Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\"></a>Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。</h5><h5 id=\"select语句\"><a href=\"#select语句\" class=\"headerlink\" title=\"- select语句\"></a>- select语句</h5><blockquote>\n<p>处理过程中首先处理的是<strong>From</strong>子句，多个<strong>From</strong>则每个步骤想象成一个临时数据集，每经过一个<strong>FROM</strong>，则进行一步筛选，得最终结果数据集。</p>\n</blockquote>\n<h5 id=\"From子句\"><a href=\"#From子句\" class=\"headerlink\" title=\"- From子句\"></a>- From子句</h5><blockquote>\n<p>子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。</p>\n</blockquote>\n<h5 id=\"HAVING子句\"><a href=\"#HAVING子句\" class=\"headerlink\" title=\"- HAVING子句\"></a>- HAVING子句</h5><blockquote>\n<p>将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。</p>\n</blockquote>\n<h5 id=\"ORDER-BY子句\"><a href=\"#ORDER-BY子句\" class=\"headerlink\" title=\"- ORDER BY子句\"></a>- ORDER BY子句</h5><blockquote>\n<p>Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。</p>\n</blockquote>\n<h4 id=\"2-INSERT-语句\"><a href=\"#2-INSERT-语句\" class=\"headerlink\" title=\"2. INSERT 语句\"></a>2. INSERT 语句</h4><h5 id=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"><a href=\"#Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\" class=\"headerlink\" title=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"></a>Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。</h5><pre><code>INSERT ALL WHEN 条件1 THEN INTO table1\n           WHEN 条件2 THEN INTO table2\n           WHEN 条件3 THEN INTO table3\n            ...\n           SELECT ** FROM table4;\n</code></pre><blockquote>\n<p>当指定<strong>ALL</strong>时，这个语句就会执行无条件的多表插入，可以用<strong>FIRST</strong>替换，此时指定按照<strong>WHEN</strong>子句在语句中的顺序进行判断    。</p>\n</blockquote>\n<h4 id=\"3-UPDATE-语句\"><a href=\"#3-UPDATE-语句\" class=\"headerlink\" title=\"3. UPDATE 语句\"></a>3. UPDATE 语句</h4><h5 id=\"该语法由-UPDATE、SET、WHERE-组成\"><a href=\"#该语法由-UPDATE、SET、WHERE-组成\" class=\"headerlink\" title=\"该语法由 UPDATE、SET、WHERE 组成\"></a>该语法由 <strong>UPDATE、SET、WHERE</strong> 组成</h5><h4 id=\"4-DELETE-语句\"><a href=\"#4-DELETE-语句\" class=\"headerlink\" title=\"4. DELETE 语句\"></a>4. DELETE 语句</h4><h5 id=\"由-DELETE、WHERE、FROM-组成\"><a href=\"#由-DELETE、WHERE、FROM-组成\" class=\"headerlink\" title=\"由 DELETE、WHERE、FROM 组成\"></a>由 DELETE、WHERE、FROM 组成</h5><h4 id=\"5-MERGE-语句\"><a href=\"#5-MERGE-语句\" class=\"headerlink\" title=\"5. MERGE 语句\"></a>5. MERGE 语句</h4><h5 id=\"MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\"><a href=\"#MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\" class=\"headerlink\" title=\"MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\"></a>MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。</h5>","site":{"data":{}},"excerpt":"","more":"<p>racle SQL（第二版）读书笔记</p>\n<h2 id=\"第一章-SQL核心\"><a href=\"#第一章-SQL核心\" class=\"headerlink\" title=\"第一章 SQL核心\"></a>第一章 SQL核心</h2><h3 id=\"数据库接口\"><a href=\"#数据库接口\" class=\"headerlink\" title=\"数据库接口\"></a>数据库接口</h3><blockquote>\n<p>1.数据库接口:<br>Oracle数据库的本地接口界面是<strong>OCI</strong>,<strong>OCI</strong> 将由 <strong>Oracle内核</strong>传递而来的查询语句发送到数据库。其他语言对应的接口：<em>Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动</em>。</p>\n</blockquote>\n<h3 id=\"SQL-Plus\"><a href=\"#SQL-Plus\" class=\"headerlink\" title=\"SQL*Plus\"></a>SQL*Plus</h3><blockquote>\n<p>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。</p>\n</blockquote>\n<h3 id=\"常用命令：\"><a href=\"#常用命令：\" class=\"headerlink\" title=\"常用命令：\"></a>常用命令：</h3><blockquote>\n<ul>\n<li>sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help index： 显示可用的命令</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。</li>\n</ul>\n</blockquote>\n<h3 id=\"在login-sql文件中修改配置\"><a href=\"#在login-sql文件中修改配置\" class=\"headerlink\" title=\"在login.sql文件中修改配置\"></a>在login.sql文件中修改配置</h3><blockquote>\n<p>在sql* plus启动时默认读取的两个文件，1.<strong>$ORACLE_HOME/sqlplus/admin</strong> 目录下的 <strong>glogin.sql</strong>和<strong>login.sql</strong> 文件。其中，<strong>login.sql</strong>中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。</p>\n</blockquote>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><blockquote>\n<p>在sql<em> plus中执行的是两种命令：<strong>sql语句</strong> 和 **SQL </em> Plus命令**</p>\n</blockquote>\n<blockquote>\n<p>SQL语句用<strong>；</strong> 和 <strong>/</strong> 结束输入</p>\n</blockquote>\n<ul>\n<li><ol>\n<li>可在命令后和另起一行使用；</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>/只能在下行中被识别。<blockquote>\n<p>sqlplus缓冲区<br>sqlplus执行 <em>.sql 文件方式：1.直接输入 </em>.sql,2.输入@或者START *，可以省略后缀。</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\"><a href=\"#五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\" class=\"headerlink\" title=\"五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\"></a>五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)</h3><h4 id=\"1-SELECT-语句\"><a href=\"#1-SELECT-语句\" class=\"headerlink\" title=\"1. SELECT 语句\"></a>1. SELECT 语句</h4><h5 id=\"Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\"><a href=\"#Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\" class=\"headerlink\" title=\"Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\"></a>Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。</h5><h5 id=\"select语句\"><a href=\"#select语句\" class=\"headerlink\" title=\"- select语句\"></a>- select语句</h5><blockquote>\n<p>处理过程中首先处理的是<strong>From</strong>子句，多个<strong>From</strong>则每个步骤想象成一个临时数据集，每经过一个<strong>FROM</strong>，则进行一步筛选，得最终结果数据集。</p>\n</blockquote>\n<h5 id=\"From子句\"><a href=\"#From子句\" class=\"headerlink\" title=\"- From子句\"></a>- From子句</h5><blockquote>\n<p>子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。</p>\n</blockquote>\n<h5 id=\"HAVING子句\"><a href=\"#HAVING子句\" class=\"headerlink\" title=\"- HAVING子句\"></a>- HAVING子句</h5><blockquote>\n<p>将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。</p>\n</blockquote>\n<h5 id=\"ORDER-BY子句\"><a href=\"#ORDER-BY子句\" class=\"headerlink\" title=\"- ORDER BY子句\"></a>- ORDER BY子句</h5><blockquote>\n<p>Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。</p>\n</blockquote>\n<h4 id=\"2-INSERT-语句\"><a href=\"#2-INSERT-语句\" class=\"headerlink\" title=\"2. INSERT 语句\"></a>2. INSERT 语句</h4><h5 id=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"><a href=\"#Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\" class=\"headerlink\" title=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"></a>Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。</h5><pre><code>INSERT ALL WHEN 条件1 THEN INTO table1\n           WHEN 条件2 THEN INTO table2\n           WHEN 条件3 THEN INTO table3\n            ...\n           SELECT ** FROM table4;\n</code></pre><blockquote>\n<p>当指定<strong>ALL</strong>时，这个语句就会执行无条件的多表插入，可以用<strong>FIRST</strong>替换，此时指定按照<strong>WHEN</strong>子句在语句中的顺序进行判断    。</p>\n</blockquote>\n<h4 id=\"3-UPDATE-语句\"><a href=\"#3-UPDATE-语句\" class=\"headerlink\" title=\"3. UPDATE 语句\"></a>3. UPDATE 语句</h4><h5 id=\"该语法由-UPDATE、SET、WHERE-组成\"><a href=\"#该语法由-UPDATE、SET、WHERE-组成\" class=\"headerlink\" title=\"该语法由 UPDATE、SET、WHERE 组成\"></a>该语法由 <strong>UPDATE、SET、WHERE</strong> 组成</h5><h4 id=\"4-DELETE-语句\"><a href=\"#4-DELETE-语句\" class=\"headerlink\" title=\"4. DELETE 语句\"></a>4. DELETE 语句</h4><h5 id=\"由-DELETE、WHERE、FROM-组成\"><a href=\"#由-DELETE、WHERE、FROM-组成\" class=\"headerlink\" title=\"由 DELETE、WHERE、FROM 组成\"></a>由 DELETE、WHERE、FROM 组成</h5><h4 id=\"5-MERGE-语句\"><a href=\"#5-MERGE-语句\" class=\"headerlink\" title=\"5. MERGE 语句\"></a>5. MERGE 语句</h4><h5 id=\"MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\"><a href=\"#MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\" class=\"headerlink\" title=\"MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\"></a>MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。</h5>"},{"title":"精通Oracle SQL（第二版）读书笔记  -  第二章 SQL执行","date":"2017-08-17T13:58:59.000Z","_content":"\n# 精通Oracle SQL（第二版）读书笔记\n## 第二章 SQL执行\n### 数据库和数据库文件、实例等概念\n> **数据库** 归属于 数据库文件\n\n> **实  例** 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。\n\n> **PGA** 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。\n\n> **SGA** 包含共享池（库高速缓存）、数据库高速缓存。\n\n### SGA\n###### 共享池\n1. 存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。\n2. Oracle 使用的系统参数，在一块被称为数据字典的区域。\n###### 高速缓存区域\n- 存储所有的数据库对象信息。\n\n###### 管理共享池：\n- 共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。\n\n### 执行SQL语句 \n\n![执行SQL语句](http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n### 绑定变量 \n-  在SQL语句中，有时使用**绑定变量**比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。\n\n>    SQL> varible v_dept number  #定义变量 v_dept 为 number 类型\n\t\n>\t SQL> exec : v_dept = 10\n\n>    SQL> SELECT * FROM employees WHERE departent_id = :v_dept;    \n### 锁存器\n- 锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。\n### 互斥锁\n- 一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：\n\n      **1.** 占内存少，且可快速获取和释放；\n\n      **2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n### SGA缓冲区缓存\n![SGA缓冲区缓存](http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- **块:** Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。\n\n- **缓冲区缓存**\n\n![SGA缓冲区缓存空间管理](http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- 刷新（清空）共享池和缓冲区缓存\n> SQL> alter system flush buffer_cache;\n\n> SQL> alter system flush shared_pool;\n\n- 硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。\n\n### 查询转换\n- 在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。\n- 查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。\n##### 查询块\n- 查询块可以由 Oracle 自动生成系统名称，也可以通过 **QB_NAME** 提示命名。\n- 可以在**V$SQL_PLAN**视图中查询所使用的查询块名称，即之前执行的 SQL 语句。\n##### 视图合并 —— 类型转换\n- 视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。\n- 阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）\n##### 子嵌套解嵌套—— 类型转换\n- 子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。\n##### 联结消除 —— 类型转换\n- Oracle 消除冗余表的两种情况\n  1. 存在主 —— 外键约束\n  2. 外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。\n- 如果一张表没有出现在执行计划中，就是发生了联结消除转换。\n- 限制\n  1. 如果在查询的任何地方引用了联结键，则不支持联结消除；\n  2. 如果主外键约束包含多个列，则不支持联结消除。\n##### 排序消除 —— 类型转换\n- 与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。\n- 优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。\n##### 谓词推进（谓语即所谓的条件）\n- 谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。\n- 如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。\n##### 使用物化视图进行查询重写\n- 查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。\n- 物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。\n\n##### 确定执行计划\n- 执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。\n","source":"_posts/2019-03-25-oracle-sql-seconds-notes-sec-2-sql-exec.md","raw":"---\ntitle: 精通Oracle SQL（第二版）读书笔记  -  第二章 SQL执行\ndate: 2017-08-17 13:58:59\ntags:\n  - Oracle\ncategories:\n  - Oracle\n---\n\n# 精通Oracle SQL（第二版）读书笔记\n## 第二章 SQL执行\n### 数据库和数据库文件、实例等概念\n> **数据库** 归属于 数据库文件\n\n> **实  例** 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。\n\n> **PGA** 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。\n\n> **SGA** 包含共享池（库高速缓存）、数据库高速缓存。\n\n### SGA\n###### 共享池\n1. 存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。\n2. Oracle 使用的系统参数，在一块被称为数据字典的区域。\n###### 高速缓存区域\n- 存储所有的数据库对象信息。\n\n###### 管理共享池：\n- 共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。\n\n### 执行SQL语句 \n\n![执行SQL语句](http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n### 绑定变量 \n-  在SQL语句中，有时使用**绑定变量**比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。\n\n>    SQL> varible v_dept number  #定义变量 v_dept 为 number 类型\n\t\n>\t SQL> exec : v_dept = 10\n\n>    SQL> SELECT * FROM employees WHERE departent_id = :v_dept;    \n### 锁存器\n- 锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。\n### 互斥锁\n- 一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：\n\n      **1.** 占内存少，且可快速获取和释放；\n\n      **2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n### SGA缓冲区缓存\n![SGA缓冲区缓存](http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- **块:** Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。\n\n- **缓冲区缓存**\n\n![SGA缓冲区缓存空间管理](http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- 刷新（清空）共享池和缓冲区缓存\n> SQL> alter system flush buffer_cache;\n\n> SQL> alter system flush shared_pool;\n\n- 硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。\n\n### 查询转换\n- 在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。\n- 查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。\n##### 查询块\n- 查询块可以由 Oracle 自动生成系统名称，也可以通过 **QB_NAME** 提示命名。\n- 可以在**V$SQL_PLAN**视图中查询所使用的查询块名称，即之前执行的 SQL 语句。\n##### 视图合并 —— 类型转换\n- 视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。\n- 阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）\n##### 子嵌套解嵌套—— 类型转换\n- 子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。\n##### 联结消除 —— 类型转换\n- Oracle 消除冗余表的两种情况\n  1. 存在主 —— 外键约束\n  2. 外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。\n- 如果一张表没有出现在执行计划中，就是发生了联结消除转换。\n- 限制\n  1. 如果在查询的任何地方引用了联结键，则不支持联结消除；\n  2. 如果主外键约束包含多个列，则不支持联结消除。\n##### 排序消除 —— 类型转换\n- 与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。\n- 优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。\n##### 谓词推进（谓语即所谓的条件）\n- 谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。\n- 如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。\n##### 使用物化视图进行查询重写\n- 查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。\n- 物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。\n\n##### 确定执行计划\n- 执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。\n","slug":"oracle-sql-seconds-notes-sec-2-sql-exec","published":1,"updated":"2019-03-25T06:00:05.626Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqlg000ihqxummhupr3v","content":"<h1 id=\"精通Oracle-SQL（第二版）读书笔记\"><a href=\"#精通Oracle-SQL（第二版）读书笔记\" class=\"headerlink\" title=\"精通Oracle SQL（第二版）读书笔记\"></a>精通Oracle SQL（第二版）读书笔记</h1><h2 id=\"第二章-SQL执行\"><a href=\"#第二章-SQL执行\" class=\"headerlink\" title=\"第二章 SQL执行\"></a>第二章 SQL执行</h2><h3 id=\"数据库和数据库文件、实例等概念\"><a href=\"#数据库和数据库文件、实例等概念\" class=\"headerlink\" title=\"数据库和数据库文件、实例等概念\"></a>数据库和数据库文件、实例等概念</h3><blockquote>\n<p><strong>数据库</strong> 归属于 数据库文件</p>\n</blockquote>\n<blockquote>\n<p><strong>实  例</strong> 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。</p>\n</blockquote>\n<blockquote>\n<p><strong>PGA</strong> 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。</p>\n</blockquote>\n<blockquote>\n<p><strong>SGA</strong> 包含共享池（库高速缓存）、数据库高速缓存。</p>\n</blockquote>\n<h3 id=\"SGA\"><a href=\"#SGA\" class=\"headerlink\" title=\"SGA\"></a>SGA</h3><h6 id=\"共享池\"><a href=\"#共享池\" class=\"headerlink\" title=\"共享池\"></a>共享池</h6><ol>\n<li>存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。</li>\n<li>Oracle 使用的系统参数，在一块被称为数据字典的区域。<h6 id=\"高速缓存区域\"><a href=\"#高速缓存区域\" class=\"headerlink\" title=\"高速缓存区域\"></a>高速缓存区域</h6></li>\n</ol>\n<ul>\n<li>存储所有的数据库对象信息。</li>\n</ul>\n<h6 id=\"管理共享池：\"><a href=\"#管理共享池：\" class=\"headerlink\" title=\"管理共享池：\"></a>管理共享池：</h6><ul>\n<li>共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。</li>\n</ul>\n<h3 id=\"执行SQL语句\"><a href=\"#执行SQL语句\" class=\"headerlink\" title=\"执行SQL语句\"></a>执行SQL语句</h3><p><img src=\"http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"执行SQL语句\"></p>\n<h3 id=\"绑定变量\"><a href=\"#绑定变量\" class=\"headerlink\" title=\"绑定变量\"></a>绑定变量</h3><ul>\n<li>在SQL语句中，有时使用<strong>绑定变量</strong>比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。</li>\n</ul>\n<blockquote>\n<p>   SQL&gt; varible v_dept number  #定义变量 v_dept 为 number 类型</p>\n</blockquote>\n<blockquote>\n<pre><code>SQL&gt; exec : v_dept = 10\n</code></pre></blockquote>\n<blockquote>\n<p>   SQL&gt; SELECT * FROM employees WHERE departent_id = :v_dept;    </p>\n</blockquote>\n<h3 id=\"锁存器\"><a href=\"#锁存器\" class=\"headerlink\" title=\"锁存器\"></a>锁存器</h3><ul>\n<li>锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。<h3 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h3></li>\n<li><p>一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：</p>\n<pre><code>**1.** 占内存少，且可快速获取和释放；\n\n**2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n</code></pre><h3 id=\"SGA缓冲区缓存\"><a href=\"#SGA缓冲区缓存\" class=\"headerlink\" title=\"SGA缓冲区缓存\"></a>SGA缓冲区缓存</h3><p><img src=\"http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存\"></p>\n</li>\n<li><p><strong>块:</strong> Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。</p>\n</li>\n<li><p><strong>缓冲区缓存</strong></p>\n</li>\n</ul>\n<p><img src=\"http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存空间管理\"></p>\n<ul>\n<li>刷新（清空）共享池和缓冲区缓存<blockquote>\n<p>SQL&gt; alter system flush buffer_cache;</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>SQL&gt; alter system flush shared_pool;</p>\n</blockquote>\n<ul>\n<li>硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。</li>\n</ul>\n<h3 id=\"查询转换\"><a href=\"#查询转换\" class=\"headerlink\" title=\"查询转换\"></a>查询转换</h3><ul>\n<li>在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。</li>\n<li>查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。<h5 id=\"查询块\"><a href=\"#查询块\" class=\"headerlink\" title=\"查询块\"></a>查询块</h5></li>\n<li>查询块可以由 Oracle 自动生成系统名称，也可以通过 <strong>QB_NAME</strong> 提示命名。</li>\n<li>可以在<strong>V$SQL_PLAN</strong>视图中查询所使用的查询块名称，即之前执行的 SQL 语句。<h5 id=\"视图合并-——-类型转换\"><a href=\"#视图合并-——-类型转换\" class=\"headerlink\" title=\"视图合并 —— 类型转换\"></a>视图合并 —— 类型转换</h5></li>\n<li>视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。</li>\n<li>阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）<h5 id=\"子嵌套解嵌套——-类型转换\"><a href=\"#子嵌套解嵌套——-类型转换\" class=\"headerlink\" title=\"子嵌套解嵌套—— 类型转换\"></a>子嵌套解嵌套—— 类型转换</h5></li>\n<li>子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。<h5 id=\"联结消除-——-类型转换\"><a href=\"#联结消除-——-类型转换\" class=\"headerlink\" title=\"联结消除 —— 类型转换\"></a>联结消除 —— 类型转换</h5></li>\n<li>Oracle 消除冗余表的两种情况<ol>\n<li>存在主 —— 外键约束</li>\n<li>外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。</li>\n</ol>\n</li>\n<li>如果一张表没有出现在执行计划中，就是发生了联结消除转换。</li>\n<li>限制<ol>\n<li>如果在查询的任何地方引用了联结键，则不支持联结消除；</li>\n<li>如果主外键约束包含多个列，则不支持联结消除。<h5 id=\"排序消除-——-类型转换\"><a href=\"#排序消除-——-类型转换\" class=\"headerlink\" title=\"排序消除 —— 类型转换\"></a>排序消除 —— 类型转换</h5></li>\n</ol>\n</li>\n<li>与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。</li>\n<li>优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。<h5 id=\"谓词推进（谓语即所谓的条件）\"><a href=\"#谓词推进（谓语即所谓的条件）\" class=\"headerlink\" title=\"谓词推进（谓语即所谓的条件）\"></a>谓词推进（谓语即所谓的条件）</h5></li>\n<li>谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。</li>\n<li>如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。<h5 id=\"使用物化视图进行查询重写\"><a href=\"#使用物化视图进行查询重写\" class=\"headerlink\" title=\"使用物化视图进行查询重写\"></a>使用物化视图进行查询重写</h5></li>\n<li>查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。</li>\n<li>物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。</li>\n</ul>\n<h5 id=\"确定执行计划\"><a href=\"#确定执行计划\" class=\"headerlink\" title=\"确定执行计划\"></a>确定执行计划</h5><ul>\n<li>执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"精通Oracle-SQL（第二版）读书笔记\"><a href=\"#精通Oracle-SQL（第二版）读书笔记\" class=\"headerlink\" title=\"精通Oracle SQL（第二版）读书笔记\"></a>精通Oracle SQL（第二版）读书笔记</h1><h2 id=\"第二章-SQL执行\"><a href=\"#第二章-SQL执行\" class=\"headerlink\" title=\"第二章 SQL执行\"></a>第二章 SQL执行</h2><h3 id=\"数据库和数据库文件、实例等概念\"><a href=\"#数据库和数据库文件、实例等概念\" class=\"headerlink\" title=\"数据库和数据库文件、实例等概念\"></a>数据库和数据库文件、实例等概念</h3><blockquote>\n<p><strong>数据库</strong> 归属于 数据库文件</p>\n</blockquote>\n<blockquote>\n<p><strong>实  例</strong> 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。</p>\n</blockquote>\n<blockquote>\n<p><strong>PGA</strong> 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。</p>\n</blockquote>\n<blockquote>\n<p><strong>SGA</strong> 包含共享池（库高速缓存）、数据库高速缓存。</p>\n</blockquote>\n<h3 id=\"SGA\"><a href=\"#SGA\" class=\"headerlink\" title=\"SGA\"></a>SGA</h3><h6 id=\"共享池\"><a href=\"#共享池\" class=\"headerlink\" title=\"共享池\"></a>共享池</h6><ol>\n<li>存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。</li>\n<li>Oracle 使用的系统参数，在一块被称为数据字典的区域。<h6 id=\"高速缓存区域\"><a href=\"#高速缓存区域\" class=\"headerlink\" title=\"高速缓存区域\"></a>高速缓存区域</h6></li>\n</ol>\n<ul>\n<li>存储所有的数据库对象信息。</li>\n</ul>\n<h6 id=\"管理共享池：\"><a href=\"#管理共享池：\" class=\"headerlink\" title=\"管理共享池：\"></a>管理共享池：</h6><ul>\n<li>共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。</li>\n</ul>\n<h3 id=\"执行SQL语句\"><a href=\"#执行SQL语句\" class=\"headerlink\" title=\"执行SQL语句\"></a>执行SQL语句</h3><p><img src=\"http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"执行SQL语句\"></p>\n<h3 id=\"绑定变量\"><a href=\"#绑定变量\" class=\"headerlink\" title=\"绑定变量\"></a>绑定变量</h3><ul>\n<li>在SQL语句中，有时使用<strong>绑定变量</strong>比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。</li>\n</ul>\n<blockquote>\n<p>   SQL&gt; varible v_dept number  #定义变量 v_dept 为 number 类型</p>\n</blockquote>\n<blockquote>\n<pre><code>SQL&gt; exec : v_dept = 10\n</code></pre></blockquote>\n<blockquote>\n<p>   SQL&gt; SELECT * FROM employees WHERE departent_id = :v_dept;    </p>\n</blockquote>\n<h3 id=\"锁存器\"><a href=\"#锁存器\" class=\"headerlink\" title=\"锁存器\"></a>锁存器</h3><ul>\n<li>锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。<h3 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h3></li>\n<li><p>一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：</p>\n<pre><code>**1.** 占内存少，且可快速获取和释放；\n\n**2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n</code></pre><h3 id=\"SGA缓冲区缓存\"><a href=\"#SGA缓冲区缓存\" class=\"headerlink\" title=\"SGA缓冲区缓存\"></a>SGA缓冲区缓存</h3><p><img src=\"http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存\"></p>\n</li>\n<li><p><strong>块:</strong> Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。</p>\n</li>\n<li><p><strong>缓冲区缓存</strong></p>\n</li>\n</ul>\n<p><img src=\"http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存空间管理\"></p>\n<ul>\n<li>刷新（清空）共享池和缓冲区缓存<blockquote>\n<p>SQL&gt; alter system flush buffer_cache;</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>SQL&gt; alter system flush shared_pool;</p>\n</blockquote>\n<ul>\n<li>硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。</li>\n</ul>\n<h3 id=\"查询转换\"><a href=\"#查询转换\" class=\"headerlink\" title=\"查询转换\"></a>查询转换</h3><ul>\n<li>在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。</li>\n<li>查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。<h5 id=\"查询块\"><a href=\"#查询块\" class=\"headerlink\" title=\"查询块\"></a>查询块</h5></li>\n<li>查询块可以由 Oracle 自动生成系统名称，也可以通过 <strong>QB_NAME</strong> 提示命名。</li>\n<li>可以在<strong>V$SQL_PLAN</strong>视图中查询所使用的查询块名称，即之前执行的 SQL 语句。<h5 id=\"视图合并-——-类型转换\"><a href=\"#视图合并-——-类型转换\" class=\"headerlink\" title=\"视图合并 —— 类型转换\"></a>视图合并 —— 类型转换</h5></li>\n<li>视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。</li>\n<li>阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）<h5 id=\"子嵌套解嵌套——-类型转换\"><a href=\"#子嵌套解嵌套——-类型转换\" class=\"headerlink\" title=\"子嵌套解嵌套—— 类型转换\"></a>子嵌套解嵌套—— 类型转换</h5></li>\n<li>子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。<h5 id=\"联结消除-——-类型转换\"><a href=\"#联结消除-——-类型转换\" class=\"headerlink\" title=\"联结消除 —— 类型转换\"></a>联结消除 —— 类型转换</h5></li>\n<li>Oracle 消除冗余表的两种情况<ol>\n<li>存在主 —— 外键约束</li>\n<li>外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。</li>\n</ol>\n</li>\n<li>如果一张表没有出现在执行计划中，就是发生了联结消除转换。</li>\n<li>限制<ol>\n<li>如果在查询的任何地方引用了联结键，则不支持联结消除；</li>\n<li>如果主外键约束包含多个列，则不支持联结消除。<h5 id=\"排序消除-——-类型转换\"><a href=\"#排序消除-——-类型转换\" class=\"headerlink\" title=\"排序消除 —— 类型转换\"></a>排序消除 —— 类型转换</h5></li>\n</ol>\n</li>\n<li>与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。</li>\n<li>优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。<h5 id=\"谓词推进（谓语即所谓的条件）\"><a href=\"#谓词推进（谓语即所谓的条件）\" class=\"headerlink\" title=\"谓词推进（谓语即所谓的条件）\"></a>谓词推进（谓语即所谓的条件）</h5></li>\n<li>谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。</li>\n<li>如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。<h5 id=\"使用物化视图进行查询重写\"><a href=\"#使用物化视图进行查询重写\" class=\"headerlink\" title=\"使用物化视图进行查询重写\"></a>使用物化视图进行查询重写</h5></li>\n<li>查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。</li>\n<li>物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。</li>\n</ul>\n<h5 id=\"确定执行计划\"><a href=\"#确定执行计划\" class=\"headerlink\" title=\"确定执行计划\"></a>确定执行计划</h5><ul>\n<li>执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。</li>\n</ul>\n"},{"title":"Centos搭建Docker私有仓库, Registry","date":"2018-09-13T13:47:14.000Z","author":"weshzhu","_content":"\n\n关于docker的安装：\n[CENTOS7二进制安装DOCKER-CE](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/)\n[CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速](http://www.weshzhu.com/2019/03/25/install-docker-yum/)\n\n1. 覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （**对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库**）\n\tcp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\n\n2. 修改openssl.cnf文件\n\tvi /etc/pki/tls/openssl.cnf\n\t在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11\n\t\n3. openssl生成私有证书\n\topenssl req [-subj \"/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11\"] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\topenssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\t\n4. 将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书\n\tcat /certs/registry.crt >> /etc/pki/tls/certs/ca-bundle.crt\n\t\n5. 重启docker\n\tsystemctl restart docker\n\n6. 运行registry\n\tdocker run -d -p 443:443 --name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2\n\t\n7. push镜像到registry\n\tdocker push 192.168.0.11/nginx\n\t常见错误\n\ta. Get https://192.168.0.11/v2/: x509: cannot validate certificate for 192.168.0.11 because it doesn't contain any IP SANs  未操作第4步\n\tb. Get https://<IpAddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步\n\n具体教程可参考[x509: cannot validate certificate because of not containing any IP SANs](http://blog.csdn.net/zsd498537806/article/details/79290732)\n","source":"_posts/2019-03-25-private-registry-docker.md","raw":"---\ntitle: Centos搭建Docker私有仓库, Registry\ndate: 2018-09-13 13:47:14\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\nauthor: weshzhu\n\n---\n\n\n关于docker的安装：\n[CENTOS7二进制安装DOCKER-CE](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/)\n[CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速](http://www.weshzhu.com/2019/03/25/install-docker-yum/)\n\n1. 覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （**对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库**）\n\tcp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\n\n2. 修改openssl.cnf文件\n\tvi /etc/pki/tls/openssl.cnf\n\t在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11\n\t\n3. openssl生成私有证书\n\topenssl req [-subj \"/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11\"] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\topenssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\t\n4. 将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书\n\tcat /certs/registry.crt >> /etc/pki/tls/certs/ca-bundle.crt\n\t\n5. 重启docker\n\tsystemctl restart docker\n\n6. 运行registry\n\tdocker run -d -p 443:443 --name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2\n\t\n7. push镜像到registry\n\tdocker push 192.168.0.11/nginx\n\t常见错误\n\ta. Get https://192.168.0.11/v2/: x509: cannot validate certificate for 192.168.0.11 because it doesn't contain any IP SANs  未操作第4步\n\tb. Get https://<IpAddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步\n\n具体教程可参考[x509: cannot validate certificate because of not containing any IP SANs](http://blog.csdn.net/zsd498537806/article/details/79290732)\n","slug":"private-registry-docker","published":1,"updated":"2019-03-25T05:50:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqlh000khqxuzvx9rcd4","content":"<p>关于docker的安装：<br><a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">CENTOS7二进制安装DOCKER-CE</a><br><a href=\"http://www.weshzhu.com/2019/03/25/install-docker-yum/\" target=\"_blank\" rel=\"noopener\">CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速</a></p>\n<ol>\n<li><p>覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （<strong>对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库</strong>）<br> cp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem</p>\n</li>\n<li><p>修改openssl.cnf文件<br> vi /etc/pki/tls/openssl.cnf<br> 在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11</p>\n</li>\n<li><p>openssl生成私有证书<br> openssl req [-subj “/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11”] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt<br> openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt</p>\n</li>\n<li><p>将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书<br> cat /certs/registry.crt &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt</p>\n</li>\n<li><p>重启docker<br> systemctl restart docker</p>\n</li>\n<li><p>运行registry<br> docker run -d -p 443:443 –name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2</p>\n</li>\n<li><p>push镜像到registry<br> docker push 192.168.0.11/nginx<br> 常见错误<br> a. Get <a href=\"https://192.168.0.11/v2/\" target=\"_blank\" rel=\"noopener\">https://192.168.0.11/v2/</a>: x509: cannot validate certificate for 192.168.0.11 because it doesn’t contain any IP SANs  未操作第4步<br> b. Get https://<ipaddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步</ipaddress></p>\n</li>\n</ol>\n<p>具体教程可参考<a href=\"http://blog.csdn.net/zsd498537806/article/details/79290732\" target=\"_blank\" rel=\"noopener\">x509: cannot validate certificate because of not containing any IP SANs</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>关于docker的安装：<br><a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">CENTOS7二进制安装DOCKER-CE</a><br><a href=\"http://www.weshzhu.com/2019/03/25/install-docker-yum/\" target=\"_blank\" rel=\"noopener\">CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速</a></p>\n<ol>\n<li><p>覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （<strong>对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库</strong>）<br> cp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem</p>\n</li>\n<li><p>修改openssl.cnf文件<br> vi /etc/pki/tls/openssl.cnf<br> 在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11</p>\n</li>\n<li><p>openssl生成私有证书<br> openssl req [-subj “/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11”] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt<br> openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt</p>\n</li>\n<li><p>将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书<br> cat /certs/registry.crt &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt</p>\n</li>\n<li><p>重启docker<br> systemctl restart docker</p>\n</li>\n<li><p>运行registry<br> docker run -d -p 443:443 –name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2</p>\n</li>\n<li><p>push镜像到registry<br> docker push 192.168.0.11/nginx<br> 常见错误<br> a. Get <a href=\"https://192.168.0.11/v2/\" target=\"_blank\" rel=\"noopener\">https://192.168.0.11/v2/</a>: x509: cannot validate certificate for 192.168.0.11 because it doesn’t contain any IP SANs  未操作第4步<br> b. Get https://<ipaddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步</ipaddress></p>\n</li>\n</ol>\n<p>具体教程可参考<a href=\"http://blog.csdn.net/zsd498537806/article/details/79290732\" target=\"_blank\" rel=\"noopener\">x509: cannot validate certificate because of not containing any IP SANs</a></p>\n"},{"title":"docker网络驱动之--overlay网络","date":"2019-03-21T20:23:46.000Z","_content":"\n\n\n>`docker overlay`网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将`swarm`集群服务和`containers`容器与`overlay`网络进行连接，使各个服务或者服务与容器之间进行通信。\n\n#### 创建或加入`swarm`服务\n\n在创建和使用`overlay`之前，必须初始化一个[`swarm`](https://docs.docker.com/engine/swarm/)或者加入某个`swarm`:\n\n- 创建一个`swarm`集群服务\n\n  用法：`docker swarm init [OPTIONS]`，针对常用的`[OPTIONS]`介绍见下方表格：\n  \n  参数说明\n\n  |参数|类型|默认值|说明|\n  |-----|-----|-----|-----|\n  |`--advertise-addr`| string ||多块网卡时对应多个IP地址时，需要指定|\n  |`--data-path-addr`|string||用于数据流量传输的IP地址或者网卡名称（例：`eth0`）|\n  |`--listen-addr`|node-addr|0.0.0.0:2377|监听地址|\n\n\n  **示例：创建`swarm`服务**\n \n  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：\n\n   ```\n   node1 : 192.168.0.190  (manager & worker)\n   node2 : 192.168.0.191 (worker)\n   ```\n   \n   ![swarm架构](/images/swarmcluster.png)\n   \n   - 创建`swarm`集群服务\n\n     ```\n     $ docker swarm init --advertise-addr 192.168.0.190\n     Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.\n     To add a worker to this swarm, run the following      command:\n       docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377\n     To add a manager to this swarm, run 'docker swarm      join-tokenmanager' and follow the instructions.\n   \n     ```\n \n     注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n \n     ```\n     docker swarm join --token xxxx <manager-ip>:<port>\n     ```\n     \n     可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n   \n     查看docker网络\n   \n     ```\n     $docker network ls\n     NETWORK ID          NAME                DRIVER                 SCOPE\n     ba18dbad1160        bridge              bridge                 local\n     58886c346808        docker_gwbridge     bridge                 local\n     7966432ad37e        host                host                   local\n     yryhkokko1tk        ingress             overlay                swarm\n     d1ab833f3555        none                null                   local\n     ```\n \n     可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n   \n     - `ingress`\n\n       一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n       使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n     \n       ```\n       $ docker inspect ingress\n       [\n           {\n               \"Name\": \"ingress\",\n               \"Id\": \"yryhkokko1tkpkhx0pf0e1zm3\",\n               \"Created\": \"2019-01-08T17:05:50.511486192+08:00\",\n               \"Scope\": \"swarm\",\n               \"Driver\": \"overlay\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"10.255.0.0/16\",\n                           \"Gateway\": \"10.255.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": true,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"ingress-endpoint\",\n                       \"EndpointID\": \"75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb\",\n                       \"MacAddress\": \"02:42:0a:ff:00:03\",\n                       \"IPv4Address\": \"10.255.0.3/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.driver.overlay.vxlanid_list\": \"4096\"\n               },\n               \"Labels\": {},\n               \"Peers\": [\n                   {\n                       \"Name\": \"5e8427535708\",\n                       \"IP\": \"192.168.0.190\"\n                   },\n                   {\n                       \"Name\": \"42c5607b0c46\",\n                       \"IP\": \"192.168.0.191\"\n                   }\n               ]\n           }\n       ]\n       ```\n\n     - `docker_gwbridge`\n\n       一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n     \n       ```\n       $ docker inspect docker_gwbridge\n       [\n           {\n               \"Name\": \"docker_gwbridge\",\n               \"Id\": \"2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4\",\n               \"Created\": \"2019-01-08T17:05:51.263715613+08:00\",\n               \"Scope\": \"local\",\n               \"Driver\": \"bridge\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"172.18.0.0/16\",\n                           \"Gateway\": \"172.18.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": false,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"gateway_ingress-sbox\",\n                       \"EndpointID\": \"4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af\",\n                       \"MacAddress\": \"02:42:ac:12:00:02\",\n                       \"IPv4Address\": \"172.18.0.2/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.bridge.enable_icc\": \"false\",\n                   \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n                   \"com.docker.network.bridge.name\": \"docker_gwbridge\"\n               },\n               \"Labels\": {}\n           }\n       ]\n       ```\n\n- 增加工作（`worker`）节点\n   \n    将node2(192.168.0.191)加入到该`swarm`：\n\n    ```\n    $ docker swarm join --token \\\n      SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\\n      192.168.0.190:2377\n\n      This node joined a swarm as a worker.\n    ```\n\n    查看node\n\n    ```\n    $ docker node ls\n      ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\n      se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce\n      timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce\n    ```\n   \n     查看**工作节点**的docker网络\n   \n     ```\n     $ docker network ls \n       NETWORK ID          NAME                DRIVER                    SCOPE\n       e39a5d50e807        bridge              bridge                    local\n       2c7254c25f76        docker_gwbridge     bridge                    local\n       a284efd6e1f2        host                host                      local\n       yryhkokko1tk        ingress             overlay                   swarm\n       13bd88a34632        none                null                  local\n     ```\n\n#### `overlay`网络\n \n - 创建`overlay`网络\n\n   在创建`overlay`网络前，需要初始化或者加入`swarm`服务。即使可能后续不会使用`swarm`服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。\n\n   要创建用于swarm服务的覆盖网络，请使用如下命令：\n   \n   ```\n   $ docker network create -d overlay my-overlay\n   ```\n\n   要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的`overlay`网络，必须添加`--attachable`标志：\n\n   ```\n   $ docker network create -d overlay --attachable my-attachable-overlay\n   ```\n\n   在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create --help\n  \n - `overlay`网络流量加密（不支持windows操作系统）\n   \n   在`swarm`服务中的管理流量默认是通过`GCM-AES`加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加`--opt encrypted`属性，Docker会在各个工作节点之间建立`IPSEC`隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。\n\n\n - 自定义默认`ingress`\n\n   Docker 17.05之后的版本，才支持用户修改默认`ingress`网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他`low-level`底层网络设置（如MTU），则此功能非常有用。\n\n   - 创建`ingress`网络\n\n     使用--ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。\n\n     ```\n     $ docker network create \\\n       --driver overlay \\\n       --ingress \\\n       --subnet=10.11.0.0/16 \\\n       --gateway=10.11.0.2 \\\n       --opt com.docker.network.driver.mtu=1200 \\\n       my-ingress\n     ```\n     注意：您可以对`ingress`网络重新命名，但您只能拥有一个`ingress`网络。\n\n   - 删除`ingress`网络\n\n     如果现有服务有发布端口，则需要先删除这些服务，然后才能删除`ingress`网络。\n\n     ```\n     $ docker network rm ingress\n \n       WARNING! Before removing the routing-mesh   network, make sure all the nodes\n       in your swarm run the same docker engine   version. Otherwise, removal may not\n       be effective and functionality of newly created   ingress networks will be\n       impaired.\n       Are you sure you want to continue? [y/N]\n     ```\n\n- 自定义`docker_gwbridge`\n\n  `docker_gwbridge`是一个虚拟网桥，将覆盖网络（包括`ingress`网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。\n\n  ```\n  $ ip addr | grep docker_gwbridge\n    docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP>   mtu 1500 qdisc noqueue state UP \n      inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge\n  ```\n  \n  1. Stop Docker service\n     \n     ```\n     $ systemctl stop docker\n     ```\n  \n  2. 删除`docker_gwbridge`网桥\n  \n     ```\n     $ ip link set  docker_gwbridge down\n     $ ip link del dev docker_gwbridge\n     ```\n  3. 启动Docker，但是不要初始化`swarm`或者加入任何`swarm`  服务网络\n  \n     ```\n     $ systemctl start docker\n     ```\n  4. 使用`docker network create`命令，使用自定义设置手动  创建或重新创建`docker_gwbridge`桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (https://docs.docker.com/engine/reference/commandline/  network_create/#bridge-driver-options)。\n     \n     ```\n     $ docker network create  \\\n       --subnet 10.11.0.0/16 \\\n       --opt    com.docker.network.bridge.name=docker_gwbridge \\\n       --opt com.docker.network.bridge.enable_icc=false  \\\n       --opt    com.docker.network.bridge.enable_ip_masquerade=true \\\n       docker_gwbridge\n     ```\n  5. 初始化或加入`swarm`服务集群。由`docker_gwbridge`网桥已经存在，初始化时Docker不再创建它。\n\n#### 创建用于`swarm`服务的`overlay`网络\n\n- 在`overlay`网络上，暴露服务端口号\n\n  连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用`docker service create`或`docker service update`上的`-p`或`--publish`参数发布端口。\n\n  ```\n  $ docker service create \n  ```\n\n  默认情况下，发布端口的`swarm`服务使用路由网格(`routing mesh`)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。\n\n- `swram`服务区（`swarm service`）绕过网格路由（`routing mesh`）\n\n  默认情况下，发布端口的`swarm`服务使用路由网格来实现负载均衡。 当您连接到任意一个`swarm`节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的`worker`节点上。实际上，Docker充当您的群服务的负载均衡器（`load balancer`）。 默认情况下，使用`routing mesh`的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过`--mode global`）也使用路由网格。使用`routing mesh`时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将`--endpoint-mode`标志设置为`dnsrr`。若使用`dnsrr`，需要在服务前运行自己的负载均衡器（常用的：有`nginx`、`HAproxy`）。通过DNS查询返回运行在`swarm`集群服务的所有节点的IP地址列表。\n  \n  >`routing mesh` 将外部请求路由到不同主机的容器，从而实现了外部网络对 `service` 的访问。\n\n- 分离控制流量和数据流量\n  \n  默认情况下，与`swarm`管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入`swarm`时，每个节点（管理节点和工作节点）需要分别指定`--advertise-addr`和`--data-path-addr`。\n\n#### 创建用于独立容器使用的`overlay`网络\n\n- 将独立容器连接到覆盖网络\n\n  在创建`ingress`网络时，若未指定`--attachable`（比如初始化`swarm`服务，或加入`swarm`时默认创建的`ingress`）意味着只有`swarm`服务可以使用它，独立运行的容器无法使用`ingress`。您可以将独立容器连接到使用--attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。\n\n\n- 容器发现\n\n  在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用`DNS lookup` 查找`tasks.<service-name>`\n\n\n","source":"_posts/2019-03-21-docker-network-overlay.md","raw":"---\ntitle: docker网络驱动之--overlay网络\ndate: 2019-03-21 20:23:46\ntags: \n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\n\n\n>`docker overlay`网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将`swarm`集群服务和`containers`容器与`overlay`网络进行连接，使各个服务或者服务与容器之间进行通信。\n\n#### 创建或加入`swarm`服务\n\n在创建和使用`overlay`之前，必须初始化一个[`swarm`](https://docs.docker.com/engine/swarm/)或者加入某个`swarm`:\n\n- 创建一个`swarm`集群服务\n\n  用法：`docker swarm init [OPTIONS]`，针对常用的`[OPTIONS]`介绍见下方表格：\n  \n  参数说明\n\n  |参数|类型|默认值|说明|\n  |-----|-----|-----|-----|\n  |`--advertise-addr`| string ||多块网卡时对应多个IP地址时，需要指定|\n  |`--data-path-addr`|string||用于数据流量传输的IP地址或者网卡名称（例：`eth0`）|\n  |`--listen-addr`|node-addr|0.0.0.0:2377|监听地址|\n\n\n  **示例：创建`swarm`服务**\n \n  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：\n\n   ```\n   node1 : 192.168.0.190  (manager & worker)\n   node2 : 192.168.0.191 (worker)\n   ```\n   \n   ![swarm架构](/images/swarmcluster.png)\n   \n   - 创建`swarm`集群服务\n\n     ```\n     $ docker swarm init --advertise-addr 192.168.0.190\n     Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.\n     To add a worker to this swarm, run the following      command:\n       docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377\n     To add a manager to this swarm, run 'docker swarm      join-tokenmanager' and follow the instructions.\n   \n     ```\n \n     注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n \n     ```\n     docker swarm join --token xxxx <manager-ip>:<port>\n     ```\n     \n     可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n   \n     查看docker网络\n   \n     ```\n     $docker network ls\n     NETWORK ID          NAME                DRIVER                 SCOPE\n     ba18dbad1160        bridge              bridge                 local\n     58886c346808        docker_gwbridge     bridge                 local\n     7966432ad37e        host                host                   local\n     yryhkokko1tk        ingress             overlay                swarm\n     d1ab833f3555        none                null                   local\n     ```\n \n     可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n   \n     - `ingress`\n\n       一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n       使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n     \n       ```\n       $ docker inspect ingress\n       [\n           {\n               \"Name\": \"ingress\",\n               \"Id\": \"yryhkokko1tkpkhx0pf0e1zm3\",\n               \"Created\": \"2019-01-08T17:05:50.511486192+08:00\",\n               \"Scope\": \"swarm\",\n               \"Driver\": \"overlay\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"10.255.0.0/16\",\n                           \"Gateway\": \"10.255.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": true,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"ingress-endpoint\",\n                       \"EndpointID\": \"75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb\",\n                       \"MacAddress\": \"02:42:0a:ff:00:03\",\n                       \"IPv4Address\": \"10.255.0.3/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.driver.overlay.vxlanid_list\": \"4096\"\n               },\n               \"Labels\": {},\n               \"Peers\": [\n                   {\n                       \"Name\": \"5e8427535708\",\n                       \"IP\": \"192.168.0.190\"\n                   },\n                   {\n                       \"Name\": \"42c5607b0c46\",\n                       \"IP\": \"192.168.0.191\"\n                   }\n               ]\n           }\n       ]\n       ```\n\n     - `docker_gwbridge`\n\n       一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n     \n       ```\n       $ docker inspect docker_gwbridge\n       [\n           {\n               \"Name\": \"docker_gwbridge\",\n               \"Id\": \"2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4\",\n               \"Created\": \"2019-01-08T17:05:51.263715613+08:00\",\n               \"Scope\": \"local\",\n               \"Driver\": \"bridge\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"172.18.0.0/16\",\n                           \"Gateway\": \"172.18.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": false,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"gateway_ingress-sbox\",\n                       \"EndpointID\": \"4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af\",\n                       \"MacAddress\": \"02:42:ac:12:00:02\",\n                       \"IPv4Address\": \"172.18.0.2/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.bridge.enable_icc\": \"false\",\n                   \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n                   \"com.docker.network.bridge.name\": \"docker_gwbridge\"\n               },\n               \"Labels\": {}\n           }\n       ]\n       ```\n\n- 增加工作（`worker`）节点\n   \n    将node2(192.168.0.191)加入到该`swarm`：\n\n    ```\n    $ docker swarm join --token \\\n      SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\\n      192.168.0.190:2377\n\n      This node joined a swarm as a worker.\n    ```\n\n    查看node\n\n    ```\n    $ docker node ls\n      ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\n      se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce\n      timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce\n    ```\n   \n     查看**工作节点**的docker网络\n   \n     ```\n     $ docker network ls \n       NETWORK ID          NAME                DRIVER                    SCOPE\n       e39a5d50e807        bridge              bridge                    local\n       2c7254c25f76        docker_gwbridge     bridge                    local\n       a284efd6e1f2        host                host                      local\n       yryhkokko1tk        ingress             overlay                   swarm\n       13bd88a34632        none                null                  local\n     ```\n\n#### `overlay`网络\n \n - 创建`overlay`网络\n\n   在创建`overlay`网络前，需要初始化或者加入`swarm`服务。即使可能后续不会使用`swarm`服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。\n\n   要创建用于swarm服务的覆盖网络，请使用如下命令：\n   \n   ```\n   $ docker network create -d overlay my-overlay\n   ```\n\n   要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的`overlay`网络，必须添加`--attachable`标志：\n\n   ```\n   $ docker network create -d overlay --attachable my-attachable-overlay\n   ```\n\n   在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create --help\n  \n - `overlay`网络流量加密（不支持windows操作系统）\n   \n   在`swarm`服务中的管理流量默认是通过`GCM-AES`加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加`--opt encrypted`属性，Docker会在各个工作节点之间建立`IPSEC`隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。\n\n\n - 自定义默认`ingress`\n\n   Docker 17.05之后的版本，才支持用户修改默认`ingress`网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他`low-level`底层网络设置（如MTU），则此功能非常有用。\n\n   - 创建`ingress`网络\n\n     使用--ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。\n\n     ```\n     $ docker network create \\\n       --driver overlay \\\n       --ingress \\\n       --subnet=10.11.0.0/16 \\\n       --gateway=10.11.0.2 \\\n       --opt com.docker.network.driver.mtu=1200 \\\n       my-ingress\n     ```\n     注意：您可以对`ingress`网络重新命名，但您只能拥有一个`ingress`网络。\n\n   - 删除`ingress`网络\n\n     如果现有服务有发布端口，则需要先删除这些服务，然后才能删除`ingress`网络。\n\n     ```\n     $ docker network rm ingress\n \n       WARNING! Before removing the routing-mesh   network, make sure all the nodes\n       in your swarm run the same docker engine   version. Otherwise, removal may not\n       be effective and functionality of newly created   ingress networks will be\n       impaired.\n       Are you sure you want to continue? [y/N]\n     ```\n\n- 自定义`docker_gwbridge`\n\n  `docker_gwbridge`是一个虚拟网桥，将覆盖网络（包括`ingress`网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。\n\n  ```\n  $ ip addr | grep docker_gwbridge\n    docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP>   mtu 1500 qdisc noqueue state UP \n      inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge\n  ```\n  \n  1. Stop Docker service\n     \n     ```\n     $ systemctl stop docker\n     ```\n  \n  2. 删除`docker_gwbridge`网桥\n  \n     ```\n     $ ip link set  docker_gwbridge down\n     $ ip link del dev docker_gwbridge\n     ```\n  3. 启动Docker，但是不要初始化`swarm`或者加入任何`swarm`  服务网络\n  \n     ```\n     $ systemctl start docker\n     ```\n  4. 使用`docker network create`命令，使用自定义设置手动  创建或重新创建`docker_gwbridge`桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (https://docs.docker.com/engine/reference/commandline/  network_create/#bridge-driver-options)。\n     \n     ```\n     $ docker network create  \\\n       --subnet 10.11.0.0/16 \\\n       --opt    com.docker.network.bridge.name=docker_gwbridge \\\n       --opt com.docker.network.bridge.enable_icc=false  \\\n       --opt    com.docker.network.bridge.enable_ip_masquerade=true \\\n       docker_gwbridge\n     ```\n  5. 初始化或加入`swarm`服务集群。由`docker_gwbridge`网桥已经存在，初始化时Docker不再创建它。\n\n#### 创建用于`swarm`服务的`overlay`网络\n\n- 在`overlay`网络上，暴露服务端口号\n\n  连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用`docker service create`或`docker service update`上的`-p`或`--publish`参数发布端口。\n\n  ```\n  $ docker service create \n  ```\n\n  默认情况下，发布端口的`swarm`服务使用路由网格(`routing mesh`)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。\n\n- `swram`服务区（`swarm service`）绕过网格路由（`routing mesh`）\n\n  默认情况下，发布端口的`swarm`服务使用路由网格来实现负载均衡。 当您连接到任意一个`swarm`节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的`worker`节点上。实际上，Docker充当您的群服务的负载均衡器（`load balancer`）。 默认情况下，使用`routing mesh`的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过`--mode global`）也使用路由网格。使用`routing mesh`时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将`--endpoint-mode`标志设置为`dnsrr`。若使用`dnsrr`，需要在服务前运行自己的负载均衡器（常用的：有`nginx`、`HAproxy`）。通过DNS查询返回运行在`swarm`集群服务的所有节点的IP地址列表。\n  \n  >`routing mesh` 将外部请求路由到不同主机的容器，从而实现了外部网络对 `service` 的访问。\n\n- 分离控制流量和数据流量\n  \n  默认情况下，与`swarm`管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入`swarm`时，每个节点（管理节点和工作节点）需要分别指定`--advertise-addr`和`--data-path-addr`。\n\n#### 创建用于独立容器使用的`overlay`网络\n\n- 将独立容器连接到覆盖网络\n\n  在创建`ingress`网络时，若未指定`--attachable`（比如初始化`swarm`服务，或加入`swarm`时默认创建的`ingress`）意味着只有`swarm`服务可以使用它，独立运行的容器无法使用`ingress`。您可以将独立容器连接到使用--attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。\n\n\n- 容器发现\n\n  在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用`DNS lookup` 查找`tasks.<service-name>`\n\n\n","slug":"docker-network-overlay","published":1,"updated":"2019-03-21T12:25:46.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqsz001jhqxu71qp5kel","content":"<blockquote>\n<p><code>docker overlay</code>网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将<code>swarm</code>集群服务和<code>containers</code>容器与<code>overlay</code>网络进行连接，使各个服务或者服务与容器之间进行通信。</p>\n</blockquote>\n<h4 id=\"创建或加入swarm服务\"><a href=\"#创建或加入swarm服务\" class=\"headerlink\" title=\"创建或加入swarm服务\"></a>创建或加入<code>swarm</code>服务</h4><p>在创建和使用<code>overlay</code>之前，必须初始化一个<a href=\"https://docs.docker.com/engine/swarm/\" target=\"_blank\" rel=\"noopener\"><code>swarm</code></a>或者加入某个<code>swarm</code>:</p>\n<ul>\n<li><p>创建一个<code>swarm</code>集群服务</p>\n<p>用法：<code>docker swarm init [OPTIONS]</code>，针对常用的<code>[OPTIONS]</code>介绍见下方表格：</p>\n<p>参数说明</p>\n<p>|参数|类型|默认值|说明|<br>|—–|—–|—–|—–|<br>|<code>--advertise-addr</code>| string ||多块网卡时对应多个IP地址时，需要指定|<br>|<code>--data-path-addr</code>|string||用于数据流量传输的IP地址或者网卡名称（例：<code>eth0</code>）|<br>|<code>--listen-addr</code>|node-addr|0.0.0.0:2377|监听地址|</p>\n</li>\n</ul>\n<p>  <strong>示例：创建<code>swarm</code>服务</strong></p>\n<p>  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：</p>\n   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1 : 192.168.0.190  (manager &amp; worker)</span><br><span class=\"line\">node2 : 192.168.0.191 (worker)</span><br></pre></td></tr></table></figure>\n<p>   <img src=\"/images/swarmcluster.png\" alt=\"swarm架构\"></p>\n<ul>\n<li><p>创建<code>swarm</code>集群服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm init --advertise-addr 192.168.0.190</span><br><span class=\"line\">Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.</span><br><span class=\"line\">To add a worker to this swarm, run the following      command:</span><br><span class=\"line\">  docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377</span><br><span class=\"line\">To add a manager to this swarm, run &apos;docker swarm      join-tokenmanager&apos; and follow the instructions.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker swarm join --token xxxx &lt;manager-ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>\n\n\n可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n\n查看docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER                 SCOPE</span><br><span class=\"line\">ba18dbad1160        bridge              bridge                 local</span><br><span class=\"line\">58886c346808        docker_gwbridge     bridge                 local</span><br><span class=\"line\">7966432ad37e        host                host                   local</span><br><span class=\"line\">yryhkokko1tk        ingress             overlay                swarm</span><br><span class=\"line\">d1ab833f3555        none                null                   local</span><br></pre></td></tr></table></figure>\n\n\n可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n\n- `ingress`\n\n  一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n  使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect ingress</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;ingress&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;yryhkokko1tkpkhx0pf0e1zm3&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:50.511486192+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;swarm&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;overlay&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;10.255.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;10.255.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: true,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;ingress-endpoint&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:0a:ff:00:03&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;10.255.0.3/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4096&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Peers&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;5e8427535708&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.190&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;42c5607b0c46&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.191&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n- `docker_gwbridge`\n\n  一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect docker_gwbridge</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;docker_gwbridge&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:51.263715613+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: false,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;gateway_ingress-sbox&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;false&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.name&quot;: &quot;docker_gwbridge&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n</code></pre><ul>\n<li><p>增加工作（<code>worker</code>）节点</p>\n<p>  将node2(192.168.0.191)加入到该<code>swarm</code>：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm join --token \\</span><br><span class=\"line\">  SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\</span><br><span class=\"line\">  192.168.0.190:2377</span><br><span class=\"line\"></span><br><span class=\"line\">  This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>\n<p>  查看node</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker node ls</span><br><span class=\"line\">  ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class=\"line\">  se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce</span><br><span class=\"line\">  timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>查看**工作节点**的docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls </span><br><span class=\"line\">  NETWORK ID          NAME                DRIVER                    SCOPE</span><br><span class=\"line\">  e39a5d50e807        bridge              bridge                    local</span><br><span class=\"line\">  2c7254c25f76        docker_gwbridge     bridge                    local</span><br><span class=\"line\">  a284efd6e1f2        host                host                      local</span><br><span class=\"line\">  yryhkokko1tk        ingress             overlay                   swarm</span><br><span class=\"line\">  13bd88a34632        none                null                  local</span><br></pre></td></tr></table></figure>\n</code></pre><h4 id=\"overlay网络\"><a href=\"#overlay网络\" class=\"headerlink\" title=\"overlay网络\"></a><code>overlay</code>网络</h4><ul>\n<li><p>创建<code>overlay</code>网络</p>\n<p>在创建<code>overlay</code>网络前，需要初始化或者加入<code>swarm</code>服务。即使可能后续不会使用<code>swarm</code>服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。</p>\n<p>要创建用于swarm服务的覆盖网络，请使用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay my-overlay</span><br></pre></td></tr></table></figure>\n<p>要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的<code>overlay</code>网络，必须添加<code>--attachable</code>标志：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay --attachable my-attachable-overlay</span><br></pre></td></tr></table></figure>\n<p>在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create –help</p>\n</li>\n<li><p><code>overlay</code>网络流量加密（不支持windows操作系统）</p>\n<p>在<code>swarm</code>服务中的管理流量默认是通过<code>GCM-AES</code>加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加<code>--opt encrypted</code>属性，Docker会在各个工作节点之间建立<code>IPSEC</code>隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。</p>\n</li>\n</ul>\n<ul>\n<li><p>自定义默认<code>ingress</code></p>\n<p>Docker 17.05之后的版本，才支持用户修改默认<code>ingress</code>网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他<code>low-level</code>底层网络设置（如MTU），则此功能非常有用。</p>\n<ul>\n<li><p>创建<code>ingress</code>网络</p>\n<p>使用–ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\">  --driver overlay \\</span><br><span class=\"line\">  --ingress \\</span><br><span class=\"line\">  --subnet=10.11.0.0/16 \\</span><br><span class=\"line\">  --gateway=10.11.0.2 \\</span><br><span class=\"line\">  --opt com.docker.network.driver.mtu=1200 \\</span><br><span class=\"line\">  my-ingress</span><br></pre></td></tr></table></figure>\n<p>注意：您可以对<code>ingress</code>网络重新命名，但您只能拥有一个<code>ingress</code>网络。</p>\n</li>\n<li><p>删除<code>ingress</code>网络</p>\n<p>如果现有服务有发布端口，则需要先删除这些服务，然后才能删除<code>ingress</code>网络。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm ingress</span><br><span class=\"line\"> </span><br><span class=\"line\">  WARNING! Before removing the routing-mesh   network, make sure all the nodes</span><br><span class=\"line\">  in your swarm run the same docker engine   version. Otherwise, removal may not</span><br><span class=\"line\">  be effective and functionality of newly created   ingress networks will be</span><br><span class=\"line\">  impaired.</span><br><span class=\"line\">  Are you sure you want to continue? [y/N]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>自定义<code>docker_gwbridge</code></p>\n<p><code>docker_gwbridge</code>是一个虚拟网桥，将覆盖网络（包括<code>ingress</code>网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr | grep docker_gwbridge</span><br><span class=\"line\">  docker_gwbridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;   mtu 1500 qdisc noqueue state UP </span><br><span class=\"line\">    inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li><p>Stop Docker service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop docker</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>删除<code>docker_gwbridge</code>网桥</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link set  docker_gwbridge down</span><br><span class=\"line\">$ ip link del dev docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动Docker，但是不要初始化<code>swarm</code>或者加入任何<code>swarm</code>  服务网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl start docker</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用<code>docker network create</code>命令，使用自定义设置手动  创建或重新创建<code>docker_gwbridge</code>桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (<a href=\"https://docs.docker.com/engine/reference/commandline/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/</a>  network_create/#bridge-driver-options)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create  \\</span><br><span class=\"line\">  --subnet 10.11.0.0/16 \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.name=docker_gwbridge \\</span><br><span class=\"line\">  --opt com.docker.network.bridge.enable_icc=false  \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.enable_ip_masquerade=true \\</span><br><span class=\"line\">  docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>初始化或加入<code>swarm</code>服务集群。由<code>docker_gwbridge</code>网桥已经存在，初始化时Docker不再创建它。</p>\n</li>\n</ol>\n<h4 id=\"创建用于swarm服务的overlay网络\"><a href=\"#创建用于swarm服务的overlay网络\" class=\"headerlink\" title=\"创建用于swarm服务的overlay网络\"></a>创建用于<code>swarm</code>服务的<code>overlay</code>网络</h4><ul>\n<li><p>在<code>overlay</code>网络上，暴露服务端口号</p>\n<p>连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用<code>docker service create</code>或<code>docker service update</code>上的<code>-p</code>或<code>--publish</code>参数发布端口。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker service create</span><br></pre></td></tr></table></figure>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格(<code>routing mesh</code>)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。</p>\n</li>\n<li><p><code>swram</code>服务区（<code>swarm service</code>）绕过网格路由（<code>routing mesh</code>）</p>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格来实现负载均衡。 当您连接到任意一个<code>swarm</code>节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的<code>worker</code>节点上。实际上，Docker充当您的群服务的负载均衡器（<code>load balancer</code>）。 默认情况下，使用<code>routing mesh</code>的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过<code>--mode global</code>）也使用路由网格。使用<code>routing mesh</code>时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将<code>--endpoint-mode</code>标志设置为<code>dnsrr</code>。若使用<code>dnsrr</code>，需要在服务前运行自己的负载均衡器（常用的：有<code>nginx</code>、<code>HAproxy</code>）。通过DNS查询返回运行在<code>swarm</code>集群服务的所有节点的IP地址列表。</p>\n<blockquote>\n<p><code>routing mesh</code> 将外部请求路由到不同主机的容器，从而实现了外部网络对 <code>service</code> 的访问。</p>\n</blockquote>\n</li>\n<li><p>分离控制流量和数据流量</p>\n<p>默认情况下，与<code>swarm</code>管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入<code>swarm</code>时，每个节点（管理节点和工作节点）需要分别指定<code>--advertise-addr</code>和<code>--data-path-addr</code>。</p>\n</li>\n</ul>\n<h4 id=\"创建用于独立容器使用的overlay网络\"><a href=\"#创建用于独立容器使用的overlay网络\" class=\"headerlink\" title=\"创建用于独立容器使用的overlay网络\"></a>创建用于独立容器使用的<code>overlay</code>网络</h4><ul>\n<li><p>将独立容器连接到覆盖网络</p>\n<p>在创建<code>ingress</code>网络时，若未指定<code>--attachable</code>（比如初始化<code>swarm</code>服务，或加入<code>swarm</code>时默认创建的<code>ingress</code>）意味着只有<code>swarm</code>服务可以使用它，独立运行的容器无法使用<code>ingress</code>。您可以将独立容器连接到使用–attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。</p>\n</li>\n</ul>\n<ul>\n<li><p>容器发现</p>\n<p>在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用<code>DNS lookup</code> 查找<code>tasks.&lt;service-name&gt;</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p><code>docker overlay</code>网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将<code>swarm</code>集群服务和<code>containers</code>容器与<code>overlay</code>网络进行连接，使各个服务或者服务与容器之间进行通信。</p>\n</blockquote>\n<h4 id=\"创建或加入swarm服务\"><a href=\"#创建或加入swarm服务\" class=\"headerlink\" title=\"创建或加入swarm服务\"></a>创建或加入<code>swarm</code>服务</h4><p>在创建和使用<code>overlay</code>之前，必须初始化一个<a href=\"https://docs.docker.com/engine/swarm/\" target=\"_blank\" rel=\"noopener\"><code>swarm</code></a>或者加入某个<code>swarm</code>:</p>\n<ul>\n<li><p>创建一个<code>swarm</code>集群服务</p>\n<p>用法：<code>docker swarm init [OPTIONS]</code>，针对常用的<code>[OPTIONS]</code>介绍见下方表格：</p>\n<p>参数说明</p>\n<p>|参数|类型|默认值|说明|<br>|—–|—–|—–|—–|<br>|<code>--advertise-addr</code>| string ||多块网卡时对应多个IP地址时，需要指定|<br>|<code>--data-path-addr</code>|string||用于数据流量传输的IP地址或者网卡名称（例：<code>eth0</code>）|<br>|<code>--listen-addr</code>|node-addr|0.0.0.0:2377|监听地址|</p>\n</li>\n</ul>\n<p>  <strong>示例：创建<code>swarm</code>服务</strong></p>\n<p>  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：</p>\n   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1 : 192.168.0.190  (manager &amp; worker)</span><br><span class=\"line\">node2 : 192.168.0.191 (worker)</span><br></pre></td></tr></table></figure>\n<p>   <img src=\"/images/swarmcluster.png\" alt=\"swarm架构\"></p>\n<ul>\n<li><p>创建<code>swarm</code>集群服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm init --advertise-addr 192.168.0.190</span><br><span class=\"line\">Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.</span><br><span class=\"line\">To add a worker to this swarm, run the following      command:</span><br><span class=\"line\">  docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377</span><br><span class=\"line\">To add a manager to this swarm, run &apos;docker swarm      join-tokenmanager&apos; and follow the instructions.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker swarm join --token xxxx &lt;manager-ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>\n\n\n可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n\n查看docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER                 SCOPE</span><br><span class=\"line\">ba18dbad1160        bridge              bridge                 local</span><br><span class=\"line\">58886c346808        docker_gwbridge     bridge                 local</span><br><span class=\"line\">7966432ad37e        host                host                   local</span><br><span class=\"line\">yryhkokko1tk        ingress             overlay                swarm</span><br><span class=\"line\">d1ab833f3555        none                null                   local</span><br></pre></td></tr></table></figure>\n\n\n可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n\n- `ingress`\n\n  一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n  使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect ingress</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;ingress&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;yryhkokko1tkpkhx0pf0e1zm3&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:50.511486192+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;swarm&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;overlay&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;10.255.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;10.255.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: true,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;ingress-endpoint&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:0a:ff:00:03&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;10.255.0.3/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4096&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Peers&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;5e8427535708&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.190&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;42c5607b0c46&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.191&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n- `docker_gwbridge`\n\n  一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect docker_gwbridge</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;docker_gwbridge&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:51.263715613+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: false,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;gateway_ingress-sbox&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;false&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.name&quot;: &quot;docker_gwbridge&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n</code></pre><ul>\n<li><p>增加工作（<code>worker</code>）节点</p>\n<p>  将node2(192.168.0.191)加入到该<code>swarm</code>：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm join --token \\</span><br><span class=\"line\">  SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\</span><br><span class=\"line\">  192.168.0.190:2377</span><br><span class=\"line\"></span><br><span class=\"line\">  This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>\n<p>  查看node</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker node ls</span><br><span class=\"line\">  ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class=\"line\">  se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce</span><br><span class=\"line\">  timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>查看**工作节点**的docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls </span><br><span class=\"line\">  NETWORK ID          NAME                DRIVER                    SCOPE</span><br><span class=\"line\">  e39a5d50e807        bridge              bridge                    local</span><br><span class=\"line\">  2c7254c25f76        docker_gwbridge     bridge                    local</span><br><span class=\"line\">  a284efd6e1f2        host                host                      local</span><br><span class=\"line\">  yryhkokko1tk        ingress             overlay                   swarm</span><br><span class=\"line\">  13bd88a34632        none                null                  local</span><br></pre></td></tr></table></figure>\n</code></pre><h4 id=\"overlay网络\"><a href=\"#overlay网络\" class=\"headerlink\" title=\"overlay网络\"></a><code>overlay</code>网络</h4><ul>\n<li><p>创建<code>overlay</code>网络</p>\n<p>在创建<code>overlay</code>网络前，需要初始化或者加入<code>swarm</code>服务。即使可能后续不会使用<code>swarm</code>服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。</p>\n<p>要创建用于swarm服务的覆盖网络，请使用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay my-overlay</span><br></pre></td></tr></table></figure>\n<p>要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的<code>overlay</code>网络，必须添加<code>--attachable</code>标志：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay --attachable my-attachable-overlay</span><br></pre></td></tr></table></figure>\n<p>在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create –help</p>\n</li>\n<li><p><code>overlay</code>网络流量加密（不支持windows操作系统）</p>\n<p>在<code>swarm</code>服务中的管理流量默认是通过<code>GCM-AES</code>加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加<code>--opt encrypted</code>属性，Docker会在各个工作节点之间建立<code>IPSEC</code>隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。</p>\n</li>\n</ul>\n<ul>\n<li><p>自定义默认<code>ingress</code></p>\n<p>Docker 17.05之后的版本，才支持用户修改默认<code>ingress</code>网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他<code>low-level</code>底层网络设置（如MTU），则此功能非常有用。</p>\n<ul>\n<li><p>创建<code>ingress</code>网络</p>\n<p>使用–ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\">  --driver overlay \\</span><br><span class=\"line\">  --ingress \\</span><br><span class=\"line\">  --subnet=10.11.0.0/16 \\</span><br><span class=\"line\">  --gateway=10.11.0.2 \\</span><br><span class=\"line\">  --opt com.docker.network.driver.mtu=1200 \\</span><br><span class=\"line\">  my-ingress</span><br></pre></td></tr></table></figure>\n<p>注意：您可以对<code>ingress</code>网络重新命名，但您只能拥有一个<code>ingress</code>网络。</p>\n</li>\n<li><p>删除<code>ingress</code>网络</p>\n<p>如果现有服务有发布端口，则需要先删除这些服务，然后才能删除<code>ingress</code>网络。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm ingress</span><br><span class=\"line\"> </span><br><span class=\"line\">  WARNING! Before removing the routing-mesh   network, make sure all the nodes</span><br><span class=\"line\">  in your swarm run the same docker engine   version. Otherwise, removal may not</span><br><span class=\"line\">  be effective and functionality of newly created   ingress networks will be</span><br><span class=\"line\">  impaired.</span><br><span class=\"line\">  Are you sure you want to continue? [y/N]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>自定义<code>docker_gwbridge</code></p>\n<p><code>docker_gwbridge</code>是一个虚拟网桥，将覆盖网络（包括<code>ingress</code>网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr | grep docker_gwbridge</span><br><span class=\"line\">  docker_gwbridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;   mtu 1500 qdisc noqueue state UP </span><br><span class=\"line\">    inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li><p>Stop Docker service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop docker</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>删除<code>docker_gwbridge</code>网桥</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link set  docker_gwbridge down</span><br><span class=\"line\">$ ip link del dev docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动Docker，但是不要初始化<code>swarm</code>或者加入任何<code>swarm</code>  服务网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl start docker</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用<code>docker network create</code>命令，使用自定义设置手动  创建或重新创建<code>docker_gwbridge</code>桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (<a href=\"https://docs.docker.com/engine/reference/commandline/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/</a>  network_create/#bridge-driver-options)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create  \\</span><br><span class=\"line\">  --subnet 10.11.0.0/16 \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.name=docker_gwbridge \\</span><br><span class=\"line\">  --opt com.docker.network.bridge.enable_icc=false  \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.enable_ip_masquerade=true \\</span><br><span class=\"line\">  docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>初始化或加入<code>swarm</code>服务集群。由<code>docker_gwbridge</code>网桥已经存在，初始化时Docker不再创建它。</p>\n</li>\n</ol>\n<h4 id=\"创建用于swarm服务的overlay网络\"><a href=\"#创建用于swarm服务的overlay网络\" class=\"headerlink\" title=\"创建用于swarm服务的overlay网络\"></a>创建用于<code>swarm</code>服务的<code>overlay</code>网络</h4><ul>\n<li><p>在<code>overlay</code>网络上，暴露服务端口号</p>\n<p>连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用<code>docker service create</code>或<code>docker service update</code>上的<code>-p</code>或<code>--publish</code>参数发布端口。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker service create</span><br></pre></td></tr></table></figure>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格(<code>routing mesh</code>)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。</p>\n</li>\n<li><p><code>swram</code>服务区（<code>swarm service</code>）绕过网格路由（<code>routing mesh</code>）</p>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格来实现负载均衡。 当您连接到任意一个<code>swarm</code>节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的<code>worker</code>节点上。实际上，Docker充当您的群服务的负载均衡器（<code>load balancer</code>）。 默认情况下，使用<code>routing mesh</code>的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过<code>--mode global</code>）也使用路由网格。使用<code>routing mesh</code>时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将<code>--endpoint-mode</code>标志设置为<code>dnsrr</code>。若使用<code>dnsrr</code>，需要在服务前运行自己的负载均衡器（常用的：有<code>nginx</code>、<code>HAproxy</code>）。通过DNS查询返回运行在<code>swarm</code>集群服务的所有节点的IP地址列表。</p>\n<blockquote>\n<p><code>routing mesh</code> 将外部请求路由到不同主机的容器，从而实现了外部网络对 <code>service</code> 的访问。</p>\n</blockquote>\n</li>\n<li><p>分离控制流量和数据流量</p>\n<p>默认情况下，与<code>swarm</code>管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入<code>swarm</code>时，每个节点（管理节点和工作节点）需要分别指定<code>--advertise-addr</code>和<code>--data-path-addr</code>。</p>\n</li>\n</ul>\n<h4 id=\"创建用于独立容器使用的overlay网络\"><a href=\"#创建用于独立容器使用的overlay网络\" class=\"headerlink\" title=\"创建用于独立容器使用的overlay网络\"></a>创建用于独立容器使用的<code>overlay</code>网络</h4><ul>\n<li><p>将独立容器连接到覆盖网络</p>\n<p>在创建<code>ingress</code>网络时，若未指定<code>--attachable</code>（比如初始化<code>swarm</code>服务，或加入<code>swarm</code>时默认创建的<code>ingress</code>）意味着只有<code>swarm</code>服务可以使用它，独立运行的容器无法使用<code>ingress</code>。您可以将独立容器连接到使用–attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。</p>\n</li>\n</ul>\n<ul>\n<li><p>容器发现</p>\n<p>在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用<code>DNS lookup</code> 查找<code>tasks.&lt;service-name&gt;</code></p>\n</li>\n</ul>\n"},{"title":"docker存储原理——介绍","date":"2019-03-21T08:46:02.000Z","_content":"\nDocker数据存储\n---\n\n>在Docker中，有两种方式对数据进行存储：`docker volume`(存储卷) 和 `docker storage driver`（存储驱动），本文主要介绍`docker storage driver`存储驱动。\n\n准备工作：\n\nOS: centos 7.4 (kernel version > 3.10.514 )\n\nDocker: docker-ce 18.03.1 ( [docker-ce安装教程](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/))\n\n\n#### Docker 数据存储\n\n在了解`Docker storage driver`之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和`docker volume`存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。\n\n   ![](/images/container-layers.jpg)\n\n如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：`/var/lib/docker/<storage-driver>/`）。以该镜像为基础，通过`docker run`启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。\n\n - 镜像层\n   Docker镜像是由一系列的层（`layer`）构成，镜像的每个`layer`对应这个Dockerfile中的每条指令\n   \n   ```\n   FROM ubuntu:15.04\n   COPY . /app\n   RUN mkdir -p /app/conf/\n   CMD python /app/app.py\n   ```\n\n   通过`docker build -t `命令构建镜像：\n  \n   ```\n   $ docker build -t my-ubuntu:test -f Dockerfile .\n     \n     Sending build context to Docker daemon  3.584kB\n     Step 1/4 : FROM ubuntu:15.04\n     ---> d1b55fd07600\n     Step 2/4 : COPY . /app\n     ---> 6e3fe23e82f3\n     Step 3/4 : RUN mkdir -p /app/conf/\n     ---> Running in 3a9b550d957b\n     Removing intermediate container 3a9b550d957b\n     ---> 038a1543c273\n     Step 4/4 : CMD python /app/app.py\n     ---> Running in 9b56a922b87f\n     Removing intermediate container 9b56a922b87f\n     ---> 58866642a2af\n     Successfully built 58866642a2af\n     Successfully tagged my-ubuntu:test\n   ```\n   查看镜像是否存在：\n\n   ```\n   $ docker images\n     REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n     my-ubuntu           test                58866642a2af        5 minutes ago       131MB\n     ubuntu              15.04               d1b55fd07600        2 years ago         131MB\n   ```\n\n   查看镜像构建详情：\n\n   ```\n   $ docker history 58866642a2af\n     \n     IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n   58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [\"/bin/sh\" \"-c\" \"pyth…   0B                  \n   038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  \n   6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                \n   d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [\"/bin/bash\"]             0B                  \n   <missing>           2 years ago         /bin/sh -c sed -i    's/^#\\s*\\(deb.*universe\\)$…   1.88kB              \n   <missing>           2 years ago         /bin/sh -c echo    '#!/bin/sh' > /usr/sbin/poli…   701B                \n   <missing>           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB\n   ```\n\n   我们看到`58866642a2af` `038a1543c273` `6e3fe23e82f3` 是刚刚创建的层，对应着Dockerfile文件中的每条指令。`d1b55fd07600`是基础镜像的层，而`missing`则是以往他人在其他主机上构建的层，可以忽视。\n   \n   当您使用`docker pull`从`registry`（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是`/var/lib/docker`。您可以在此示例中看到这些镜像层被拉出：\n\n   ```\n   $ docker pull ubuntu:15.04\n     15.04: Pulling from library/ubuntu\n     9502adfba7f1: Pull complete \n     4332ffb06e4b: Pull complete \n     2f937cc07b5f: Pull complete \n     a3ed95caeb02: Pull complete \n     Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f\n     Status: Downloaded newer image for ubuntu:15.04\n   ```\n\n   下拉的镜像层存储在`/var/lib/docker/<storage-driver>/`目录中，本例使用的存储驱动是`overlay2`，Docker version > 1.10的版本，每层的目录名称与图层ID不对应。\n\n   ```\n   $ ls -l /var/lib/docker/overlay2/\n     drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9\n     drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c\n     drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b\n     drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226\n     drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172\n   ```\n\n - 容器层\n   \n   容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），`low-level`的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。\n   若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用`docker volume`存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。\n\n  ![](/images/sharing-layers.jpg)\n\n   当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径`/var/lib/docker/containers`\n\n   ```\n   $ ls -l /var/lib/docker/containers\n   drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28\n   drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569\n   drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a\n   drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea\n   drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509   \n   ```\n\n#### 写时复制（CoW）策略\n\n写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的`low-level`层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。\n\n对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：\n\n1. 在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。\n2. `copy_up`对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。\n3. 对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。\n\n\n\n\n\n\n\n","source":"_posts/2019-03-21-docker-storage.md","raw":"---\ntitle: docker存储原理——介绍\ndate: 2019-03-21 08:46:02\ntags:\n  - docker\n  - storage\ncategories:\n  - 运维\n  - docker\n---\n\nDocker数据存储\n---\n\n>在Docker中，有两种方式对数据进行存储：`docker volume`(存储卷) 和 `docker storage driver`（存储驱动），本文主要介绍`docker storage driver`存储驱动。\n\n准备工作：\n\nOS: centos 7.4 (kernel version > 3.10.514 )\n\nDocker: docker-ce 18.03.1 ( [docker-ce安装教程](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/))\n\n\n#### Docker 数据存储\n\n在了解`Docker storage driver`之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和`docker volume`存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。\n\n   ![](/images/container-layers.jpg)\n\n如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：`/var/lib/docker/<storage-driver>/`）。以该镜像为基础，通过`docker run`启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。\n\n - 镜像层\n   Docker镜像是由一系列的层（`layer`）构成，镜像的每个`layer`对应这个Dockerfile中的每条指令\n   \n   ```\n   FROM ubuntu:15.04\n   COPY . /app\n   RUN mkdir -p /app/conf/\n   CMD python /app/app.py\n   ```\n\n   通过`docker build -t `命令构建镜像：\n  \n   ```\n   $ docker build -t my-ubuntu:test -f Dockerfile .\n     \n     Sending build context to Docker daemon  3.584kB\n     Step 1/4 : FROM ubuntu:15.04\n     ---> d1b55fd07600\n     Step 2/4 : COPY . /app\n     ---> 6e3fe23e82f3\n     Step 3/4 : RUN mkdir -p /app/conf/\n     ---> Running in 3a9b550d957b\n     Removing intermediate container 3a9b550d957b\n     ---> 038a1543c273\n     Step 4/4 : CMD python /app/app.py\n     ---> Running in 9b56a922b87f\n     Removing intermediate container 9b56a922b87f\n     ---> 58866642a2af\n     Successfully built 58866642a2af\n     Successfully tagged my-ubuntu:test\n   ```\n   查看镜像是否存在：\n\n   ```\n   $ docker images\n     REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n     my-ubuntu           test                58866642a2af        5 minutes ago       131MB\n     ubuntu              15.04               d1b55fd07600        2 years ago         131MB\n   ```\n\n   查看镜像构建详情：\n\n   ```\n   $ docker history 58866642a2af\n     \n     IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n   58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [\"/bin/sh\" \"-c\" \"pyth…   0B                  \n   038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  \n   6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                \n   d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [\"/bin/bash\"]             0B                  \n   <missing>           2 years ago         /bin/sh -c sed -i    's/^#\\s*\\(deb.*universe\\)$…   1.88kB              \n   <missing>           2 years ago         /bin/sh -c echo    '#!/bin/sh' > /usr/sbin/poli…   701B                \n   <missing>           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB\n   ```\n\n   我们看到`58866642a2af` `038a1543c273` `6e3fe23e82f3` 是刚刚创建的层，对应着Dockerfile文件中的每条指令。`d1b55fd07600`是基础镜像的层，而`missing`则是以往他人在其他主机上构建的层，可以忽视。\n   \n   当您使用`docker pull`从`registry`（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是`/var/lib/docker`。您可以在此示例中看到这些镜像层被拉出：\n\n   ```\n   $ docker pull ubuntu:15.04\n     15.04: Pulling from library/ubuntu\n     9502adfba7f1: Pull complete \n     4332ffb06e4b: Pull complete \n     2f937cc07b5f: Pull complete \n     a3ed95caeb02: Pull complete \n     Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f\n     Status: Downloaded newer image for ubuntu:15.04\n   ```\n\n   下拉的镜像层存储在`/var/lib/docker/<storage-driver>/`目录中，本例使用的存储驱动是`overlay2`，Docker version > 1.10的版本，每层的目录名称与图层ID不对应。\n\n   ```\n   $ ls -l /var/lib/docker/overlay2/\n     drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9\n     drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c\n     drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b\n     drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226\n     drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172\n   ```\n\n - 容器层\n   \n   容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），`low-level`的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。\n   若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用`docker volume`存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。\n\n  ![](/images/sharing-layers.jpg)\n\n   当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径`/var/lib/docker/containers`\n\n   ```\n   $ ls -l /var/lib/docker/containers\n   drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28\n   drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569\n   drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a\n   drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea\n   drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509   \n   ```\n\n#### 写时复制（CoW）策略\n\n写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的`low-level`层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。\n\n对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：\n\n1. 在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。\n2. `copy_up`对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。\n3. 对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。\n\n\n\n\n\n\n\n","slug":"docker-storage","published":1,"updated":"2019-03-21T12:19:28.918Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqt0001khqxuhy9r80b7","content":"<h2 id=\"Docker数据存储\"><a href=\"#Docker数据存储\" class=\"headerlink\" title=\"Docker数据存储\"></a>Docker数据存储</h2><blockquote>\n<p>在Docker中，有两种方式对数据进行存储：<code>docker volume</code>(存储卷) 和 <code>docker storage driver</code>（存储驱动），本文主要介绍<code>docker storage driver</code>存储驱动。</p>\n</blockquote>\n<p>准备工作：</p>\n<p>OS: centos 7.4 (kernel version &gt; 3.10.514 )</p>\n<p>Docker: docker-ce 18.03.1 ( <a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">docker-ce安装教程</a>)</p>\n<h4 id=\"Docker-数据存储\"><a href=\"#Docker-数据存储\" class=\"headerlink\" title=\"Docker 数据存储\"></a>Docker 数据存储</h4><p>在了解<code>Docker storage driver</code>之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和<code>docker volume</code>存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。</p>\n<p>   <img src=\"/images/container-layers.jpg\" alt></p>\n<p>如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：<code>/var/lib/docker/&lt;storage-driver&gt;/</code>）。以该镜像为基础，通过<code>docker run</code>启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。</p>\n<ul>\n<li><p>镜像层<br>Docker镜像是由一系列的层（<code>layer</code>）构成，镜像的每个<code>layer</code>对应这个Dockerfile中的每条指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:15.04</span><br><span class=\"line\">COPY . /app</span><br><span class=\"line\">RUN mkdir -p /app/conf/</span><br><span class=\"line\">CMD python /app/app.py</span><br></pre></td></tr></table></figure>\n<p>通过<code>docker build -t</code>命令构建镜像：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker build -t my-ubuntu:test -f Dockerfile .</span><br><span class=\"line\">  </span><br><span class=\"line\">  Sending build context to Docker daemon  3.584kB</span><br><span class=\"line\">  Step 1/4 : FROM ubuntu:15.04</span><br><span class=\"line\">  ---&gt; d1b55fd07600</span><br><span class=\"line\">  Step 2/4 : COPY . /app</span><br><span class=\"line\">  ---&gt; 6e3fe23e82f3</span><br><span class=\"line\">  Step 3/4 : RUN mkdir -p /app/conf/</span><br><span class=\"line\">  ---&gt; Running in 3a9b550d957b</span><br><span class=\"line\">  Removing intermediate container 3a9b550d957b</span><br><span class=\"line\">  ---&gt; 038a1543c273</span><br><span class=\"line\">  Step 4/4 : CMD python /app/app.py</span><br><span class=\"line\">  ---&gt; Running in 9b56a922b87f</span><br><span class=\"line\">  Removing intermediate container 9b56a922b87f</span><br><span class=\"line\">  ---&gt; 58866642a2af</span><br><span class=\"line\">  Successfully built 58866642a2af</span><br><span class=\"line\">  Successfully tagged my-ubuntu:test</span><br></pre></td></tr></table></figure>\n<p>查看镜像是否存在：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker images</span><br><span class=\"line\">  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">  my-ubuntu           test                58866642a2af        5 minutes ago       131MB</span><br><span class=\"line\">  ubuntu              15.04               d1b55fd07600        2 years ago         131MB</span><br></pre></td></tr></table></figure>\n<p>查看镜像构建详情：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker history 58866642a2af</span><br><span class=\"line\">  </span><br><span class=\"line\">  IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class=\"line\">58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;pyth…   0B                  </span><br><span class=\"line\">038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  </span><br><span class=\"line\">6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                </span><br><span class=\"line\">d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [&quot;/bin/bash&quot;]             0B                  </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i    &apos;s/^#\\s*\\(deb.*universe\\)$…   1.88kB              </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c echo    &apos;#!/bin/sh&apos; &gt; /usr/sbin/poli…   701B                </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB</span><br></pre></td></tr></table></figure>\n<p>我们看到<code>58866642a2af</code> <code>038a1543c273</code> <code>6e3fe23e82f3</code> 是刚刚创建的层，对应着Dockerfile文件中的每条指令。<code>d1b55fd07600</code>是基础镜像的层，而<code>missing</code>则是以往他人在其他主机上构建的层，可以忽视。</p>\n<p>当您使用<code>docker pull</code>从<code>registry</code>（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是<code>/var/lib/docker</code>。您可以在此示例中看到这些镜像层被拉出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull ubuntu:15.04</span><br><span class=\"line\">  15.04: Pulling from library/ubuntu</span><br><span class=\"line\">  9502adfba7f1: Pull complete </span><br><span class=\"line\">  4332ffb06e4b: Pull complete </span><br><span class=\"line\">  2f937cc07b5f: Pull complete </span><br><span class=\"line\">  a3ed95caeb02: Pull complete </span><br><span class=\"line\">  Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f</span><br><span class=\"line\">  Status: Downloaded newer image for ubuntu:15.04</span><br></pre></td></tr></table></figure>\n<p>下拉的镜像层存储在<code>/var/lib/docker/&lt;storage-driver&gt;/</code>目录中，本例使用的存储驱动是<code>overlay2</code>，Docker version &gt; 1.10的版本，每层的目录名称与图层ID不对应。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/overlay2/</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>容器层</p>\n<p>容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），<code>low-level</code>的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。<br>若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用<code>docker volume</code>存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。</p>\n<p><img src=\"/images/sharing-layers.jpg\" alt></p>\n<p>当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径<code>/var/lib/docker/containers</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/containers</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569</span><br><span class=\"line\">drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"写时复制（CoW）策略\"><a href=\"#写时复制（CoW）策略\" class=\"headerlink\" title=\"写时复制（CoW）策略\"></a>写时复制（CoW）策略</h4><p>写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的<code>low-level</code>层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。</p>\n<p>对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：</p>\n<ol>\n<li>在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。</li>\n<li><code>copy_up</code>对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。</li>\n<li>对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Docker数据存储\"><a href=\"#Docker数据存储\" class=\"headerlink\" title=\"Docker数据存储\"></a>Docker数据存储</h2><blockquote>\n<p>在Docker中，有两种方式对数据进行存储：<code>docker volume</code>(存储卷) 和 <code>docker storage driver</code>（存储驱动），本文主要介绍<code>docker storage driver</code>存储驱动。</p>\n</blockquote>\n<p>准备工作：</p>\n<p>OS: centos 7.4 (kernel version &gt; 3.10.514 )</p>\n<p>Docker: docker-ce 18.03.1 ( <a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">docker-ce安装教程</a>)</p>\n<h4 id=\"Docker-数据存储\"><a href=\"#Docker-数据存储\" class=\"headerlink\" title=\"Docker 数据存储\"></a>Docker 数据存储</h4><p>在了解<code>Docker storage driver</code>之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和<code>docker volume</code>存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。</p>\n<p>   <img src=\"/images/container-layers.jpg\" alt></p>\n<p>如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：<code>/var/lib/docker/&lt;storage-driver&gt;/</code>）。以该镜像为基础，通过<code>docker run</code>启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。</p>\n<ul>\n<li><p>镜像层<br>Docker镜像是由一系列的层（<code>layer</code>）构成，镜像的每个<code>layer</code>对应这个Dockerfile中的每条指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:15.04</span><br><span class=\"line\">COPY . /app</span><br><span class=\"line\">RUN mkdir -p /app/conf/</span><br><span class=\"line\">CMD python /app/app.py</span><br></pre></td></tr></table></figure>\n<p>通过<code>docker build -t</code>命令构建镜像：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker build -t my-ubuntu:test -f Dockerfile .</span><br><span class=\"line\">  </span><br><span class=\"line\">  Sending build context to Docker daemon  3.584kB</span><br><span class=\"line\">  Step 1/4 : FROM ubuntu:15.04</span><br><span class=\"line\">  ---&gt; d1b55fd07600</span><br><span class=\"line\">  Step 2/4 : COPY . /app</span><br><span class=\"line\">  ---&gt; 6e3fe23e82f3</span><br><span class=\"line\">  Step 3/4 : RUN mkdir -p /app/conf/</span><br><span class=\"line\">  ---&gt; Running in 3a9b550d957b</span><br><span class=\"line\">  Removing intermediate container 3a9b550d957b</span><br><span class=\"line\">  ---&gt; 038a1543c273</span><br><span class=\"line\">  Step 4/4 : CMD python /app/app.py</span><br><span class=\"line\">  ---&gt; Running in 9b56a922b87f</span><br><span class=\"line\">  Removing intermediate container 9b56a922b87f</span><br><span class=\"line\">  ---&gt; 58866642a2af</span><br><span class=\"line\">  Successfully built 58866642a2af</span><br><span class=\"line\">  Successfully tagged my-ubuntu:test</span><br></pre></td></tr></table></figure>\n<p>查看镜像是否存在：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker images</span><br><span class=\"line\">  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">  my-ubuntu           test                58866642a2af        5 minutes ago       131MB</span><br><span class=\"line\">  ubuntu              15.04               d1b55fd07600        2 years ago         131MB</span><br></pre></td></tr></table></figure>\n<p>查看镜像构建详情：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker history 58866642a2af</span><br><span class=\"line\">  </span><br><span class=\"line\">  IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class=\"line\">58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;pyth…   0B                  </span><br><span class=\"line\">038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  </span><br><span class=\"line\">6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                </span><br><span class=\"line\">d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [&quot;/bin/bash&quot;]             0B                  </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i    &apos;s/^#\\s*\\(deb.*universe\\)$…   1.88kB              </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c echo    &apos;#!/bin/sh&apos; &gt; /usr/sbin/poli…   701B                </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB</span><br></pre></td></tr></table></figure>\n<p>我们看到<code>58866642a2af</code> <code>038a1543c273</code> <code>6e3fe23e82f3</code> 是刚刚创建的层，对应着Dockerfile文件中的每条指令。<code>d1b55fd07600</code>是基础镜像的层，而<code>missing</code>则是以往他人在其他主机上构建的层，可以忽视。</p>\n<p>当您使用<code>docker pull</code>从<code>registry</code>（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是<code>/var/lib/docker</code>。您可以在此示例中看到这些镜像层被拉出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull ubuntu:15.04</span><br><span class=\"line\">  15.04: Pulling from library/ubuntu</span><br><span class=\"line\">  9502adfba7f1: Pull complete </span><br><span class=\"line\">  4332ffb06e4b: Pull complete </span><br><span class=\"line\">  2f937cc07b5f: Pull complete </span><br><span class=\"line\">  a3ed95caeb02: Pull complete </span><br><span class=\"line\">  Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f</span><br><span class=\"line\">  Status: Downloaded newer image for ubuntu:15.04</span><br></pre></td></tr></table></figure>\n<p>下拉的镜像层存储在<code>/var/lib/docker/&lt;storage-driver&gt;/</code>目录中，本例使用的存储驱动是<code>overlay2</code>，Docker version &gt; 1.10的版本，每层的目录名称与图层ID不对应。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/overlay2/</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>容器层</p>\n<p>容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），<code>low-level</code>的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。<br>若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用<code>docker volume</code>存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。</p>\n<p><img src=\"/images/sharing-layers.jpg\" alt></p>\n<p>当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径<code>/var/lib/docker/containers</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/containers</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569</span><br><span class=\"line\">drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"写时复制（CoW）策略\"><a href=\"#写时复制（CoW）策略\" class=\"headerlink\" title=\"写时复制（CoW）策略\"></a>写时复制（CoW）策略</h4><p>写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的<code>low-level</code>层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。</p>\n<p>对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：</p>\n<ol>\n<li>在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。</li>\n<li><code>copy_up</code>对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。</li>\n<li>对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。</li>\n</ol>\n"},{"title":"Docker网络驱动(network driver)之————网桥(bridge)","date":"2019-03-25T13:33:15.000Z","_content":"\nDocker网络驱动(network driver)之————网桥(bridge)\n>在《计算机网络》这本教材中，我们学习过，**网桥**是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。\n\n在Docker的网络系统中，**网桥**`bridge network`是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的**容器**之间进行通信，同时隔离那些未连接到该**网桥**的容器。当启动`Docker daemon`（`docker`守护进程)时，会自动创建**网桥**（`bridge network`），称为:`bridge`，即对应host上的`docker0`。`Docker network`会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。\n\n查看主机上的网络设备\n```\n$ ip addr \n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3\n       valid_lft 84147sec preferred_lft 84147sec\n    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8\n       valid_lft 996sec preferred_lft 996sec\n    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:60ff:fee0:e955/64 scope link \n       valid_lft forever preferred_lft forever\n```\n查看docker网络驱动\n```\n$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nb549b06a92e7        bridge              bridge              local\nc5149e25deea        host                host                local\nbfa90bfc3dfe        none                null                local\n```\n\n**网桥**`bridge network`适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的[覆盖网络`overlay`](https://docs.docker.com/network/overlay/)和[`macvlan`](https://docs.docker.com/network/macvlan/)。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico\n\n如果用户启动一个新的容器（`container`），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（`self-defined bridge networks`）。\n**自定义网桥**在容器安全性、容器间通信等方面优于默认网桥（`bridge`）\n\n#### 用户定义的网桥与默认网桥之间的区别\n\n - 用户定义的网桥可在容器化应用程序（`container application`）之间提供更好的隔离性和连通性\n   连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。\n\n   比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。\n   如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或--publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。\n\n - 用户定义的桥接器在容器之间提供自动DNS解析\n   默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用`--link`选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。\n   还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（`--link`）。如果容器数量达到几十或者几百，那么工作量将会非常大。\n   \n - 容器可以在运行中与用户定义的网络连接和分离\n   \n - 每个用户定义的网络都会创建一个可配置的网桥\n   如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用`docker network create`创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。\n   ```\n   $ docker network create my-net\n   ```\n\n - 默认桥接网络上的链接容器共享环境变量\n   最初，在两个容器之间共享环境变量的唯一方法是使用--link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：\n\n   - 多个容器可以挂载包含共享信息的文件或目录，使用`Docker volume`挂载卷进行文件或者变量共享。\n\n   - 可以使用`docker-compose`一起启动多个容器，并且compose文件可以定义共享变量。\n\n   - 您可以使用集群服务（`swamp service`）而不是独立容器，并利用[`secrets`](https://docs.docker.com/engine/swarm/secrets/)和[`configs`](https://docs.docker.com/engine/swarm/configs/)共享变量。\n     ```\n\t docker service create \\\n     --name nginx \\\n     --secret site.key \\\n     --secret site.crt \\\n     --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n     --publish published=3000,target=443 \\\n     nginx:latest \\\n     sh -c \"exec nginx -g 'daemon off;'\"\n\t ```\n#### 创建用户自定义网桥（self-define ）\n\n- 使用命令`docker network create ` 命令创建用户自定义网络\n   \n   具体使用方法可以使用`docker network create --help`获取帮助  \n    ```\n    $ docker network create \\\n     --driver=bridge \\\n     --subnet=172.28.0.0/16 \\\n     --ip-range=172.28.5.0/24 \\\n     --gateway=172.28.5.254 \\\n        br0\n   ```\n\n- 使用命令`docker network rm `命令删除已存在的网络\n   ```\n   $ docker network rm my-net\n   ```\n当用户**删除**或**创建**网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改`iptables`规则）。这些操作对用户来说是透明的。\n\n#### 连接容器到自定义网络\n用户在创建容器时，可以指定连接到自定义网络（使用`--network`方式）；也可以将正在运行的（runing)的容器连接到自定义网络。\n\n - 创建容器，并连接到自定义网络\n\n   例如：创建`Nginx`容器，连接到`my-net`网络中\n   ```\n   $ docker create --name my-nginx \\\n      --network my-net \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   创建一个容器`my-nginx`，连接到已存在的`my-net` 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。\n\n - `running`容器连接到自定义网络中\n\n   启动`my-nignx`容器\n   ```\n   $ docker run --name my-nginx \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   连接到`my-net`自定义网络\n   ```\n   $ docker network connect my-net my-nginx\n   ```\n   如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。\n\n#### 修改Docker默认网桥\n修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件\n\n - 修改dockerd启动配置文件\n\n   dockerd启动文件默认位置：`/usr/lib/systemd/system/docker.service`\n   ```\n   ...\n   ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\\n     -H tcp://0.0.0.0:2376 \\\n     --bip=10.2.54.1/24 \\ \n     --mtu=1450 \\ \n     --dns=[\"10.20.1.2\",\"10.20.1.3\"]\n   ...\n   ```\n\n - daemon.json文件\n   ```\n   {\n      \"bip\": \"192.168.1.5/24\",\n      \"fixed-cidr\": \"192.168.1.5/25\",\n      \"fixed-cidr-v6\": \"2001:db8::/64\",\n      \"mtu\": 1500,\n      \"default-gateway\": \"10.20.1.1\",\n      \"default-gateway-v6\": \"2001:db8:abcd::89\",\n      \"dns\": [\"10.20.1.2\",\"10.20.1.3\"]\n   }\n   ```\n使参数生效，则需要重启Docker守护进程。\n\n\n\n\n\n\n\n","source":"_posts/2019-03-25-docker-network-bridge.md","raw":"---\ntitle: Docker网络驱动(network driver)之————网桥(bridge) \ndate: 2019-03-25 13:33:15\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\nDocker网络驱动(network driver)之————网桥(bridge)\n>在《计算机网络》这本教材中，我们学习过，**网桥**是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。\n\n在Docker的网络系统中，**网桥**`bridge network`是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的**容器**之间进行通信，同时隔离那些未连接到该**网桥**的容器。当启动`Docker daemon`（`docker`守护进程)时，会自动创建**网桥**（`bridge network`），称为:`bridge`，即对应host上的`docker0`。`Docker network`会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。\n\n查看主机上的网络设备\n```\n$ ip addr \n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3\n       valid_lft 84147sec preferred_lft 84147sec\n    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8\n       valid_lft 996sec preferred_lft 996sec\n    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:60ff:fee0:e955/64 scope link \n       valid_lft forever preferred_lft forever\n```\n查看docker网络驱动\n```\n$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nb549b06a92e7        bridge              bridge              local\nc5149e25deea        host                host                local\nbfa90bfc3dfe        none                null                local\n```\n\n**网桥**`bridge network`适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的[覆盖网络`overlay`](https://docs.docker.com/network/overlay/)和[`macvlan`](https://docs.docker.com/network/macvlan/)。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico\n\n如果用户启动一个新的容器（`container`），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（`self-defined bridge networks`）。\n**自定义网桥**在容器安全性、容器间通信等方面优于默认网桥（`bridge`）\n\n#### 用户定义的网桥与默认网桥之间的区别\n\n - 用户定义的网桥可在容器化应用程序（`container application`）之间提供更好的隔离性和连通性\n   连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。\n\n   比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。\n   如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或--publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。\n\n - 用户定义的桥接器在容器之间提供自动DNS解析\n   默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用`--link`选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。\n   还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（`--link`）。如果容器数量达到几十或者几百，那么工作量将会非常大。\n   \n - 容器可以在运行中与用户定义的网络连接和分离\n   \n - 每个用户定义的网络都会创建一个可配置的网桥\n   如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用`docker network create`创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。\n   ```\n   $ docker network create my-net\n   ```\n\n - 默认桥接网络上的链接容器共享环境变量\n   最初，在两个容器之间共享环境变量的唯一方法是使用--link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：\n\n   - 多个容器可以挂载包含共享信息的文件或目录，使用`Docker volume`挂载卷进行文件或者变量共享。\n\n   - 可以使用`docker-compose`一起启动多个容器，并且compose文件可以定义共享变量。\n\n   - 您可以使用集群服务（`swamp service`）而不是独立容器，并利用[`secrets`](https://docs.docker.com/engine/swarm/secrets/)和[`configs`](https://docs.docker.com/engine/swarm/configs/)共享变量。\n     ```\n\t docker service create \\\n     --name nginx \\\n     --secret site.key \\\n     --secret site.crt \\\n     --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n     --publish published=3000,target=443 \\\n     nginx:latest \\\n     sh -c \"exec nginx -g 'daemon off;'\"\n\t ```\n#### 创建用户自定义网桥（self-define ）\n\n- 使用命令`docker network create ` 命令创建用户自定义网络\n   \n   具体使用方法可以使用`docker network create --help`获取帮助  \n    ```\n    $ docker network create \\\n     --driver=bridge \\\n     --subnet=172.28.0.0/16 \\\n     --ip-range=172.28.5.0/24 \\\n     --gateway=172.28.5.254 \\\n        br0\n   ```\n\n- 使用命令`docker network rm `命令删除已存在的网络\n   ```\n   $ docker network rm my-net\n   ```\n当用户**删除**或**创建**网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改`iptables`规则）。这些操作对用户来说是透明的。\n\n#### 连接容器到自定义网络\n用户在创建容器时，可以指定连接到自定义网络（使用`--network`方式）；也可以将正在运行的（runing)的容器连接到自定义网络。\n\n - 创建容器，并连接到自定义网络\n\n   例如：创建`Nginx`容器，连接到`my-net`网络中\n   ```\n   $ docker create --name my-nginx \\\n      --network my-net \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   创建一个容器`my-nginx`，连接到已存在的`my-net` 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。\n\n - `running`容器连接到自定义网络中\n\n   启动`my-nignx`容器\n   ```\n   $ docker run --name my-nginx \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   连接到`my-net`自定义网络\n   ```\n   $ docker network connect my-net my-nginx\n   ```\n   如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。\n\n#### 修改Docker默认网桥\n修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件\n\n - 修改dockerd启动配置文件\n\n   dockerd启动文件默认位置：`/usr/lib/systemd/system/docker.service`\n   ```\n   ...\n   ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\\n     -H tcp://0.0.0.0:2376 \\\n     --bip=10.2.54.1/24 \\ \n     --mtu=1450 \\ \n     --dns=[\"10.20.1.2\",\"10.20.1.3\"]\n   ...\n   ```\n\n - daemon.json文件\n   ```\n   {\n      \"bip\": \"192.168.1.5/24\",\n      \"fixed-cidr\": \"192.168.1.5/25\",\n      \"fixed-cidr-v6\": \"2001:db8::/64\",\n      \"mtu\": 1500,\n      \"default-gateway\": \"10.20.1.1\",\n      \"default-gateway-v6\": \"2001:db8:abcd::89\",\n      \"dns\": [\"10.20.1.2\",\"10.20.1.3\"]\n   }\n   ```\n使参数生效，则需要重启Docker守护进程。\n\n\n\n\n\n\n\n","slug":"docker-network-bridge","published":1,"updated":"2019-03-25T05:45:06.757Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqt3001mhqxudwebylac","content":"<p>Docker网络驱动(network driver)之————网桥(bridge)</p>\n<blockquote>\n<p>在《计算机网络》这本教材中，我们学习过，<strong>网桥</strong>是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。</p>\n</blockquote>\n<p>在Docker的网络系统中，<strong>网桥</strong><code>bridge network</code>是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的<strong>容器</strong>之间进行通信，同时隔离那些未连接到该<strong>网桥</strong>的容器。当启动<code>Docker daemon</code>（<code>docker</code>守护进程)时，会自动创建<strong>网桥</strong>（<code>bridge network</code>），称为:<code>bridge</code>，即对应host上的<code>docker0</code>。<code>Docker network</code>会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。</p>\n<p>查看主机上的网络设备<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr </span><br><span class=\"line\">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class=\"line\">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class=\"line\">    inet 127.0.0.1/8 scope host lo</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 ::1/128 scope host </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class=\"line\">       valid_lft 84147sec preferred_lft 84147sec</span><br><span class=\"line\">    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8</span><br><span class=\"line\">       valid_lft 996sec preferred_lft 996sec</span><br><span class=\"line\">    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class=\"line\">    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 fe80::42:60ff:fee0:e955/64 scope link </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p>\n<p>查看docker网络驱动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">b549b06a92e7        bridge              bridge              local</span><br><span class=\"line\">c5149e25deea        host                host                local</span><br><span class=\"line\">bfa90bfc3dfe        none                null                local</span><br></pre></td></tr></table></figure></p>\n<p><strong>网桥</strong><code>bridge network</code>适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的<a href=\"https://docs.docker.com/network/overlay/\" target=\"_blank\" rel=\"noopener\">覆盖网络<code>overlay</code></a>和<a href=\"https://docs.docker.com/network/macvlan/\" target=\"_blank\" rel=\"noopener\"><code>macvlan</code></a>。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico</p>\n<p>如果用户启动一个新的容器（<code>container</code>），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（<code>self-defined bridge networks</code>）。<br><strong>自定义网桥</strong>在容器安全性、容器间通信等方面优于默认网桥（<code>bridge</code>）</p>\n<h4 id=\"用户定义的网桥与默认网桥之间的区别\"><a href=\"#用户定义的网桥与默认网桥之间的区别\" class=\"headerlink\" title=\"用户定义的网桥与默认网桥之间的区别\"></a>用户定义的网桥与默认网桥之间的区别</h4><ul>\n<li><p>用户定义的网桥可在容器化应用程序（<code>container application</code>）之间提供更好的隔离性和连通性<br>连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。</p>\n<p>比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。<br>如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或–publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。</p>\n</li>\n<li><p>用户定义的桥接器在容器之间提供自动DNS解析<br>默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用<code>--link</code>选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。<br>还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（<code>--link</code>）。如果容器数量达到几十或者几百，那么工作量将会非常大。</p>\n</li>\n<li><p>容器可以在运行中与用户定义的网络连接和分离</p>\n</li>\n<li><p>每个用户定义的网络都会创建一个可配置的网桥<br>如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用<code>docker network create</code>创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create my-net</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>默认桥接网络上的链接容器共享环境变量<br>最初，在两个容器之间共享环境变量的唯一方法是使用–link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：</p>\n<ul>\n<li><p>多个容器可以挂载包含共享信息的文件或目录，使用<code>Docker volume</code>挂载卷进行文件或者变量共享。</p>\n</li>\n<li><p>可以使用<code>docker-compose</code>一起启动多个容器，并且compose文件可以定义共享变量。</p>\n</li>\n<li><p>您可以使用集群服务（<code>swamp service</code>）而不是独立容器，并利用<a href=\"https://docs.docker.com/engine/swarm/secrets/\" target=\"_blank\" rel=\"noopener\"><code>secrets</code></a>和<a href=\"https://docs.docker.com/engine/swarm/configs/\" target=\"_blank\" rel=\"noopener\"><code>configs</code></a>共享变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker service create \\</span><br><span class=\"line\">   --name nginx \\</span><br><span class=\"line\">   --secret site.key \\</span><br><span class=\"line\">   --secret site.crt \\</span><br><span class=\"line\">   --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\</span><br><span class=\"line\">   --publish published=3000,target=443 \\</span><br><span class=\"line\">   nginx:latest \\</span><br><span class=\"line\">   sh -c &quot;exec nginx -g &apos;daemon off;&apos;&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"创建用户自定义网桥（self-define-）\"><a href=\"#创建用户自定义网桥（self-define-）\" class=\"headerlink\" title=\"创建用户自定义网桥（self-define ）\"></a>创建用户自定义网桥（self-define ）</h4><ul>\n<li><p>使用命令<code>docker network create</code> 命令创建用户自定义网络</p>\n<p> 具体使用方法可以使用<code>docker network create --help</code>获取帮助  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\"> --driver=bridge \\</span><br><span class=\"line\"> --subnet=172.28.0.0/16 \\</span><br><span class=\"line\"> --ip-range=172.28.5.0/24 \\</span><br><span class=\"line\"> --gateway=172.28.5.254 \\</span><br><span class=\"line\">    br0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用命令<code>docker network rm</code>命令删除已存在的网络</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm my-net</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>当用户<strong>删除</strong>或<strong>创建</strong>网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改<code>iptables</code>规则）。这些操作对用户来说是透明的。</p>\n<h4 id=\"连接容器到自定义网络\"><a href=\"#连接容器到自定义网络\" class=\"headerlink\" title=\"连接容器到自定义网络\"></a>连接容器到自定义网络</h4><p>用户在创建容器时，可以指定连接到自定义网络（使用<code>--network</code>方式）；也可以将正在运行的（runing)的容器连接到自定义网络。</p>\n<ul>\n<li><p>创建容器，并连接到自定义网络</p>\n<p>例如：创建<code>Nginx</code>容器，连接到<code>my-net</code>网络中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker create --name my-nginx \\</span><br><span class=\"line\">   --network my-net \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>创建一个容器<code>my-nginx</code>，连接到已存在的<code>my-net</code> 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。</p>\n</li>\n<li><p><code>running</code>容器连接到自定义网络中</p>\n<p>启动<code>my-nignx</code>容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --name my-nginx \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>连接到<code>my-net</code>自定义网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network connect my-net my-nginx</span><br></pre></td></tr></table></figure>\n<p>如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。</p>\n</li>\n</ul>\n<h4 id=\"修改Docker默认网桥\"><a href=\"#修改Docker默认网桥\" class=\"headerlink\" title=\"修改Docker默认网桥\"></a>修改Docker默认网桥</h4><p>修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件</p>\n<ul>\n<li><p>修改dockerd启动配置文件</p>\n<p>dockerd启动文件默认位置：<code>/usr/lib/systemd/system/docker.service</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\</span><br><span class=\"line\">  -H tcp://0.0.0.0:2376 \\</span><br><span class=\"line\">  --bip=10.2.54.1/24 \\ </span><br><span class=\"line\">  --mtu=1450 \\ </span><br><span class=\"line\">  --dns=[&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>daemon.json文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;bip&quot;: &quot;192.168.1.5/24&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,</span><br><span class=\"line\">   &quot;mtu&quot;: 1500,</span><br><span class=\"line\">   &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</span><br><span class=\"line\">   &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</span><br><span class=\"line\">   &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使参数生效，则需要重启Docker守护进程。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Docker网络驱动(network driver)之————网桥(bridge)</p>\n<blockquote>\n<p>在《计算机网络》这本教材中，我们学习过，<strong>网桥</strong>是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。</p>\n</blockquote>\n<p>在Docker的网络系统中，<strong>网桥</strong><code>bridge network</code>是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的<strong>容器</strong>之间进行通信，同时隔离那些未连接到该<strong>网桥</strong>的容器。当启动<code>Docker daemon</code>（<code>docker</code>守护进程)时，会自动创建<strong>网桥</strong>（<code>bridge network</code>），称为:<code>bridge</code>，即对应host上的<code>docker0</code>。<code>Docker network</code>会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。</p>\n<p>查看主机上的网络设备<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr </span><br><span class=\"line\">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class=\"line\">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class=\"line\">    inet 127.0.0.1/8 scope host lo</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 ::1/128 scope host </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class=\"line\">       valid_lft 84147sec preferred_lft 84147sec</span><br><span class=\"line\">    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8</span><br><span class=\"line\">       valid_lft 996sec preferred_lft 996sec</span><br><span class=\"line\">    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class=\"line\">    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 fe80::42:60ff:fee0:e955/64 scope link </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p>\n<p>查看docker网络驱动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">b549b06a92e7        bridge              bridge              local</span><br><span class=\"line\">c5149e25deea        host                host                local</span><br><span class=\"line\">bfa90bfc3dfe        none                null                local</span><br></pre></td></tr></table></figure></p>\n<p><strong>网桥</strong><code>bridge network</code>适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的<a href=\"https://docs.docker.com/network/overlay/\" target=\"_blank\" rel=\"noopener\">覆盖网络<code>overlay</code></a>和<a href=\"https://docs.docker.com/network/macvlan/\" target=\"_blank\" rel=\"noopener\"><code>macvlan</code></a>。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico</p>\n<p>如果用户启动一个新的容器（<code>container</code>），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（<code>self-defined bridge networks</code>）。<br><strong>自定义网桥</strong>在容器安全性、容器间通信等方面优于默认网桥（<code>bridge</code>）</p>\n<h4 id=\"用户定义的网桥与默认网桥之间的区别\"><a href=\"#用户定义的网桥与默认网桥之间的区别\" class=\"headerlink\" title=\"用户定义的网桥与默认网桥之间的区别\"></a>用户定义的网桥与默认网桥之间的区别</h4><ul>\n<li><p>用户定义的网桥可在容器化应用程序（<code>container application</code>）之间提供更好的隔离性和连通性<br>连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。</p>\n<p>比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。<br>如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或–publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。</p>\n</li>\n<li><p>用户定义的桥接器在容器之间提供自动DNS解析<br>默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用<code>--link</code>选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。<br>还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（<code>--link</code>）。如果容器数量达到几十或者几百，那么工作量将会非常大。</p>\n</li>\n<li><p>容器可以在运行中与用户定义的网络连接和分离</p>\n</li>\n<li><p>每个用户定义的网络都会创建一个可配置的网桥<br>如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用<code>docker network create</code>创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create my-net</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>默认桥接网络上的链接容器共享环境变量<br>最初，在两个容器之间共享环境变量的唯一方法是使用–link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：</p>\n<ul>\n<li><p>多个容器可以挂载包含共享信息的文件或目录，使用<code>Docker volume</code>挂载卷进行文件或者变量共享。</p>\n</li>\n<li><p>可以使用<code>docker-compose</code>一起启动多个容器，并且compose文件可以定义共享变量。</p>\n</li>\n<li><p>您可以使用集群服务（<code>swamp service</code>）而不是独立容器，并利用<a href=\"https://docs.docker.com/engine/swarm/secrets/\" target=\"_blank\" rel=\"noopener\"><code>secrets</code></a>和<a href=\"https://docs.docker.com/engine/swarm/configs/\" target=\"_blank\" rel=\"noopener\"><code>configs</code></a>共享变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker service create \\</span><br><span class=\"line\">   --name nginx \\</span><br><span class=\"line\">   --secret site.key \\</span><br><span class=\"line\">   --secret site.crt \\</span><br><span class=\"line\">   --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\</span><br><span class=\"line\">   --publish published=3000,target=443 \\</span><br><span class=\"line\">   nginx:latest \\</span><br><span class=\"line\">   sh -c &quot;exec nginx -g &apos;daemon off;&apos;&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"创建用户自定义网桥（self-define-）\"><a href=\"#创建用户自定义网桥（self-define-）\" class=\"headerlink\" title=\"创建用户自定义网桥（self-define ）\"></a>创建用户自定义网桥（self-define ）</h4><ul>\n<li><p>使用命令<code>docker network create</code> 命令创建用户自定义网络</p>\n<p> 具体使用方法可以使用<code>docker network create --help</code>获取帮助  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\"> --driver=bridge \\</span><br><span class=\"line\"> --subnet=172.28.0.0/16 \\</span><br><span class=\"line\"> --ip-range=172.28.5.0/24 \\</span><br><span class=\"line\"> --gateway=172.28.5.254 \\</span><br><span class=\"line\">    br0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用命令<code>docker network rm</code>命令删除已存在的网络</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm my-net</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>当用户<strong>删除</strong>或<strong>创建</strong>网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改<code>iptables</code>规则）。这些操作对用户来说是透明的。</p>\n<h4 id=\"连接容器到自定义网络\"><a href=\"#连接容器到自定义网络\" class=\"headerlink\" title=\"连接容器到自定义网络\"></a>连接容器到自定义网络</h4><p>用户在创建容器时，可以指定连接到自定义网络（使用<code>--network</code>方式）；也可以将正在运行的（runing)的容器连接到自定义网络。</p>\n<ul>\n<li><p>创建容器，并连接到自定义网络</p>\n<p>例如：创建<code>Nginx</code>容器，连接到<code>my-net</code>网络中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker create --name my-nginx \\</span><br><span class=\"line\">   --network my-net \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>创建一个容器<code>my-nginx</code>，连接到已存在的<code>my-net</code> 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。</p>\n</li>\n<li><p><code>running</code>容器连接到自定义网络中</p>\n<p>启动<code>my-nignx</code>容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --name my-nginx \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>连接到<code>my-net</code>自定义网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network connect my-net my-nginx</span><br></pre></td></tr></table></figure>\n<p>如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。</p>\n</li>\n</ul>\n<h4 id=\"修改Docker默认网桥\"><a href=\"#修改Docker默认网桥\" class=\"headerlink\" title=\"修改Docker默认网桥\"></a>修改Docker默认网桥</h4><p>修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件</p>\n<ul>\n<li><p>修改dockerd启动配置文件</p>\n<p>dockerd启动文件默认位置：<code>/usr/lib/systemd/system/docker.service</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\</span><br><span class=\"line\">  -H tcp://0.0.0.0:2376 \\</span><br><span class=\"line\">  --bip=10.2.54.1/24 \\ </span><br><span class=\"line\">  --mtu=1450 \\ </span><br><span class=\"line\">  --dns=[&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>daemon.json文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;bip&quot;: &quot;192.168.1.5/24&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,</span><br><span class=\"line\">   &quot;mtu&quot;: 1500,</span><br><span class=\"line\">   &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</span><br><span class=\"line\">   &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</span><br><span class=\"line\">   &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使参数生效，则需要重启Docker守护进程。</p>\n"},{"title":"NGINX Ingress Controller教程","date":"2019-01-25T16:26:10.000Z","_content":"\n## NGINX Ingress Controller\n[TOC]\n### Bare-metal considerations\n - MetalLB\n`MetalLB`提供了一个不仅仅只有云服务商才可提供的在`kubernetes`集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。\n本教程介绍使用[ **Layer 2 configuration mode**](https://metallb.universe.tf/tutorial/layer2/) [**MetalLB**](https://metallb.universe.tf/)和`NGINX Ingress controller`在集群中有公开访问的节点。在此模式下，一个节点吸引`ingress-nginx`服务IP的所有流量。\n**MetalLB:Layer2**\n![MetalLB:Layer2](/images/metallb.jpg)\n例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <None>)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n依照下方`yaml`文件创建`ComfigMap`, MetalLB获得池中其中一个IP地址的所有权，并相应地更新`ingress-nginx`服务的`loadBalancer IP`字段。.\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 203.0.113.2-203.0.113.3\n```\n```\n$ kubectl -n ingress-nginx get svc\nNAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)\ndefault-http-backend   ClusterIP     10.0.64.249    <none>       80/TCP\ningress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP\n```\n----\n - ##### Over a NodePort Service\n 在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配`ingress-nginx service`的`Type`为`Nodeport`。\n ![Over a NodePort Service](/images/nodeport.jpg)\n 例如：Given the NodePort 30100 allocated to the ingress-nginx Service\n ```\n$ kubectl get svc -n ingress-nginx\nNAME                   TYPE        CLUSTER-IP     PORT(S)\ndefault-http-backend   ClusterIP   10.0.64.249    80/TCP\ningress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n ```\n 其中一个`Node`节点的IP地址为203.0.113.2 (`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n客户端可通过`http://myapp.example.com:30100`与配置`host`:`myapp.example.com`的`Ingress`进行通信，` myapp.example.com` 子域解析为203.0.113.2地址。\n这种方法还有一些应该注意的其他限制\n  - **Source IP address**\n    Services of type NodePort perform source address translation by default。这意味着：HTTP请求的`source IP`始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。\n\t建议通过设置`ingress-nginx Service`的`spec.externalTrafficPolicy`的属性域为`local`（[例如](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14)），来保留`source IP`\n\t```yaml\n\tkind: Service\n\tapiVersion: v1\n\tmetadata:\n\t  name: ingress-nginx\n\t  namespace: ingress-nginx\n\t  ...\n\tspec:\n\t  # this setting is t make sure the source IP address is preserved.\n\t  externalTrafficPolicy: Local\n\t  type: LoadBalancer\n\t  ...\n\t  ports:\n\t  - name: http\n\t\tport: 80\n\t\ttargetPort: http\n\t  ...\n\t```\n\t例如一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\tnginx-ingress-controller的Deployment 有两个副本集`replicas`\n\t```\n\t$ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP           NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2\n\tnginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3\n\tnginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2\n\t```\n\t到`host-2`和`host-3`的请求将被转发到 `NGINX`并且原始的客户端IP将被保留，但是请求到`host-1`的`Node`的请求将被丢弃，因为在该`Node`上没有`NGINX`副本集。\n\t\n  - **Ingress status**\n    因为`NodePort`类型的`Service`没有按定义分配`LoadBalancerIP`，`NGINX Ingress controller`不会更新`Ingress`对象的状态。\n\t```\n\t$ kubectl get ingress\n    NAME           HOSTS               ADDRESS   PORTS\n    test-ingress   myapp.example.com             80\n\t```\n\t尽管没有负载均衡器为`NGINX Ingress Controller`提供公共IP地址，但可以通过设置`ingress-nginx Service`的`externalIPs`字段来强制所有管理的Ingress对象的状态更新。\n\t例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\t可以编辑`ingress-nginx Service` 添加如下代码片段到到属性域`spec`中：\n\t```\n\t...\n\tspec:\n\t  externalIPs:\n\t  - 203.0.113.1\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n\t...\n\t```\n\t如此，将会在`Ingress`对象上生效：\n\t```\n\t$ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                               PORTS\n\ttest-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80\n\t```\n  - **Redirects**\n  > As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.\n   \n    由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。\n\t举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to www.domain, are generated without NodePort:\n\t```\n\t$ curl -D- http://myapp.example.com:30100\n\tHTTP/1.1 308 Permanent Redirect\n\tServer: nginx/1.15.2\n\tLocation: https://myapp.example.com/  #-> missing NodePort in HTTPS redirect\n\t```\n----\n - ##### Via the host network\n   在没有可用的外部负载均衡器的设置中，但不能使用`NodePorts`。还有一种方法就是，通过设置`ingress-nginx`的Pods使用**主机网络**，而不是专用的网络命名空间(`network namespace`)。该方案的好处就是，在没有额外的`NodePort Service`提供的外部网络转换情况下，`NGINX Ingress controller`可以直接绑定k8s的`Node`网络接口的端口80或443。\n   这可以通过配置Pods属性域`template.spec`的`hostNetwork`选项来实现：\n   ```\n   template:\n\t  spec:\n\t\thostNetwork: true\n   ```\n   注意：\n   启用此选项会将所有系统守护进程暴露给任何网络接口上的`NGINX Ingress Controller`，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。\n   例如：`nginx-ingress-controller`Deployment有两个副本集，`NGINX` PodsN继承其主机的IP地址，而不是内部 Pod IP\n   ```\n   $ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n   ```\n   该部署方式的主要限制是：每个群集节点上只能安排一个`NGINX Ingress Controller` Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，\n   ```\n   $ kubectl -n ingress-nginx describe pod <unschedulable-nginx-ingress-controller-pod>\n\t...\n\tEvents:\n\t  Type     Reason            From               Message\n\t  ----     ------            ----               -------\n\t  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn't have free ports for the requested pod ports.\n   ```\n   确保仅创建可调度Pod的一种方法是将`NGINX Ingress Controller`部署为`DaemonSet`而不是传统的`Deployment`。\n   ![hostnetwork](/images/hostnetwork.jpg)\n   与NodePorts一样，这种方法有一些怪癖，重要的是要注意\n     - **DNS resolution**\n     如果Pods配置了`hostNetwork: true`属性，则不使用内部DNS解析器(`kube-dns`或`CoreDns`)，除非Pods的`spec.dnsPolicy`配置了`ClusterFirstWithHostNet`属性。\n\t \n     - **Ingress status**\n     由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认--publish-service标志不适用，并且所有Ingress对象的状态保持空白。\n\t ```\n\t $ kubectl get ingress\n\tNAME           HOSTS               ADDRESS   PORTS\n\ttest-ingress   myapp.example.com             80\n\t ```\n\t 相反，由于`bare-metal`Node通常没有`Extral IP`，因此必须启用`--report-node-internal-ip-address`，它将所有Ingress对象的状态设置为运行`NGINX Ingress Controller`的所有节点的内部IP地址。\n\t Given a nginx-ingress-controller DaemonSet composed of 2 replicas\n\t ```\n\t $ kubectl -n ingress-nginx get pod -o wide\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n\t ```\n\t 控制器将其管理的所有Ingress对象的状态设置为以下值：\n\t ```\n\t $ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                   PORTS\n\ttest-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80\n\t ```\n - ##### Using a self-provisioned edge\n   与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。\n   此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。\n   边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：\n   ![Using a self-provisioned edge](/images/user_edge.jpg)\n   根据官方Kubernetes文档的“服务”页面，`externalIPs`选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的`endpoints`。这些IP地址必须属于目标节点(target node)。\n   > 例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n    ```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n    ```\n   and the following ingress-nginx NodePort Service\n   ```\n   $ kubectl -n ingress-nginx get svc\n   NAME                   TYPE        CLUSTER-IP     PORT(S)\n   ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n   ```\n   我们可以在`Service`的`spec.externalIPs`属性域中设置**externalIPs**, 则**NGINX**通过`NodePort`和`Service Port`变的可达：\n   ```\n   spec:\n\t  externalIPs:\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n   ```\n   ```\n   $ curl -D- http://myapp.example.com:30100\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   $ curl -D- http://myapp.example.com\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   ```\n   我们假设 `myapp.example.com` 域名解析成IP地址：203.0.113.2 和 203.0.113.3。\n\n\n\n","source":"_posts/2019-03-25-nginx-ingress-controller-introduct.md","raw":"---\ntitle: NGINX Ingress Controller教程\ndate: 2019-01-25 16:26:10\ntags:\n  - kubernetes\ncategories:\n  - 运维\n  - kubernetes\n\n---\n\n## NGINX Ingress Controller\n[TOC]\n### Bare-metal considerations\n - MetalLB\n`MetalLB`提供了一个不仅仅只有云服务商才可提供的在`kubernetes`集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。\n本教程介绍使用[ **Layer 2 configuration mode**](https://metallb.universe.tf/tutorial/layer2/) [**MetalLB**](https://metallb.universe.tf/)和`NGINX Ingress controller`在集群中有公开访问的节点。在此模式下，一个节点吸引`ingress-nginx`服务IP的所有流量。\n**MetalLB:Layer2**\n![MetalLB:Layer2](/images/metallb.jpg)\n例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <None>)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n依照下方`yaml`文件创建`ComfigMap`, MetalLB获得池中其中一个IP地址的所有权，并相应地更新`ingress-nginx`服务的`loadBalancer IP`字段。.\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 203.0.113.2-203.0.113.3\n```\n```\n$ kubectl -n ingress-nginx get svc\nNAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)\ndefault-http-backend   ClusterIP     10.0.64.249    <none>       80/TCP\ningress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP\n```\n----\n - ##### Over a NodePort Service\n 在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配`ingress-nginx service`的`Type`为`Nodeport`。\n ![Over a NodePort Service](/images/nodeport.jpg)\n 例如：Given the NodePort 30100 allocated to the ingress-nginx Service\n ```\n$ kubectl get svc -n ingress-nginx\nNAME                   TYPE        CLUSTER-IP     PORT(S)\ndefault-http-backend   ClusterIP   10.0.64.249    80/TCP\ningress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n ```\n 其中一个`Node`节点的IP地址为203.0.113.2 (`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n客户端可通过`http://myapp.example.com:30100`与配置`host`:`myapp.example.com`的`Ingress`进行通信，` myapp.example.com` 子域解析为203.0.113.2地址。\n这种方法还有一些应该注意的其他限制\n  - **Source IP address**\n    Services of type NodePort perform source address translation by default。这意味着：HTTP请求的`source IP`始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。\n\t建议通过设置`ingress-nginx Service`的`spec.externalTrafficPolicy`的属性域为`local`（[例如](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14)），来保留`source IP`\n\t```yaml\n\tkind: Service\n\tapiVersion: v1\n\tmetadata:\n\t  name: ingress-nginx\n\t  namespace: ingress-nginx\n\t  ...\n\tspec:\n\t  # this setting is t make sure the source IP address is preserved.\n\t  externalTrafficPolicy: Local\n\t  type: LoadBalancer\n\t  ...\n\t  ports:\n\t  - name: http\n\t\tport: 80\n\t\ttargetPort: http\n\t  ...\n\t```\n\t例如一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\tnginx-ingress-controller的Deployment 有两个副本集`replicas`\n\t```\n\t$ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP           NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2\n\tnginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3\n\tnginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2\n\t```\n\t到`host-2`和`host-3`的请求将被转发到 `NGINX`并且原始的客户端IP将被保留，但是请求到`host-1`的`Node`的请求将被丢弃，因为在该`Node`上没有`NGINX`副本集。\n\t\n  - **Ingress status**\n    因为`NodePort`类型的`Service`没有按定义分配`LoadBalancerIP`，`NGINX Ingress controller`不会更新`Ingress`对象的状态。\n\t```\n\t$ kubectl get ingress\n    NAME           HOSTS               ADDRESS   PORTS\n    test-ingress   myapp.example.com             80\n\t```\n\t尽管没有负载均衡器为`NGINX Ingress Controller`提供公共IP地址，但可以通过设置`ingress-nginx Service`的`externalIPs`字段来强制所有管理的Ingress对象的状态更新。\n\t例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\t可以编辑`ingress-nginx Service` 添加如下代码片段到到属性域`spec`中：\n\t```\n\t...\n\tspec:\n\t  externalIPs:\n\t  - 203.0.113.1\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n\t...\n\t```\n\t如此，将会在`Ingress`对象上生效：\n\t```\n\t$ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                               PORTS\n\ttest-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80\n\t```\n  - **Redirects**\n  > As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.\n   \n    由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。\n\t举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to www.domain, are generated without NodePort:\n\t```\n\t$ curl -D- http://myapp.example.com:30100\n\tHTTP/1.1 308 Permanent Redirect\n\tServer: nginx/1.15.2\n\tLocation: https://myapp.example.com/  #-> missing NodePort in HTTPS redirect\n\t```\n----\n - ##### Via the host network\n   在没有可用的外部负载均衡器的设置中，但不能使用`NodePorts`。还有一种方法就是，通过设置`ingress-nginx`的Pods使用**主机网络**，而不是专用的网络命名空间(`network namespace`)。该方案的好处就是，在没有额外的`NodePort Service`提供的外部网络转换情况下，`NGINX Ingress controller`可以直接绑定k8s的`Node`网络接口的端口80或443。\n   这可以通过配置Pods属性域`template.spec`的`hostNetwork`选项来实现：\n   ```\n   template:\n\t  spec:\n\t\thostNetwork: true\n   ```\n   注意：\n   启用此选项会将所有系统守护进程暴露给任何网络接口上的`NGINX Ingress Controller`，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。\n   例如：`nginx-ingress-controller`Deployment有两个副本集，`NGINX` PodsN继承其主机的IP地址，而不是内部 Pod IP\n   ```\n   $ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n   ```\n   该部署方式的主要限制是：每个群集节点上只能安排一个`NGINX Ingress Controller` Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，\n   ```\n   $ kubectl -n ingress-nginx describe pod <unschedulable-nginx-ingress-controller-pod>\n\t...\n\tEvents:\n\t  Type     Reason            From               Message\n\t  ----     ------            ----               -------\n\t  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn't have free ports for the requested pod ports.\n   ```\n   确保仅创建可调度Pod的一种方法是将`NGINX Ingress Controller`部署为`DaemonSet`而不是传统的`Deployment`。\n   ![hostnetwork](/images/hostnetwork.jpg)\n   与NodePorts一样，这种方法有一些怪癖，重要的是要注意\n     - **DNS resolution**\n     如果Pods配置了`hostNetwork: true`属性，则不使用内部DNS解析器(`kube-dns`或`CoreDns`)，除非Pods的`spec.dnsPolicy`配置了`ClusterFirstWithHostNet`属性。\n\t \n     - **Ingress status**\n     由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认--publish-service标志不适用，并且所有Ingress对象的状态保持空白。\n\t ```\n\t $ kubectl get ingress\n\tNAME           HOSTS               ADDRESS   PORTS\n\ttest-ingress   myapp.example.com             80\n\t ```\n\t 相反，由于`bare-metal`Node通常没有`Extral IP`，因此必须启用`--report-node-internal-ip-address`，它将所有Ingress对象的状态设置为运行`NGINX Ingress Controller`的所有节点的内部IP地址。\n\t Given a nginx-ingress-controller DaemonSet composed of 2 replicas\n\t ```\n\t $ kubectl -n ingress-nginx get pod -o wide\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n\t ```\n\t 控制器将其管理的所有Ingress对象的状态设置为以下值：\n\t ```\n\t $ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                   PORTS\n\ttest-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80\n\t ```\n - ##### Using a self-provisioned edge\n   与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。\n   此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。\n   边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：\n   ![Using a self-provisioned edge](/images/user_edge.jpg)\n   根据官方Kubernetes文档的“服务”页面，`externalIPs`选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的`endpoints`。这些IP地址必须属于目标节点(target node)。\n   > 例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n    ```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n    ```\n   and the following ingress-nginx NodePort Service\n   ```\n   $ kubectl -n ingress-nginx get svc\n   NAME                   TYPE        CLUSTER-IP     PORT(S)\n   ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n   ```\n   我们可以在`Service`的`spec.externalIPs`属性域中设置**externalIPs**, 则**NGINX**通过`NodePort`和`Service Port`变的可达：\n   ```\n   spec:\n\t  externalIPs:\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n   ```\n   ```\n   $ curl -D- http://myapp.example.com:30100\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   $ curl -D- http://myapp.example.com\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   ```\n   我们假设 `myapp.example.com` 域名解析成IP地址：203.0.113.2 和 203.0.113.3。\n\n\n\n","slug":"nginx-ingress-controller-introduct","published":1,"updated":"2019-03-25T08:37:21.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjto6rqt5001ohqxufu3os4ji","content":"<h2 id=\"NGINX-Ingress-Controller\"><a href=\"#NGINX-Ingress-Controller\" class=\"headerlink\" title=\"NGINX Ingress Controller\"></a>NGINX Ingress Controller</h2><p>[TOC]</p>\n<h3 id=\"Bare-metal-considerations\"><a href=\"#Bare-metal-considerations\" class=\"headerlink\" title=\"Bare-metal considerations\"></a>Bare-metal considerations</h3><ul>\n<li>MetalLB<br><code>MetalLB</code>提供了一个不仅仅只有云服务商才可提供的在<code>kubernetes</code>集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。<br>本教程介绍使用<a href=\"https://metallb.universe.tf/tutorial/layer2/\" target=\"_blank\" rel=\"noopener\"> <strong>Layer 2 configuration mode</strong></a> <a href=\"https://metallb.universe.tf/\" target=\"_blank\" rel=\"noopener\"><strong>MetalLB</strong></a>和<code>NGINX Ingress controller</code>在集群中有公开访问的节点。在此模式下，一个节点吸引<code>ingress-nginx</code>服务IP的所有流量。<br><strong>MetalLB:Layer2</strong><br><img src=\"/images/metallb.jpg\" alt=\"MetalLB:Layer2\"><br>例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <none>)<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</none></li>\n</ul>\n<p>依照下方<code>yaml</code>文件创建<code>ComfigMap</code>, MetalLB获得池中其中一个IP地址的所有权，并相应地更新<code>ingress-nginx</code>服务的<code>loadBalancer IP</code>字段。.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: metallb-system</span><br><span class=\"line\">  name: config</span><br><span class=\"line\">data:</span><br><span class=\"line\">  config: |</span><br><span class=\"line\">    address-pools:</span><br><span class=\"line\">    - name: default</span><br><span class=\"line\">      protocol: layer2</span><br><span class=\"line\">      addresses:</span><br><span class=\"line\">      - 203.0.113.2-203.0.113.3</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP     10.0.64.249    &lt;none&gt;       80/TCP</span><br><span class=\"line\">ingress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li><h5 id=\"Over-a-NodePort-Service\"><a href=\"#Over-a-NodePort-Service\" class=\"headerlink\" title=\"Over a NodePort Service\"></a>Over a NodePort Service</h5><p>在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配<code>ingress-nginx service</code>的<code>Type</code>为<code>Nodeport</code>。<br><img src=\"/images/nodeport.jpg\" alt=\"Over a NodePort Service\"><br>例如：Given the NodePort 30100 allocated to the ingress-nginx Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get svc -n ingress-nginx</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP   10.0.64.249    80/TCP</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>其中一个<code>Node</code>节点的IP地址为203.0.113.2 (<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>客户端可通过<code>http://myapp.example.com:30100</code>与配置<code>host</code>:<code>myapp.example.com</code>的<code>Ingress</code>进行通信，<code>myapp.example.com</code> 子域解析为203.0.113.2地址。<br>这种方法还有一些应该注意的其他限制</p>\n<ul>\n<li><p><strong>Source IP address</strong><br>Services of type NodePort perform source address translation by default。这意味着：HTTP请求的<code>source IP</code>始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。<br>建议通过设置<code>ingress-nginx Service</code>的<code>spec.externalTrafficPolicy</code>的属性域为<code>local</code>（<a href=\"https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14\" target=\"_blank\" rel=\"noopener\">例如</a>），来保留<code>source IP</code></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"comment\"># this setting is t make sure the source IP address is preserved.</span></span><br><span class=\"line\"><span class=\"attr\">  externalTrafficPolicy:</span> <span class=\"string\">Local</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">LoadBalancer</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">  ports:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">http</span></span><br><span class=\"line\">\t<span class=\"attr\">port:</span> <span class=\"number\">80</span></span><br><span class=\"line\">\t<span class=\"attr\">targetPort:</span> <span class=\"string\">http</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>例如一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>nginx-ingress-controller的Deployment 有两个副本集<code>replicas</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP           NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2</span><br></pre></td></tr></table></figure>\n<p>到<code>host-2</code>和<code>host-3</code>的请求将被转发到 <code>NGINX</code>并且原始的客户端IP将被保留，但是请求到<code>host-1</code>的<code>Node</code>的请求将被丢弃，因为在该<code>Node</code>上没有<code>NGINX</code>副本集。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>因为<code>NodePort</code>类型的<code>Service</code>没有按定义分配<code>LoadBalancerIP</code>，<code>NGINX Ingress controller</code>不会更新<code>Ingress</code>对象的状态。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress</span><br><span class=\"line\">   NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">   test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>尽管没有负载均衡器为<code>NGINX Ingress Controller</code>提供公共IP地址，但可以通过设置<code>ingress-nginx Service</code>的<code>externalIPs</code>字段来强制所有管理的Ingress对象的状态更新。<br>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>可以编辑<code>ingress-nginx Service</code> 添加如下代码片段到到属性域<code>spec</code>中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  externalIPs:</span><br><span class=\"line\">  - 203.0.113.1</span><br><span class=\"line\">  - 203.0.113.2</span><br><span class=\"line\">  - 203.0.113.3</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>如此，将会在<code>Ingress</code>对象上生效：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                               PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>Redirects</strong></p>\n<blockquote>\n<p>As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.</p>\n</blockquote>\n<p>由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。<br>举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to <a href=\"http://www.domain\" target=\"_blank\" rel=\"noopener\">www.domain</a>, are generated without NodePort:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 308 Permanent Redirect</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">Location: https://myapp.example.com/  #-&gt; missing NodePort in HTTPS redirect</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h5 id=\"Via-the-host-network\"><a href=\"#Via-the-host-network\" class=\"headerlink\" title=\"Via the host network\"></a>Via the host network</h5><p>在没有可用的外部负载均衡器的设置中，但不能使用<code>NodePorts</code>。还有一种方法就是，通过设置<code>ingress-nginx</code>的Pods使用<strong>主机网络</strong>，而不是专用的网络命名空间(<code>network namespace</code>)。该方案的好处就是，在没有额外的<code>NodePort Service</code>提供的外部网络转换情况下，<code>NGINX Ingress controller</code>可以直接绑定k8s的<code>Node</code>网络接口的端口80或443。<br>这可以通过配置Pods属性域<code>template.spec</code>的<code>hostNetwork</code>选项来实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> template:</span><br><span class=\"line\"> spec:</span><br><span class=\"line\">hostNetwork: true</span><br></pre></td></tr></table></figure>\n<p>注意：<br>启用此选项会将所有系统守护进程暴露给任何网络接口上的<code>NGINX Ingress Controller</code>，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。<br>例如：<code>nginx-ingress-controller</code>Deployment有两个副本集，<code>NGINX</code> PodsN继承其主机的IP地址，而不是内部 Pod IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>该部署方式的主要限制是：每个群集节点上只能安排一个<code>NGINX Ingress Controller</code> Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl -n ingress-nginx describe pod &lt;unschedulable-nginx-ingress-controller-pod&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason            From               Message</span><br><span class=\"line\">  ----     ------            ----               -------</span><br><span class=\"line\">  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn&apos;t have free ports for the requested pod ports.</span><br></pre></td></tr></table></figure>\n<p>确保仅创建可调度Pod的一种方法是将<code>NGINX Ingress Controller</code>部署为<code>DaemonSet</code>而不是传统的<code>Deployment</code>。<br><img src=\"/images/hostnetwork.jpg\" alt=\"hostnetwork\"><br>与NodePorts一样，这种方法有一些怪癖，重要的是要注意</p>\n<ul>\n<li><p><strong>DNS resolution</strong><br>如果Pods配置了<code>hostNetwork: true</code>属性，则不使用内部DNS解析器(<code>kube-dns</code>或<code>CoreDns</code>)，除非Pods的<code>spec.dnsPolicy</code>配置了<code>ClusterFirstWithHostNet</code>属性。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认–publish-service标志不适用，并且所有Ingress对象的状态保持空白。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress</span><br><span class=\"line\">NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>相反，由于<code>bare-metal</code>Node通常没有<code>Extral IP</code>，因此必须启用<code>--report-node-internal-ip-address</code>，它将所有Ingress对象的状态设置为运行<code>NGINX Ingress Controller</code>的所有节点的内部IP地址。<br>Given a nginx-ingress-controller DaemonSet composed of 2 replicas</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl -n ingress-nginx get pod -o wide</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>控制器将其管理的所有Ingress对象的状态设置为以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><h5 id=\"Using-a-self-provisioned-edge\"><a href=\"#Using-a-self-provisioned-edge\" class=\"headerlink\" title=\"Using a self-provisioned edge\"></a>Using a self-provisioned edge</h5><p>与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。<br>此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。<br>边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：<br><img src=\"/images/user_edge.jpg\" alt=\"Using a self-provisioned edge\"><br>根据官方Kubernetes文档的“服务”页面，<code>externalIPs</code>选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的<code>endpoints</code>。这些IP地址必须属于目标节点(target node)。</p>\n<blockquote>\n<p>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>and the following ingress-nginx NodePort Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>我们可以在<code>Service</code>的<code>spec.externalIPs</code>属性域中设置<strong>externalIPs</strong>, 则<strong>NGINX</strong>通过<code>NodePort</code>和<code>Service Port</code>变的可达：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">externalIPs:</span><br><span class=\"line\">- 203.0.113.2</span><br><span class=\"line\">- 203.0.113.3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">$ curl -D- http://myapp.example.com</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br></pre></td></tr></table></figure>\n<p>我们假设 <code>myapp.example.com</code> 域名解析成IP地址：203.0.113.2 和 203.0.113.3。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"NGINX-Ingress-Controller\"><a href=\"#NGINX-Ingress-Controller\" class=\"headerlink\" title=\"NGINX Ingress Controller\"></a>NGINX Ingress Controller</h2><p>[TOC]</p>\n<h3 id=\"Bare-metal-considerations\"><a href=\"#Bare-metal-considerations\" class=\"headerlink\" title=\"Bare-metal considerations\"></a>Bare-metal considerations</h3><ul>\n<li>MetalLB<br><code>MetalLB</code>提供了一个不仅仅只有云服务商才可提供的在<code>kubernetes</code>集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。<br>本教程介绍使用<a href=\"https://metallb.universe.tf/tutorial/layer2/\" target=\"_blank\" rel=\"noopener\"> <strong>Layer 2 configuration mode</strong></a> <a href=\"https://metallb.universe.tf/\" target=\"_blank\" rel=\"noopener\"><strong>MetalLB</strong></a>和<code>NGINX Ingress controller</code>在集群中有公开访问的节点。在此模式下，一个节点吸引<code>ingress-nginx</code>服务IP的所有流量。<br><strong>MetalLB:Layer2</strong><br><img src=\"/images/metallb.jpg\" alt=\"MetalLB:Layer2\"><br>例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <none>)<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</none></li>\n</ul>\n<p>依照下方<code>yaml</code>文件创建<code>ComfigMap</code>, MetalLB获得池中其中一个IP地址的所有权，并相应地更新<code>ingress-nginx</code>服务的<code>loadBalancer IP</code>字段。.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: metallb-system</span><br><span class=\"line\">  name: config</span><br><span class=\"line\">data:</span><br><span class=\"line\">  config: |</span><br><span class=\"line\">    address-pools:</span><br><span class=\"line\">    - name: default</span><br><span class=\"line\">      protocol: layer2</span><br><span class=\"line\">      addresses:</span><br><span class=\"line\">      - 203.0.113.2-203.0.113.3</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP     10.0.64.249    &lt;none&gt;       80/TCP</span><br><span class=\"line\">ingress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li><h5 id=\"Over-a-NodePort-Service\"><a href=\"#Over-a-NodePort-Service\" class=\"headerlink\" title=\"Over a NodePort Service\"></a>Over a NodePort Service</h5><p>在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配<code>ingress-nginx service</code>的<code>Type</code>为<code>Nodeport</code>。<br><img src=\"/images/nodeport.jpg\" alt=\"Over a NodePort Service\"><br>例如：Given the NodePort 30100 allocated to the ingress-nginx Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get svc -n ingress-nginx</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP   10.0.64.249    80/TCP</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>其中一个<code>Node</code>节点的IP地址为203.0.113.2 (<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>客户端可通过<code>http://myapp.example.com:30100</code>与配置<code>host</code>:<code>myapp.example.com</code>的<code>Ingress</code>进行通信，<code>myapp.example.com</code> 子域解析为203.0.113.2地址。<br>这种方法还有一些应该注意的其他限制</p>\n<ul>\n<li><p><strong>Source IP address</strong><br>Services of type NodePort perform source address translation by default。这意味着：HTTP请求的<code>source IP</code>始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。<br>建议通过设置<code>ingress-nginx Service</code>的<code>spec.externalTrafficPolicy</code>的属性域为<code>local</code>（<a href=\"https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14\" target=\"_blank\" rel=\"noopener\">例如</a>），来保留<code>source IP</code></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"comment\"># this setting is t make sure the source IP address is preserved.</span></span><br><span class=\"line\"><span class=\"attr\">  externalTrafficPolicy:</span> <span class=\"string\">Local</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">LoadBalancer</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">  ports:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">http</span></span><br><span class=\"line\">\t<span class=\"attr\">port:</span> <span class=\"number\">80</span></span><br><span class=\"line\">\t<span class=\"attr\">targetPort:</span> <span class=\"string\">http</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>例如一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>nginx-ingress-controller的Deployment 有两个副本集<code>replicas</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP           NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2</span><br></pre></td></tr></table></figure>\n<p>到<code>host-2</code>和<code>host-3</code>的请求将被转发到 <code>NGINX</code>并且原始的客户端IP将被保留，但是请求到<code>host-1</code>的<code>Node</code>的请求将被丢弃，因为在该<code>Node</code>上没有<code>NGINX</code>副本集。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>因为<code>NodePort</code>类型的<code>Service</code>没有按定义分配<code>LoadBalancerIP</code>，<code>NGINX Ingress controller</code>不会更新<code>Ingress</code>对象的状态。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress</span><br><span class=\"line\">   NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">   test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>尽管没有负载均衡器为<code>NGINX Ingress Controller</code>提供公共IP地址，但可以通过设置<code>ingress-nginx Service</code>的<code>externalIPs</code>字段来强制所有管理的Ingress对象的状态更新。<br>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>可以编辑<code>ingress-nginx Service</code> 添加如下代码片段到到属性域<code>spec</code>中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  externalIPs:</span><br><span class=\"line\">  - 203.0.113.1</span><br><span class=\"line\">  - 203.0.113.2</span><br><span class=\"line\">  - 203.0.113.3</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>如此，将会在<code>Ingress</code>对象上生效：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                               PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>Redirects</strong></p>\n<blockquote>\n<p>As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.</p>\n</blockquote>\n<p>由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。<br>举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to <a href=\"http://www.domain\" target=\"_blank\" rel=\"noopener\">www.domain</a>, are generated without NodePort:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 308 Permanent Redirect</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">Location: https://myapp.example.com/  #-&gt; missing NodePort in HTTPS redirect</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h5 id=\"Via-the-host-network\"><a href=\"#Via-the-host-network\" class=\"headerlink\" title=\"Via the host network\"></a>Via the host network</h5><p>在没有可用的外部负载均衡器的设置中，但不能使用<code>NodePorts</code>。还有一种方法就是，通过设置<code>ingress-nginx</code>的Pods使用<strong>主机网络</strong>，而不是专用的网络命名空间(<code>network namespace</code>)。该方案的好处就是，在没有额外的<code>NodePort Service</code>提供的外部网络转换情况下，<code>NGINX Ingress controller</code>可以直接绑定k8s的<code>Node</code>网络接口的端口80或443。<br>这可以通过配置Pods属性域<code>template.spec</code>的<code>hostNetwork</code>选项来实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> template:</span><br><span class=\"line\"> spec:</span><br><span class=\"line\">hostNetwork: true</span><br></pre></td></tr></table></figure>\n<p>注意：<br>启用此选项会将所有系统守护进程暴露给任何网络接口上的<code>NGINX Ingress Controller</code>，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。<br>例如：<code>nginx-ingress-controller</code>Deployment有两个副本集，<code>NGINX</code> PodsN继承其主机的IP地址，而不是内部 Pod IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>该部署方式的主要限制是：每个群集节点上只能安排一个<code>NGINX Ingress Controller</code> Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl -n ingress-nginx describe pod &lt;unschedulable-nginx-ingress-controller-pod&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason            From               Message</span><br><span class=\"line\">  ----     ------            ----               -------</span><br><span class=\"line\">  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn&apos;t have free ports for the requested pod ports.</span><br></pre></td></tr></table></figure>\n<p>确保仅创建可调度Pod的一种方法是将<code>NGINX Ingress Controller</code>部署为<code>DaemonSet</code>而不是传统的<code>Deployment</code>。<br><img src=\"/images/hostnetwork.jpg\" alt=\"hostnetwork\"><br>与NodePorts一样，这种方法有一些怪癖，重要的是要注意</p>\n<ul>\n<li><p><strong>DNS resolution</strong><br>如果Pods配置了<code>hostNetwork: true</code>属性，则不使用内部DNS解析器(<code>kube-dns</code>或<code>CoreDns</code>)，除非Pods的<code>spec.dnsPolicy</code>配置了<code>ClusterFirstWithHostNet</code>属性。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认–publish-service标志不适用，并且所有Ingress对象的状态保持空白。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress</span><br><span class=\"line\">NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>相反，由于<code>bare-metal</code>Node通常没有<code>Extral IP</code>，因此必须启用<code>--report-node-internal-ip-address</code>，它将所有Ingress对象的状态设置为运行<code>NGINX Ingress Controller</code>的所有节点的内部IP地址。<br>Given a nginx-ingress-controller DaemonSet composed of 2 replicas</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl -n ingress-nginx get pod -o wide</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>控制器将其管理的所有Ingress对象的状态设置为以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><h5 id=\"Using-a-self-provisioned-edge\"><a href=\"#Using-a-self-provisioned-edge\" class=\"headerlink\" title=\"Using a self-provisioned edge\"></a>Using a self-provisioned edge</h5><p>与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。<br>此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。<br>边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：<br><img src=\"/images/user_edge.jpg\" alt=\"Using a self-provisioned edge\"><br>根据官方Kubernetes文档的“服务”页面，<code>externalIPs</code>选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的<code>endpoints</code>。这些IP地址必须属于目标节点(target node)。</p>\n<blockquote>\n<p>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>and the following ingress-nginx NodePort Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>我们可以在<code>Service</code>的<code>spec.externalIPs</code>属性域中设置<strong>externalIPs</strong>, 则<strong>NGINX</strong>通过<code>NodePort</code>和<code>Service Port</code>变的可达：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">externalIPs:</span><br><span class=\"line\">- 203.0.113.2</span><br><span class=\"line\">- 203.0.113.3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">$ curl -D- http://myapp.example.com</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br></pre></td></tr></table></figure>\n<p>我们假设 <code>myapp.example.com</code> 域名解析成IP地址：203.0.113.2 和 203.0.113.3。</p>\n</li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found/example.png","post":"cjto6rqkj0000hqxucsmeexuw","slug":"example.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cjto6rqkv0008hqxubomg75xx","category_id":"cjto6rqle000fhqxup4x5rdrs","_id":"cjto6rqlk000phqxu8mcn36wk"},{"post_id":"cjto6rqkj0000hqxucsmeexuw","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqlk000thqxu8q3kpwzg"},{"post_id":"cjto6rqkj0000hqxucsmeexuw","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqll000whqxu0rxey2cz"},{"post_id":"cjto6rqky000ahqxu3sr1ye1u","category_id":"cjto6rqlk000qhqxuj0bh420y","_id":"cjto6rqlm0010hqxuuwu67p86"},{"post_id":"cjto6rql1000dhqxu6tyw14qu","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqlp0014hqxu1h7nk63d"},{"post_id":"cjto6rql1000dhqxu6tyw14qu","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqlq0016hqxubgxk93r6"},{"post_id":"cjto6rqko0002hqxuomxpid3y","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqlq0018hqxugkdrsfdf"},{"post_id":"cjto6rqko0002hqxuomxpid3y","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqlr001bhqxu5dbt1x77"},{"post_id":"cjto6rql3000ehqxuigyvaeu6","category_id":"cjto6rqlp0013hqxug51q5hdp","_id":"cjto6rqls001ehqxup6j4zfzx"},{"post_id":"cjto6rqlg000ihqxummhupr3v","category_id":"cjto6rqlp0013hqxug51q5hdp","_id":"cjto6rqlt001ghqxuy6fxmzqd"},{"post_id":"cjto6rqlh000khqxuzvx9rcd4","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqlt001hhqxuqckuv1ct"},{"post_id":"cjto6rqlh000khqxuzvx9rcd4","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqlu001ihqxuyqylkejz"},{"post_id":"cjto6rqsz001jhqxu71qp5kel","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqt5001phqxult63mfpz"},{"post_id":"cjto6rqsz001jhqxu71qp5kel","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqtc001rhqxubt9irxfv"},{"post_id":"cjto6rqt0001khqxuhy9r80b7","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqtd001uhqxuetj7nae5"},{"post_id":"cjto6rqt0001khqxuhy9r80b7","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqtd001whqxuua0mrvs0"},{"post_id":"cjto6rqt3001mhqxudwebylac","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqte001yhqxunk7x44tb"},{"post_id":"cjto6rqt3001mhqxudwebylac","category_id":"cjto6rqli000lhqxuwzld3nbc","_id":"cjto6rqte0020hqxut4x0nkrk"},{"post_id":"cjto6rqt5001ohqxufu3os4ji","category_id":"cjto6rqkr0004hqxunbffcjgv","_id":"cjto6rqte0021hqxu904o61vh"},{"post_id":"cjto6rqt5001ohqxufu3os4ji","category_id":"cjto6rqtd001shqxumd5pk0om","_id":"cjto6rqte0022hqxulfeyb1mn"}],"PostTag":[{"post_id":"cjto6rql1000dhqxu6tyw14qu","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqlg000hhqxu0o0cdar3"},{"post_id":"cjto6rqkj0000hqxucsmeexuw","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqlh000jhqxux4u1af8i"},{"post_id":"cjto6rqkj0000hqxucsmeexuw","tag_id":"cjto6rql0000chqxuioarl37g","_id":"cjto6rqlj000nhqxu5qwq95uo"},{"post_id":"cjto6rqko0002hqxuomxpid3y","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqlj000ohqxuelz5z3g6"},{"post_id":"cjto6rqlh000khqxuzvx9rcd4","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqlk000shqxusoc1osb7"},{"post_id":"cjto6rqkt0006hqxulpkpfwp0","tag_id":"cjto6rqli000mhqxuep33bzne","_id":"cjto6rqll000xhqxumoydc8pd"},{"post_id":"cjto6rqkt0006hqxulpkpfwp0","tag_id":"cjto6rqlk000rhqxunmqelvjm","_id":"cjto6rqlm000yhqxu6idfl7dm"},{"post_id":"cjto6rqkv0008hqxubomg75xx","tag_id":"cjto6rqll000vhqxuf76c05zz","_id":"cjto6rqln0012hqxukr19sqeu"},{"post_id":"cjto6rqky000ahqxu3sr1ye1u","tag_id":"cjto6rqlm0011hqxu4f4ig6cx","_id":"cjto6rqlq0017hqxudj32s4l9"},{"post_id":"cjto6rql3000ehqxuigyvaeu6","tag_id":"cjto6rqlq0015hqxuwfuqeth9","_id":"cjto6rqlr001chqxu6lzolddm"},{"post_id":"cjto6rqlg000ihqxummhupr3v","tag_id":"cjto6rqlq0015hqxuwfuqeth9","_id":"cjto6rqlt001fhqxuwsoiqpkx"},{"post_id":"cjto6rqsz001jhqxu71qp5kel","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqt3001lhqxuycxldju0"},{"post_id":"cjto6rqt3001mhqxudwebylac","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqt7001qhqxuakh3qcvm"},{"post_id":"cjto6rqt0001khqxuhy9r80b7","tag_id":"cjto6rqkt0005hqxugei2rvtv","_id":"cjto6rqtd001vhqxuuqov12bi"},{"post_id":"cjto6rqt0001khqxuhy9r80b7","tag_id":"cjto6rqt4001nhqxuunq1pwg3","_id":"cjto6rqtd001xhqxu0pi5q7o8"},{"post_id":"cjto6rqt5001ohqxufu3os4ji","tag_id":"cjto6rqtd001thqxu97dedrpc","_id":"cjto6rqte001zhqxuu7hy72z2"}],"Tag":[{"name":"docker","_id":"cjto6rqkt0005hqxugei2rvtv"},{"name":"jenkins","_id":"cjto6rql0000chqxuioarl37g"},{"name":"Python","_id":"cjto6rqli000mhqxuep33bzne"},{"name":"thread","_id":"cjto6rqlk000rhqxunmqelvjm"},{"name":"算法","_id":"cjto6rqll000vhqxuf76c05zz"},{"name":"gRPC","_id":"cjto6rqlm0011hqxu4f4ig6cx"},{"name":"Oracle","_id":"cjto6rqlq0015hqxuwfuqeth9"},{"name":"storage","_id":"cjto6rqt4001nhqxuunq1pwg3"},{"name":"kubernetes","_id":"cjto6rqtd001thqxu97dedrpc"}]}}