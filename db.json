{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/2019-03-25_180320.png","path":"images/2019-03-25_180320.png","modified":1,"renderable":0},{"_id":"source/images/container-layers.jpg","path":"images/container-layers.jpg","modified":1,"renderable":0},{"_id":"source/images/docker_versions.png","path":"images/docker_versions.png","modified":1,"renderable":0},{"_id":"source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":0},{"_id":"source/images/hostnetwork.jpg","path":"images/hostnetwork.jpg","modified":1,"renderable":0},{"_id":"source/images/kube-proxy-mode iptables .png","path":"images/kube-proxy-mode iptables .png","modified":1,"renderable":0},{"_id":"source/images/metallb.jpg","path":"images/metallb.jpg","modified":1,"renderable":0},{"_id":"source/images/node.png","path":"images/node.png","modified":1,"renderable":0},{"_id":"source/images/nodeport.jpg","path":"images/nodeport.jpg","modified":1,"renderable":0},{"_id":"source/images/sharing-layers.jpg","path":"images/sharing-layers.jpg","modified":1,"renderable":0},{"_id":"source/images/swarmcluster.png","path":"images/swarmcluster.png","modified":1,"renderable":0},{"_id":"source/images/user_edge.jpg","path":"images/user_edge.jpg","modified":1,"renderable":0},{"_id":"source/images/2018-03-27_115251.png","path":"images/2018-03-27_115251.png","modified":1,"renderable":0},{"_id":"source/images/k8s¹¤×÷Á÷³Ì.png","path":"images/k8s¹¤×÷Á÷³Ì.png","modified":1,"renderable":0},{"_id":"source/images/2018061310290292.jpg","path":"images/2018061310290292.jpg","modified":1,"renderable":0},{"_id":"source/images/kubernetes¼ܹ¹¼°×é¼þ.png","path":"images/kubernetes¼ܹ¹¼°×é¼þ.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.png","path":"images/avatar.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon.ico","path":"images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"source/images/k8s¼ܹ¹.png","path":"images/k8s¼ܹ¹.png","modified":1,"renderable":0},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"source/images/service_nodeport.jpg","path":"images/service_nodeport.jpg","modified":1,"renderable":0},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1553168509298},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1553168509298},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1553168509298},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1553168509298},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1553168509298},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1553168509298},{"_id":"themes/next/.travis.yml","hash":"c42d9608c8c7fe90de7b1581a8dc3886e90c179e","modified":1553168509298},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1553168509298},{"_id":"themes/next/README.en.md","hash":"32d6cdfec1447f54aae1d7f1365ce6733dfcec8f","modified":1553168509298},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1553168509299},{"_id":"themes/next/_config.yml","hash":"995b35ba298024513b70cf59753c719bb8d55639","modified":1553677346944},{"_id":"themes/next/bower.json","hash":"7d7938f9da896fe710aa0e9120140e528bf058df","modified":1553168509299},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1553168509299},{"_id":"themes/next/package.json","hash":"193dad6f59a588908fac082cc46fe067dac1b84d","modified":1553168509302},{"_id":"source/_posts/2019-03-21-docker-network-overlay.md","hash":"346ca36c8a1c9997842fa341267bd890c9c2bb0c","modified":1553171146633},{"_id":"source/_posts/2019-03-21-docker-storage.md","hash":"b2ebbc7a94cdfae5e0742068cf965b9c1e07fbc7","modified":1553170768918},{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found.md","hash":"232f08a06fc42a1294a2717a50f6ca163ba0893d","modified":1553170380218},{"_id":"source/_posts/2019-03-21-pull-docker-images-failed.md","hash":"cb3753d027e783ed9d9407378f2789dd1f45bb4d","modified":1553168509289},{"_id":"source/_posts/2019-03-21-python-mulit-thread.md","hash":"39f7012a9a9ad5647a25fc252b1c97583628f514","modified":1553168509289},{"_id":"source/_posts/2019-03-25-algorithm-two-order-list-merge.md","hash":"11c41468e06e2753788acf767961e09a37063a7c","modified":1553502873291},{"_id":"source/_posts/2019-03-25-docker-network-bridge.md","hash":"f3ecda19ba989562572c90810742a8eeb7336586","modified":1553492706757},{"_id":"source/_posts/2019-03-25-grpc-introduction.md","hash":"7aca1528bf7ac18d950e94725193f07efcd1c96f","modified":1553519690011},{"_id":"source/_posts/2019-03-25-install-docker-yum.md","hash":"78a5bf98f7c4237527b11aafa78b57a568786dd4","modified":1553492222708},{"_id":"source/_posts/2019-03-25-nginx-ingress-controller-introduct.md","hash":"66661c5b12fa45e77a561b637e3ec8d685927417","modified":1553503041935},{"_id":"source/_posts/2019-03-25-oracle-sql-second-version-note.md","hash":"ba06bf418fd9f579eb571bb2c7b1d89755cb7486","modified":1553505673093},{"_id":"source/_posts/2019-03-25-oracle-sql-seconds-notes-sec-2-sql-exec.md","hash":"853d0f96bc4253845092b2587802448ea3769802","modified":1553493605626},{"_id":"source/_posts/2019-03-25-private-registry-docker.md","hash":"af7c6d9cdb57069e2531cd47f462f6774380fefb","modified":1553493039000},{"_id":"source/_posts/2019-03-26-fabric2-tutorial.md","hash":"d53c6d4cd8317b2cc1afeba3c3b0b59d2ce722cd","modified":1553678806405},{"_id":"source/_posts/2019-03-27-first-grpc-example.md","hash":"eb1ec9b039b358a0bead967f8469995110463c9c","modified":1553677122035},{"_id":"source/about/index.md","hash":"eb6ffa20e19dbcff21f70669a732c18d1228990e","modified":1553168509289},{"_id":"source/archives/index.md","hash":"67a4aab57d1119d6efc0fb93cac2a54410c10497","modified":1553168509289},{"_id":"source/categories/index.md","hash":"42e2a5053a5afe11bb23e35b98b873cf9bbe74d9","modified":1553168509289},{"_id":"source/images/2019-03-25_180320.png","hash":"a80c974fc0071094aeb8ff013cbf3f18e224ac36","modified":1553508346318},{"_id":"source/images/container-layers.jpg","hash":"c6354991c7892a38207dddf9f07b4328d3dbeed3","modified":1553502583851},{"_id":"source/images/docker_versions.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553502584120},{"_id":"source/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553171567836},{"_id":"source/images/hostnetwork.jpg","hash":"b0478a0fd5086c6a1452920252dca60069b73962","modified":1553502584995},{"_id":"source/images/kube-proxy-mode iptables .png","hash":"d91b3164dff6e387721fedf99cf3b3edb7050a1a","modified":1553502588291},{"_id":"source/images/metallb.jpg","hash":"1f9f9e9f8685321d9329716b2c11ebcf188e1d9e","modified":1553502589902},{"_id":"source/images/node.png","hash":"c1399721d686508989b821d65ccca33eea7c489e","modified":1553502590309},{"_id":"source/images/nodeport.jpg","hash":"9f9383454db303f5e60d23ba32c89ddb05f87d93","modified":1553502590711},{"_id":"source/images/sharing-layers.jpg","hash":"82b3e992947958d7935aeb52753c9e6a2f07e171","modified":1553502593130},{"_id":"source/images/swarmcluster.png","hash":"e8bfdf7b46713fff7c63fdda89bc0f4a754c70fb","modified":1553502593402},{"_id":"source/images/user_edge.jpg","hash":"309d632e807ba54ec13cad7e6c122eaa07956f49","modified":1553502593940},{"_id":"source/tags/index.md","hash":"682c04efc90349264811e4b400e19eb9f46aa67a","modified":1553168509289},{"_id":"themes/next/languages/de.yml","hash":"306db8c865630f32c6b6260ade9d3209fbec8011","modified":1553168509299},{"_id":"themes/next/languages/default.yml","hash":"4cc6aeb1ac09a58330e494c8771773758ab354af","modified":1553168509299},{"_id":"themes/next/languages/en.yml","hash":"e7def07a709ef55684490b700a06998c67f35f39","modified":1553168509299},{"_id":"themes/next/languages/fr-FR.yml","hash":"24180322c83587a153cea110e74e96eacc3355ad","modified":1553168509299},{"_id":"themes/next/languages/id.yml","hash":"2835ea80dadf093fcf47edd957680973f1fb6b85","modified":1553168509299},{"_id":"themes/next/languages/ja.yml","hash":"1c3a05ab80a6f8be63268b66da6f19da7aa2c638","modified":1553168509299},{"_id":"themes/next/languages/ko.yml","hash":"be150543379150f78329815af427bf152c0e9431","modified":1553168509299},{"_id":"themes/next/languages/pt-BR.yml","hash":"958e49571818a34fdf4af3232a07a024050f8f4e","modified":1553168509299},{"_id":"themes/next/languages/pt.yml","hash":"36c8f60dacbe5d27d84d0e0d6974d7679f928da0","modified":1553168509299},{"_id":"themes/next/languages/ru.yml","hash":"1549a7c2fe23caa7cbedcd0aa2b77c46e57caf27","modified":1553168509299},{"_id":"themes/next/languages/zh-Hans.yml","hash":"e85ea999bac9ed7f9b9482b9d6f7c6b6eb5ec737","modified":1553218375034},{"_id":"themes/next/languages/zh-hk.yml","hash":"1c917997413bf566cb79e0975789f3c9c9128ccd","modified":1553168509299},{"_id":"themes/next/languages/zh-tw.yml","hash":"0b2c18aa76570364003c8d1cd429fa158ae89022","modified":1553168509299},{"_id":"themes/next/layout/_layout.swig","hash":"06b1eab2e00273e0b94bd32dc682bd92c1e0a747","modified":1553168509299},{"_id":"themes/next/layout/archive.swig","hash":"383f64deab105724fd5512371963bd9e9aafbffd","modified":1553168509301},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1553168509301},{"_id":"themes/next/layout/index.swig","hash":"03e8a2cda03bad42ac0cb827025eb81f95d496a2","modified":1553168509301},{"_id":"themes/next/layout/page.swig","hash":"37c874cd720acf0eda8d26e063278f2b6ae8d3a6","modified":1553168509302},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1553483072403},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1553168509302},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1553168509302},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1553168509302},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1553168509302},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1553168509322},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1553168509322},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1553168509322},{"_id":"source/images/2018-03-27_115251.png","hash":"691c7fa5be387e11f7ab8faea59ea06124090272","modified":1553502581366},{"_id":"source/images/k8s¹¤×÷Á÷³Ì.png","hash":"4e2812f8106982442bfaf13e29fd569816b07638","modified":1553519690012},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509306},{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found/example.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553170044266},{"_id":"source/images/2018061310290292.jpg","hash":"eda3d80ff692b0b59edf7d10d4ef46ae7332308f","modified":1553502583310},{"_id":"source/images/kubernetes¼ܹ¹¼°×é¼þ.png","hash":"0e952fd6aecf6a52d1a20c363bbab5412ea664ce","modified":1553519690015},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1553168509299},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1553168509299},{"_id":"themes/next/layout/_macro/google_adsense.swig","hash":"03601ea39f4933e21b57214e5c9a6fce8aebeb25","modified":1553484268966},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1553168509299},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"53d4f83b2b7fb4387dfc9fe81519abd56fbce4ae","modified":1553168509299},{"_id":"themes/next/layout/_macro/post.swig","hash":"be11e400c3ada8136405f3f1c92936f9c6b128e6","modified":1553678705050},{"_id":"themes/next/layout/_macro/reward.swig","hash":"5d5f70deb6074cb4dd0438463e14ccf89213c282","modified":1553168509300},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"faa7886ccf986890cd776f4e9d70cb89fe9fda5f","modified":1553168509300},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1553168509300},{"_id":"themes/next/layout/_partials/comments.swig","hash":"ce7094ee05878161e7568a6dfae5b56ff3fbd6e1","modified":1553168509300},{"_id":"themes/next/layout/_partials/footer.swig","hash":"2c1756b65b383dfc1d90206bb7ef2a1adcd5dc95","modified":1553218883280},{"_id":"themes/next/layout/_partials/head.swig","hash":"1f14d3f494b2dbbcee802fd6f6d1abd5b7e2304c","modified":1553168509300},{"_id":"themes/next/layout/_partials/header.swig","hash":"a1ffbb691dfad3eaf2832a11766e58a179003b8b","modified":1553168509300},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1553168509300},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1553168509300},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1553168509300},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1553168509300},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1553168509300},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1553168509300},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1553168509301},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1553168509301},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1553168509301},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1553168509301},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1553168509301},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1553168509301},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1553168509302},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1553168509302},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1553168509302},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1553168509302},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1553168509302},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1553168509302},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1553168509302},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1553168509302},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1553168509302},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1553168509306},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1553168509306},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1553168509306},{"_id":"themes/next/source/images/avatar.png","hash":"e696f046e8385f0b71c71aaca7f61141b5893510","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1553168509306},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1553168509306},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1553168509306},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1553168509306},{"_id":"themes/next/source/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553168509306},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553168509306},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553168509306},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1553168509306},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1553168509306},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1553168509306},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509300},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509305},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1553168509306},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1553168509300},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1553168509300},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1553168509300},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1553168509300},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1553168509300},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1553168509300},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1553168509300},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"3358d11b9a26185a2d36c96049e4340e701646e4","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1553168509301},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"ee63aa2e49507b884a2d56778479cf01c723d751","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1553168509301},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1553168509301},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1553168509301},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"eaedfaf06dae94ba77a8f4893e2e434bf8859bac","modified":1553168509305},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"49b5210fa62d6cbc6a98f57d89d5067a06ab3561","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1553168509305},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cfee25d790e4f9b7d57f0dc7e2ea9c1649f08f11","modified":1553168509306},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d477196c5699c8261b08e993a77ef67054d86166","modified":1553168509306},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1553168509306},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1553168509307},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1553168509307},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1553168509307},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1553168509307},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1553168509307},{"_id":"themes/next/source/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1553168509307},{"_id":"themes/next/source/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1553168509307},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1553168509307},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1553168509307},{"_id":"themes/next/source/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1553168509307},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1553168509308},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1553168509311},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1553168509312},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1553168509312},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1553168509316},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1553168509316},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1553168509317},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1553168509317},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1553168509317},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1553168509317},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1553168509317},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1553168509320},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1553168509320},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1553168509321},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1553168509321},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1553168509321},{"_id":"source/images/k8s¼ܹ¹.png","hash":"56a633e09dcdf7951af1c195326c22a1dd33d0d1","modified":1553519690014},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1553168509316},{"_id":"source/images/service_nodeport.jpg","hash":"15d79cd10d5e82d1ca2011bea7e92193af3fbcbe","modified":1553502592591},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1553168509301},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1553168509301},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"d026c8489f66ab6c12ad04bd37f1d5b6f2f3f0d1","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1553168509302},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1553168509304},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"2915df7152ea095a6290ef69157fd67669e0e793","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"86b6fd7f1b1be3ae98f8af6b23a6b1299c670ce9","modified":1553168509304},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1553168509305},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1553168509305},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"bc8c388553bbcf95897459a466ba35bffd5ec5f0","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"e3e23751d4ad24e8714b425d768cf68e37de7ded","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1553168509305},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1553168509308},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1553168509311},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1553168509312},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1553168509312},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1553168509312},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1553168509320},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1553168509320},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1553168509308},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1553168509308},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1553168509315},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1553168509316},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1553168509321},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"ed88c8b51d0517759c777e71a6bfbe2907bcd994","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ee554b1031ef0070a5916477939021800e3c9d27","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post-wordcount.styl","hash":"4fda5d38c6c8d910e3bf5c74a48a8d4a3f3dc73d","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"51eca243220cf57133a4becae9b78514bcfdc723","modified":1553168509303},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"65a64d5662637b66e2f039a5f58217afe7a6e800","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"5f6ea57aabfa30a437059bf8352f1ad829dbd4ff","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"57d2c8a060f5e4e1a0aef9aae11a0016cf7ac5ba","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"45df0cf4c97b47e05573bcd41028ee50f3fdf432","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1553168509304},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"aeff0e6e23725e8baea27c890ccbbf466024f767","modified":1553168509304},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1553168509305},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1553168509305},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1553168509307},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1553168509307},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1553168509311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1553168509311},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1553168509313},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1553168509315},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1553168509314},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1553168509307},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1553168509310},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1553168509320},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1553168509315},{"_id":"public/atom.xml","hash":"23f37edc97d8a62dc24f9cb6b7046355f254915b","modified":1553678849776},{"_id":"public/about/index.html","hash":"4dc2a1250f44d8e695259175b014c284e811772f","modified":1553678849803},{"_id":"public/categories/常见算法/index.html","hash":"259e8968a66764f8d99e9feb164431455c0f128d","modified":1553678849803},{"_id":"public/categories/运维/kubernetes/index.html","hash":"3950ec8f3e431a2a1018161f9141696490afc494","modified":1553678849803},{"_id":"public/categories/运维/Fabric/index.html","hash":"5f49706c48d84d85b063ea6e5f1b3a99101cfe78","modified":1553678849804},{"_id":"public/tags/jenkins/index.html","hash":"56d0cc5f7b101073cbde0fa7e9019a7d47614dd7","modified":1553678849804},{"_id":"public/tags/thread/index.html","hash":"997bf6cacb25e5b6720bf6e2762c88e62622b7b2","modified":1553678849804},{"_id":"public/tags/算法/index.html","hash":"a6e8b0b190a8d1d247fc48eecfae6a738b98d0d0","modified":1553678849804},{"_id":"public/tags/storage/index.html","hash":"3d4a6a83b33cade23e2a027ea5f25c24415877e4","modified":1553678849804},{"_id":"public/tags/kubernetes/index.html","hash":"d87d962332855dd57c3f0ab336d8ab38ecaa2922","modified":1553678849835},{"_id":"public/tags/Fabric/index.html","hash":"79f42a8ae551cc78abcfd97081ba248a3c7ffc8c","modified":1553678849835},{"_id":"public/archives/index.html","hash":"d91f9202b78c8f9d74f71562d83f1c7bc35e3408","modified":1553678849835},{"_id":"public/categories/index.html","hash":"91334e9538e4f1653efde266b5973c7db9278cee","modified":1553678849835},{"_id":"public/tags/index.html","hash":"7be6bad83d41c2bdb6943537b45e61cf96648df1","modified":1553678849835},{"_id":"public/2019/03/28/first-grpc-example/index.html","hash":"c30c0afa0765700a5f78fd4ba67bf8b7d41b6d7a","modified":1553678849835},{"_id":"public/2019/03/26/fabric2-tutorial/index.html","hash":"091bef4eca87bd3cabe5d28519a967e5d05225e2","modified":1553678849836},{"_id":"public/2019/03/26/grpc-introduction/index.html","hash":"be7ad3c2d2c65508971591fad87a56a07e1fe273","modified":1553678849836},{"_id":"public/2019/03/25/algorithm-two-order-list-merge/index.html","hash":"28a651c443b48ffce2cb02a7f51d201b469a7c46","modified":1553678849836},{"_id":"public/2019/03/25/install-docker-yum/index.html","hash":"668dc25a1f93d366ac44bd9a23d3e4c85c638993","modified":1553678849836},{"_id":"public/2019/03/25/docker-network-bridge/index.html","hash":"001c18ce4151e62b9247d3eb024b6036d9af2164","modified":1553678849836},{"_id":"public/2019/03/22/docker-network-overlay/index.html","hash":"b0fa599e756ff56f05c354e6c8eb97d81bcec89c","modified":1553678849836},{"_id":"public/2019/03/21/python-mulit-thread/index.html","hash":"fa3567995f4c5fd46cc2998b19c06b3b2187d6d9","modified":1553678849836},{"_id":"public/2019/03/21/pull-docker-images-failed/index.html","hash":"ad39cc020f5ac991da2641b8382bf421bd473c95","modified":1553678849836},{"_id":"public/2019/03/21/docker-storage/index.html","hash":"c001d4e70a00e2c36f6bf9230c05f9bd66293a36","modified":1553678849836},{"_id":"public/2019/01/26/nginx-ingress-controller-introduct/index.html","hash":"921a71be477eff7c8e76c98aa338a089c702b388","modified":1553678849836},{"_id":"public/2018/09/13/private-registry-docker/index.html","hash":"823c9c0b99d1edf0ba76b134e47294d23e44feec","modified":1553678849836},{"_id":"public/2018/03/22/jenkins-docker-command-not-found/index.html","hash":"629946672b9d5d4e05c775d920a5b085876c416b","modified":1553678849836},{"_id":"public/2017/08/17/oracle-sql-seconds-notes-sec-2-sql-exec/index.html","hash":"c72a37d00877881b152ec1bb375bd49c770d00ee","modified":1553678849837},{"_id":"public/2016/12/05/oracle-sql-second-version-note/index.html","hash":"d5cacfd10a1add8e1814d05210497533c83e76a5","modified":1553678849837},{"_id":"public/archives/page/2/index.html","hash":"1c054e50b682d55a71dd86a0c8739070300a9c6c","modified":1553678849837},{"_id":"public/archives/2016/index.html","hash":"0f9645fa5ad9e9b2639c04f560c4f9e1af405eb3","modified":1553678849837},{"_id":"public/archives/2016/12/index.html","hash":"99b6e6ea4849f9a2403bfb4cc5390b2df6e4b9a3","modified":1553678849837},{"_id":"public/archives/2017/index.html","hash":"3da8822a3607f209e9db8bb15d7b903f89dfb341","modified":1553678849837},{"_id":"public/archives/2017/08/index.html","hash":"1fa3c962a8688d794f5c8fc0de4fc70a58ed0033","modified":1553678849837},{"_id":"public/archives/2018/index.html","hash":"ea29ff7187a049f822e1945637983bd64a746753","modified":1553678849837},{"_id":"public/archives/2018/03/index.html","hash":"9628bed6570023a8386f8319973ff72eb84d7f16","modified":1553678849837},{"_id":"public/archives/2018/09/index.html","hash":"9b8653e97070fb69d3c59c0693a41217d0317f89","modified":1553678849837},{"_id":"public/archives/2019/index.html","hash":"83c387a0314d7623091171d584d53e95341349ab","modified":1553678849837},{"_id":"public/archives/2019/page/2/index.html","hash":"6a462325f5cde972b512484a95846e6c8521be7d","modified":1553678849837},{"_id":"public/archives/2019/01/index.html","hash":"7d61eaad9238dcd35f514e5ec8e111c5169b9081","modified":1553678849837},{"_id":"public/archives/2019/03/index.html","hash":"20f281b171b9c769789d84c9eda8d5fe21d23c10","modified":1553678849837},{"_id":"public/categories/运维/index.html","hash":"ed299239cda83e3c4ad85a6dc68024f7b79538c5","modified":1553678849837},{"_id":"public/categories/运维/docker/index.html","hash":"a21543c97ce1d16cea5b855e08b2dc65554951e1","modified":1553678849837},{"_id":"public/categories/gRPC/index.html","hash":"f444a16034bc210b371bb8263d1aaede47495104","modified":1553678849837},{"_id":"public/categories/Oracle/index.html","hash":"1df2c23b222606649bb2e00b2008ec4a1e4ec585","modified":1553678849838},{"_id":"public/index.html","hash":"f937f529fd87f7dc163d95a8a5eada2320b15247","modified":1553678849838},{"_id":"public/page/2/index.html","hash":"f1830d3199ae9737c813c5bc23ec5e3211a9db28","modified":1553678849838},{"_id":"public/tags/docker/index.html","hash":"98c9ca5bd9ea69a94690900b5bb7529dbf821968","modified":1553678849838},{"_id":"public/tags/Python/index.html","hash":"e1baabb100432a2af4e745a4aa46fb2bf4ea205d","modified":1553678849838},{"_id":"public/tags/gRPC/index.html","hash":"2f37d57a46fd929b9bccdafeba61cf93ea6af7fc","modified":1553678849838},{"_id":"public/tags/Oracle/index.html","hash":"6d29ab3321f74ed7f6d7a2011cbf2525ea710e6a","modified":1553678849838},{"_id":"public/images/2019-03-25_180320.png","hash":"a80c974fc0071094aeb8ff013cbf3f18e224ac36","modified":1553678849838},{"_id":"public/images/docker_versions.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553678849838},{"_id":"public/images/favicon.ico","hash":"c168c50a843b52342efeef22376bc2e74688a116","modified":1553678849838},{"_id":"public/images/hostnetwork.jpg","hash":"b0478a0fd5086c6a1452920252dca60069b73962","modified":1553678849838},{"_id":"public/images/kube-proxy-mode iptables .png","hash":"d91b3164dff6e387721fedf99cf3b3edb7050a1a","modified":1553678849838},{"_id":"public/images/metallb.jpg","hash":"1f9f9e9f8685321d9329716b2c11ebcf188e1d9e","modified":1553678849838},{"_id":"public/images/node.png","hash":"c1399721d686508989b821d65ccca33eea7c489e","modified":1553678849838},{"_id":"public/images/nodeport.jpg","hash":"9f9383454db303f5e60d23ba32c89ddb05f87d93","modified":1553678849838},{"_id":"public/images/sharing-layers.jpg","hash":"82b3e992947958d7935aeb52753c9e6a2f07e171","modified":1553678849838},{"_id":"public/images/swarmcluster.png","hash":"e8bfdf7b46713fff7c63fdda89bc0f4a754c70fb","modified":1553678849839},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1553678849839},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1553678849839},{"_id":"public/images/avatar.png","hash":"e696f046e8385f0b71c71aaca7f61141b5893510","modified":1553678849839},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1553678849839},{"_id":"public/images/container-layers.jpg","hash":"c6354991c7892a38207dddf9f07b4328d3dbeed3","modified":1553678850418},{"_id":"public/images/user_edge.jpg","hash":"309d632e807ba54ec13cad7e6c122eaa07956f49","modified":1553678850418},{"_id":"public/images/2018-03-27_115251.png","hash":"691c7fa5be387e11f7ab8faea59ea06124090272","modified":1553678850419},{"_id":"public/images/k8s¹¤×÷Á÷³Ì.png","hash":"4e2812f8106982442bfaf13e29fd569816b07638","modified":1553678850419},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1553678850419},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1553678850419},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1553678850419},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1553678850419},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1553678850419},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553678850420},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1553678850420},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1553678850420},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1553678850420},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1553678850420},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1553678850420},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1553678850420},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1553678850420},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1553678850420},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1553678850420},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1553678850420},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1553678850420},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1553678850420},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1553678850420},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1553678850420},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1553678850420},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1553678850420},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1553678850420},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1553678850420},{"_id":"public/2018/03/22/jenkins-docker-command-not-found/example.png","hash":"f6dc2081688d582a3ef0ff29cf32a410c67393a6","modified":1553678850420},{"_id":"public/css/main.css","hash":"f6271c004bfbbb3513d2824629d0d65a3a23f368","modified":1553678850439},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1553678850443},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1553678850444},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1553678850458},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1553678850458},{"_id":"public/js/src/bootstrap.js","hash":"6117f97b4984b8e33f21c726132da64ba678e4ed","modified":1553678850458},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1553678850458},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1553678850458},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1553678850458},{"_id":"public/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1553678850458},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1553678850458},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1553678850459},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1553678850459},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1553678850459},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1553678850459},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1553678850459},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1553678850459},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1553678850459},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1553678850459},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1553678850459},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1553678850459},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1553678850459},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1553678850459},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1553678850459},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1553678850459},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1553678850459},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1553678850459},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1553678850460},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1553678850460},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1553678850460},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1553678850460},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1553678850460},{"_id":"public/images/2018061310290292.jpg","hash":"eda3d80ff692b0b59edf7d10d4ef46ae7332308f","modified":1553678850460},{"_id":"public/images/kubernetes¼ܹ¹¼°×é¼þ.png","hash":"0e952fd6aecf6a52d1a20c363bbab5412ea664ce","modified":1553678850460},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1553678850460},{"_id":"public/js/src/motion.js","hash":"dc0365b2fb315a8b43d3ef19b59d3a82a366fcc1","modified":1553678850466},{"_id":"public/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1553678850466},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1553678850467},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1553678850467},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1553678850471},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1553678850471},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1553678850471},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1553678850471},{"_id":"public/images/k8s¼ܹ¹.png","hash":"56a633e09dcdf7951af1c195326c22a1dd33d0d1","modified":1553678850471},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1553678850471},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1553678850471},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1553678850474},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1553678850475},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1553678850475},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1553678850483},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1553678850503},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1553678850504},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1553678850504},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1553678850504},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1553678850504},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1553678850504},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1553678850504},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1553678850509},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1553678850509},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1553678850512},{"_id":"public/images/service_nodeport.jpg","hash":"15d79cd10d5e82d1ca2011bea7e92193af3fbcbe","modified":1553678850512},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1553678850520},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1553678850524},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1553678850525},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1553678850535},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1553678850542},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1553678850546}],"Category":[{"name":"运维","_id":"cjtr09ox30004t2xulzb3i6tc"},{"name":"常见算法","_id":"cjtr09oxf000et2xukk7xjlri"},{"name":"docker","parent":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oxn000kt2xu4s93r4kk"},{"name":"gRPC","_id":"cjtr09oxo000pt2xunk3kns0q"},{"name":"Oracle","_id":"cjtr09oxr0012t2xu377psg3v"},{"name":"kubernetes","parent":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oz8001tt2xusvzylf67"},{"name":"Fabric","parent":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09p5y0028t2xuebtvvymr"}],"Data":[],"Page":[{"title":"about","date":"2019-03-21T15:51:19.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-03-21 15:51:19\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjtr09ox00001t2xu3093hiax","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"archives","date":"2019-03-21T15:50:07.000Z","type":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2019-03-21 15:50:07\ntype: \"archives\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"archives/index.html","comments":1,"layout":"page","_id":"cjtr09ox20003t2xuv1z9egip","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2019-03-21T15:51:42.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-03-21 15:51:42\ntype: \"categories\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjtr09ox70007t2xuag1jan25","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-03-21T15:49:53.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-03-21 15:49:53\ntype: \"tags\"\n---\n","updated":"2019-03-21T11:41:49.289Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjtr09oyq001it2xuxi6vafqa","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Docker中启动jenkins容器，并在jenkins中使用docker 命令，解决docker command not found","date":"2018-03-21T20:04:07.000Z","_content":"\n\n首先，制作支持docker的jenkins镜像，基础镜像是`jenkins:2.60.3`\n参考[Running Docker in Jenkins (in Docker)](https://container-solutions.com/running-docker-in-jenkins-in-docker/)\n\n编辑Dockerfile，内容如下：\n```\nFROM jenkins:2.60.3\n\nUSER root\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n\nRUN apt-get update       && apt-get install -y sudo       && apt-get install -y libltdl7       && rm -rf /var/lib/apt/lists/*\nRUN echo \"jenkins ALL=NOPASSWD: ALL\" >> /etc/sudoers\n\nUSER jenkins\nCOPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt\n\n```\n\n\n\n出现在执行docker命令时报：`docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory`错误[解决办法，参考](https://www.cnblogs.com/leolztang/p/6934694.html)\n加入如下代码后，问题解决：\n```\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n```\n预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。\n```\n\nscm-api:latest\ngit-client:latest\ngit:latest\ngreenballs:latest\n\n```\n启动jenkins容器，执行如下命令，启动jenkins容器\n\n```\ndocker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6\n```\n注意挂载`-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker`，才可以共享宿主机的docker资源\n指定工作目录：`-v $PWD:/var/jenkins_home`，将当前目录作为jenkins的工作目录。\n此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。\n首先，我们新建一个pipeline构建计划，Jenkinsfile内容：\n\n```\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'docker images'\n            }\n        }\n    }\n}\n```\n，执行立即构建，当执行pipeline中的`docker images`命令时，报错：\n```\n+ docker images\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied\n```\n这是jenkinsfile中的命令在访问宿主机的`unix:///var/run/docker.sock`守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加`sudo `，便成功执行：\n\n```\n[test_pipeline] Running shell script\n+ sudo docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB\njenkins             v2.6                bb042102b598        3 hours ago         705MB\njenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB\nbusybox             latest              22c2dd5ee85d        3 days ago          1.16MB\n```\n","source":"_posts/2019-03-21-jenkins-docker-command-not-found.md","raw":"---\ntitle: Docker中启动jenkins容器，并在jenkins中使用docker 命令，解决docker command not found\ndate: 2018-03-21 20:04:07\ntags:\n  - docker\n  - jenkins\ncategories:\n  - 运维\n  - docker\n---\n\n\n首先，制作支持docker的jenkins镜像，基础镜像是`jenkins:2.60.3`\n参考[Running Docker in Jenkins (in Docker)](https://container-solutions.com/running-docker-in-jenkins-in-docker/)\n\n编辑Dockerfile，内容如下：\n```\nFROM jenkins:2.60.3\n\nUSER root\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n\nRUN apt-get update       && apt-get install -y sudo       && apt-get install -y libltdl7       && rm -rf /var/lib/apt/lists/*\nRUN echo \"jenkins ALL=NOPASSWD: ALL\" >> /etc/sudoers\n\nUSER jenkins\nCOPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt\n\n```\n\n\n\n出现在执行docker命令时报：`docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory`错误[解决办法，参考](https://www.cnblogs.com/leolztang/p/6934694.html)\n加入如下代码后，问题解决：\n```\nRUN echo '' > /etc/apt/sources.list.d/jessie-backports.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie main contrib non-free\" > /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\" >> /etc/apt/sources.list \\\n  && echo \"deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free\" >> /etc/apt/sources.list\n```\n预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。\n```\n\nscm-api:latest\ngit-client:latest\ngit:latest\ngreenballs:latest\n\n```\n启动jenkins容器，执行如下命令，启动jenkins容器\n\n```\ndocker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6\n```\n注意挂载`-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker`，才可以共享宿主机的docker资源\n指定工作目录：`-v $PWD:/var/jenkins_home`，将当前目录作为jenkins的工作目录。\n此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。\n首先，我们新建一个pipeline构建计划，Jenkinsfile内容：\n\n```\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'docker images'\n            }\n        }\n    }\n}\n```\n，执行立即构建，当执行pipeline中的`docker images`命令时，报错：\n```\n+ docker images\nGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied\n```\n这是jenkinsfile中的命令在访问宿主机的`unix:///var/run/docker.sock`守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加`sudo `，便成功执行：\n\n```\n[test_pipeline] Running shell script\n+ sudo docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\njenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB\njenkins             v2.6                bb042102b598        3 hours ago         705MB\njenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB\nbusybox             latest              22c2dd5ee85d        3 days ago          1.16MB\n```\n","slug":"jenkins-docker-command-not-found","published":1,"updated":"2019-03-21T12:13:00.218Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oww0000t2xuprnvqyox","content":"<p>首先，制作支持docker的jenkins镜像，基础镜像是<code>jenkins:2.60.3</code><br>参考<a href=\"https://container-solutions.com/running-docker-in-jenkins-in-docker/\" target=\"_blank\" rel=\"noopener\">Running Docker in Jenkins (in Docker)</a></p>\n<p>编辑Dockerfile，内容如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM jenkins:2.60.3</span><br><span class=\"line\"></span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">RUN apt-get update       &amp;&amp; apt-get install -y sudo       &amp;&amp; apt-get install -y libltdl7       &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">RUN echo &quot;jenkins ALL=NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</span><br><span class=\"line\"></span><br><span class=\"line\">USER jenkins</span><br><span class=\"line\">COPY plugins.txt /usr/share/jenkins/plugins.txt</span><br><span class=\"line\">RUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt</span><br></pre></td></tr></table></figure></p>\n<p>出现在执行docker命令时报：<code>docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory</code>错误<a href=\"https://www.cnblogs.com/leolztang/p/6934694.html\" target=\"_blank\" rel=\"noopener\">解决办法，参考</a><br>加入如下代码后，问题解决：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scm-api:latest</span><br><span class=\"line\">git-client:latest</span><br><span class=\"line\">git:latest</span><br><span class=\"line\">greenballs:latest</span><br></pre></td></tr></table></figure></p>\n<p>启动jenkins容器，执行如下命令，启动jenkins容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6</span><br></pre></td></tr></table></figure>\n<p>注意挂载<code>-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker</code>，才可以共享宿主机的docker资源<br>指定工作目录：<code>-v $PWD:/var/jenkins_home</code>，将当前目录作为jenkins的工作目录。<br>此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。<br>首先，我们新建一个pipeline构建计划，Jenkinsfile内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent any</span><br><span class=\"line\">    stages &#123;</span><br><span class=\"line\">        stage(&apos;Test&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                sh &apos;docker images&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>，执行立即构建，当执行pipeline中的<code>docker images</code>命令时，报错：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ docker images</span><br><span class=\"line\">Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></p>\n<p>这是jenkinsfile中的命令在访问宿主机的<code>unix:///var/run/docker.sock</code>守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加<code>sudo</code>，便成功执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[test_pipeline] Running shell script</span><br><span class=\"line\">+ sudo docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">jenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB</span><br><span class=\"line\">jenkins             v2.6                bb042102b598        3 hours ago         705MB</span><br><span class=\"line\">jenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB</span><br><span class=\"line\">busybox             latest              22c2dd5ee85d        3 days ago          1.16MB</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>首先，制作支持docker的jenkins镜像，基础镜像是<code>jenkins:2.60.3</code><br>参考<a href=\"https://container-solutions.com/running-docker-in-jenkins-in-docker/\" target=\"_blank\" rel=\"noopener\">Running Docker in Jenkins (in Docker)</a></p>\n<p>编辑Dockerfile，内容如下：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM jenkins:2.60.3</span><br><span class=\"line\"></span><br><span class=\"line\">USER root</span><br><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">RUN apt-get update       &amp;&amp; apt-get install -y sudo       &amp;&amp; apt-get install -y libltdl7       &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">RUN echo &quot;jenkins ALL=NOPASSWD: ALL&quot; &gt;&gt; /etc/sudoers</span><br><span class=\"line\"></span><br><span class=\"line\">USER jenkins</span><br><span class=\"line\">COPY plugins.txt /usr/share/jenkins/plugins.txt</span><br><span class=\"line\">RUN /usr/local/bin/plugins.sh /usr/share/jenkins/plugins.txt</span><br></pre></td></tr></table></figure></p>\n<p>出现在执行docker命令时报：<code>docker: error while loading shared libraries: libltdl.so.7: cannot open shared object file: No such file or directory</code>错误<a href=\"https://www.cnblogs.com/leolztang/p/6934694.html\" target=\"_blank\" rel=\"noopener\">解决办法，参考</a><br>加入如下代码后，问题解决：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">RUN echo &apos;&apos; &gt; /etc/apt/sources.list.d/jessie-backports.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie main contrib non-free&quot; &gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list \\</span><br><span class=\"line\">  &amp;&amp; echo &quot;deb http://mirrors.aliyun.com/debian-security jessie/updates main contrib non-free&quot; &gt;&gt; /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>预先安装的插件，放入plugins.txt文件中，也可以部署jenkins后，手动安装插件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">scm-api:latest</span><br><span class=\"line\">git-client:latest</span><br><span class=\"line\">git:latest</span><br><span class=\"line\">greenballs:latest</span><br></pre></td></tr></table></figure></p>\n<p>启动jenkins容器，执行如下命令，启动jenkins容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run -d -v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker -v $PWD:/var/jenkins_home -p 8080:8080 jenkins:v2.6</span><br></pre></td></tr></table></figure>\n<p>注意挂载<code>-v /var/run/docker.sock:/var/run/docker.sock -v $(which docker):/usr/bin/docker</code>，才可以共享宿主机的docker资源<br>指定工作目录：<code>-v $PWD:/var/jenkins_home</code>，将当前目录作为jenkins的工作目录。<br>此时，可以通过ip:8080端口访问jenkins，按照提示一步一步进行。配置完后，就可以使用了。<br>首先，我们新建一个pipeline构建计划，Jenkinsfile内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pipeline &#123;</span><br><span class=\"line\">    agent any</span><br><span class=\"line\">    stages &#123;</span><br><span class=\"line\">        stage(&apos;Test&apos;) &#123;</span><br><span class=\"line\">            steps &#123;</span><br><span class=\"line\">                sh &apos;docker images&apos;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>，执行立即构建，当执行pipeline中的<code>docker images</code>命令时，报错：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">+ docker images</span><br><span class=\"line\">Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.37/images/json: dial unix /var/run/docker.sock: connect: permission denied</span><br></pre></td></tr></table></figure></p>\n<p>这是jenkinsfile中的命令在访问宿主机的<code>unix:///var/run/docker.sock</code>守护进程时，权限不足。在jenkins中，执行pipeline的用户是jenkins，可以在pipelines中的docker命令前增加<code>sudo</code>，便成功执行：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[test_pipeline] Running shell script</span><br><span class=\"line\">+ sudo docker images</span><br><span class=\"line\">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">jenkins             v2.6.3              7c6cba7c8a03        18 minutes ago      705MB</span><br><span class=\"line\">jenkins             v2.6                bb042102b598        3 hours ago         705MB</span><br><span class=\"line\">jenkins             2.60.3              cd14cecfdb3a        2 days ago          696MB</span><br><span class=\"line\">busybox             latest              22c2dd5ee85d        3 days ago          1.16MB</span><br></pre></td></tr></table></figure>\n"},{"title":"gcr.io和quay.io拉取镜像失败","date":"2019-03-21T11:17:18.000Z","_content":"\nk8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中`spec.containers.image`包含：\n```\nquay.io/coreos/example_\ngcr.io/google_containers/example_\n```\n也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com\n- 例如\n    **下拉镜像**：`quay.io/coreos/flannel:v0.10.0-s390x`\n    如果拉取较慢，可以改为：`quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x`\n    \n    **下拉镜像**：`gcr.io/google_containers/kube-proxy`\n    可以改为： `registry.aliyuncs.com/google_containers/kube-proxy`\n\n\n\n","source":"_posts/2019-03-21-pull-docker-images-failed.md","raw":"---\ntitle: gcr.io和quay.io拉取镜像失败\ndate: 2019-03-21 11:17:18\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\nk8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中`spec.containers.image`包含：\n```\nquay.io/coreos/example_\ngcr.io/google_containers/example_\n```\n也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com\n- 例如\n    **下拉镜像**：`quay.io/coreos/flannel:v0.10.0-s390x`\n    如果拉取较慢，可以改为：`quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x`\n    \n    **下拉镜像**：`gcr.io/google_containers/kube-proxy`\n    可以改为： `registry.aliyuncs.com/google_containers/kube-proxy`\n\n\n\n","slug":"pull-docker-images-failed","published":1,"updated":"2019-03-21T11:41:49.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09ox10002t2xuwgjsqfuj","content":"<p>k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中<code>spec.containers.image</code>包含：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quay.io/coreos/example_</span><br><span class=\"line\">gcr.io/google_containers/example_</span><br></pre></td></tr></table></figure></p>\n<p>也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com</p>\n<ul>\n<li><p>例如<br>  <strong>下拉镜像</strong>：<code>quay.io/coreos/flannel:v0.10.0-s390x</code><br>  如果拉取较慢，可以改为：<code>quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x</code></p>\n<p>  <strong>下拉镜像</strong>：<code>gcr.io/google_containers/kube-proxy</code><br>  可以改为： <code>registry.aliyuncs.com/google_containers/kube-proxy</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中<code>spec.containers.image</code>包含：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">quay.io/coreos/example_</span><br><span class=\"line\">gcr.io/google_containers/example_</span><br></pre></td></tr></table></figure></p>\n<p>也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com</p>\n<ul>\n<li><p>例如<br>  <strong>下拉镜像</strong>：<code>quay.io/coreos/flannel:v0.10.0-s390x</code><br>  如果拉取较慢，可以改为：<code>quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x</code></p>\n<p>  <strong>下拉镜像</strong>：<code>gcr.io/google_containers/kube-proxy</code><br>  可以改为： <code>registry.aliyuncs.com/google_containers/kube-proxy</code></p>\n</li>\n</ul>\n"},{"title":"python 多线程锁机制介绍","date":"2019-03-21T15:56:07.000Z","_content":"\n### Lock\n- 说明：\n\n对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。\n\n- 使用：\n\n```\nimport threading\n_lock = threading.lock() # 定义锁 _local\n\n_lock.accquire()  # 获取锁\n# TODO do something\ndo_somthing(share_var)   # 操作共享资源\n_lock.release()  #释放锁\n\n```\n\n- 缺点：\n  \n  死锁\n\n  当有多个共享资源（比如：`R_A`, `R_B`），多个线程（比如：`T_A`, `T_B`），每个线程都需要操作共享资源。假如线程 `T_A` 已经获取了共享资源 `R_A`，`T_B` 获取了共享资源 `R_B` ， 而线程 `T_A` 等待 `T_B` 释放共享资源 `R_B` 。 同时，线程 `T_B` 等待 `T_A` 释放共享资源 `R_A` ，此时就陷入死锁状态。\n\n\n### RLock\n\n- 说明：\n\n  RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 `Lock` 有是四个特点：\n  1. 谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 `Lock` 锁，可以被另外一个线程所释放。\n  2. 同一线程可以多次获取到该锁，即可以acquire多次；\n  3. 如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）\n  4. 相对 `Rlock` ， `Lock` 速度更快。\n- 使用：\n  \n  使用 `Rlock` 锁\n  ```\n  import threading  \n  rLock = threading.RLock()  #RLock对象  \n  rLock.acquire()  \n  rLock.acquire() #在同一线程内，程序不会堵塞。  \n  rLock.release()  \n  rLock.release()  \n\n  ```\n  \n  使用 `Lock` 锁：\n\n  ```\n  import threading  \n  lock = threading.Lock() #Lock对象  \n  lock.acquire()  \n  lock.acquire()  #产生了死琐。  \n  lock.release()  \n  lock.release()  \n  ```\n  \n\n- 缺点：\n \n  \n### semaphore（信号量）\n\n- 说明：\n\n  信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为**负值**时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成**非负值**时。\n\n  本质上，信号量就是一个计数器，当计数器的值为 **非负值** 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 **负值** 时，所有待获取共享资源的线程挂起状态。\n\n\n- 使用：\n\n  ```\n  semaphore = threading.Semaphore(0)\n\n  # Thread1:\n  def thread1_method():\n      semaphore.acquire()  # 线程1 对信号量进行获取操作\n  \n\n  # Thread2:\n  def thread2_method():\n    semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器\n\n  ```\n  \n  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。\n  \n\n- 缺点：\n  \n  导致死锁\n\n  有多个线程（比如：`t1` ， `t2`），竞争多个信号量（比如：`s1` , `s2`）。 假如，现在有一个线程 `t1` 先等待信号量 `s1` ，然后等待信号量 `s2` ，而线程 `t2` 会先等待信号量 `s2` ，然后再等待信号量 `s1` ，这样就可能会发生死锁，导致 `t1` 等待 `s2` ，但是 `t2` 在等待 `s1` 。\n\n\n### Condition - 条件同步\n\n- 说明：\n  \n  当多个线程**等待**同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。\n\n- 使用：\n\n  ```\n  import threading\n\n  condition = threading.Condition()\n  \n  #  生产者\n  def thread1_method():\n    condition.acquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n        condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n    \n    # TODO do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()  # 释放资源\n\n  # 消费者\n  def thread2_method():\n     \n    condition.accquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n         condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n\n    # 条件满足\n    # TODO  do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()   # 释放资源\n\n  ```\n  `wait` 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。\n  \n  `notify` 唤醒一个挂起的线程（如果存在挂起的线程）。注意：`notify()`方法不会释放所占用的琐。需要通过 `release()` 方法释放锁。\n\n\n- 缺点：\n  \n\n### Event - 事件\n\n- 说明：\n- 使用：\n\n  ```\n  import threading\n  event = threading.Event()\n  \n\n  ```\n\n- 缺点：\n\n\n\n\n\n**参考：**\n\n- [基于线程的并行](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html)\n\n- [What is the difference between Lock and RLock\n](https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock)\n\n\n","source":"_posts/2019-03-21-python-mulit-thread.md","raw":"---\ntitle: python 多线程锁机制介绍\ndate: 2019-03-21 15:56:07\ntags:\n  - Python\n  - thread\n---\n\n### Lock\n- 说明：\n\n对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。\n\n- 使用：\n\n```\nimport threading\n_lock = threading.lock() # 定义锁 _local\n\n_lock.accquire()  # 获取锁\n# TODO do something\ndo_somthing(share_var)   # 操作共享资源\n_lock.release()  #释放锁\n\n```\n\n- 缺点：\n  \n  死锁\n\n  当有多个共享资源（比如：`R_A`, `R_B`），多个线程（比如：`T_A`, `T_B`），每个线程都需要操作共享资源。假如线程 `T_A` 已经获取了共享资源 `R_A`，`T_B` 获取了共享资源 `R_B` ， 而线程 `T_A` 等待 `T_B` 释放共享资源 `R_B` 。 同时，线程 `T_B` 等待 `T_A` 释放共享资源 `R_A` ，此时就陷入死锁状态。\n\n\n### RLock\n\n- 说明：\n\n  RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 `Lock` 有是四个特点：\n  1. 谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 `Lock` 锁，可以被另外一个线程所释放。\n  2. 同一线程可以多次获取到该锁，即可以acquire多次；\n  3. 如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）\n  4. 相对 `Rlock` ， `Lock` 速度更快。\n- 使用：\n  \n  使用 `Rlock` 锁\n  ```\n  import threading  \n  rLock = threading.RLock()  #RLock对象  \n  rLock.acquire()  \n  rLock.acquire() #在同一线程内，程序不会堵塞。  \n  rLock.release()  \n  rLock.release()  \n\n  ```\n  \n  使用 `Lock` 锁：\n\n  ```\n  import threading  \n  lock = threading.Lock() #Lock对象  \n  lock.acquire()  \n  lock.acquire()  #产生了死琐。  \n  lock.release()  \n  lock.release()  \n  ```\n  \n\n- 缺点：\n \n  \n### semaphore（信号量）\n\n- 说明：\n\n  信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为**负值**时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成**非负值**时。\n\n  本质上，信号量就是一个计数器，当计数器的值为 **非负值** 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 **负值** 时，所有待获取共享资源的线程挂起状态。\n\n\n- 使用：\n\n  ```\n  semaphore = threading.Semaphore(0)\n\n  # Thread1:\n  def thread1_method():\n      semaphore.acquire()  # 线程1 对信号量进行获取操作\n  \n\n  # Thread2:\n  def thread2_method():\n    semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器\n\n  ```\n  \n  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。\n  \n\n- 缺点：\n  \n  导致死锁\n\n  有多个线程（比如：`t1` ， `t2`），竞争多个信号量（比如：`s1` , `s2`）。 假如，现在有一个线程 `t1` 先等待信号量 `s1` ，然后等待信号量 `s2` ，而线程 `t2` 会先等待信号量 `s2` ，然后再等待信号量 `s1` ，这样就可能会发生死锁，导致 `t1` 等待 `s2` ，但是 `t2` 在等待 `s1` 。\n\n\n### Condition - 条件同步\n\n- 说明：\n  \n  当多个线程**等待**同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。\n\n- 使用：\n\n  ```\n  import threading\n\n  condition = threading.Condition()\n  \n  #  生产者\n  def thread1_method():\n    condition.acquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n        condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n    \n    # TODO do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()  # 释放资源\n\n  # 消费者\n  def thread2_method():\n     \n    condition.accquire()\n    # 条件判断\n    if (condition_var == False)：  # 条件不满足       \n         condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒\n\n    # 条件满足\n    # TODO  do something\n\n    condition.notify()  # 条件满足，通知其他线程\n    condition.release()   # 释放资源\n\n  ```\n  `wait` 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。\n  \n  `notify` 唤醒一个挂起的线程（如果存在挂起的线程）。注意：`notify()`方法不会释放所占用的琐。需要通过 `release()` 方法释放锁。\n\n\n- 缺点：\n  \n\n### Event - 事件\n\n- 说明：\n- 使用：\n\n  ```\n  import threading\n  event = threading.Event()\n  \n\n  ```\n\n- 缺点：\n\n\n\n\n\n**参考：**\n\n- [基于线程的并行](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html)\n\n- [What is the difference between Lock and RLock\n](https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock)\n\n\n","slug":"python-mulit-thread","published":1,"updated":"2019-03-21T11:41:49.289Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09ox50006t2xuzopwjnt9","content":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><ul>\n<li>说明：</li>\n</ul>\n<p>对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。</p>\n<ul>\n<li>使用：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">_lock = threading.lock() # 定义锁 _local</span><br><span class=\"line\"></span><br><span class=\"line\">_lock.accquire()  # 获取锁</span><br><span class=\"line\"># TODO do something</span><br><span class=\"line\">do_somthing(share_var)   # 操作共享资源</span><br><span class=\"line\">_lock.release()  #释放锁</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>缺点：</p>\n<p>死锁</p>\n<p>当有多个共享资源（比如：<code>R_A</code>, <code>R_B</code>），多个线程（比如：<code>T_A</code>, <code>T_B</code>），每个线程都需要操作共享资源。假如线程 <code>T_A</code> 已经获取了共享资源 <code>R_A</code>，<code>T_B</code> 获取了共享资源 <code>R_B</code> ， 而线程 <code>T_A</code> 等待 <code>T_B</code> 释放共享资源 <code>R_B</code> 。 同时，线程 <code>T_B</code> 等待 <code>T_A</code> 释放共享资源 <code>R_A</code> ，此时就陷入死锁状态。</p>\n</li>\n</ul>\n<h3 id=\"RLock\"><a href=\"#RLock\" class=\"headerlink\" title=\"RLock\"></a>RLock</h3><ul>\n<li><p>说明：</p>\n<p>RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 <code>Lock</code> 有是四个特点：</p>\n<ol>\n<li>谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 <code>Lock</code> 锁，可以被另外一个线程所释放。</li>\n<li>同一线程可以多次获取到该锁，即可以acquire多次；</li>\n<li>如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）</li>\n<li>相对 <code>Rlock</code> ， <code>Lock</code> 速度更快。</li>\n</ol>\n</li>\n<li><p>使用：</p>\n<p>使用 <code>Rlock</code> 锁</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">rLock = threading.RLock()  #RLock对象  </span><br><span class=\"line\">rLock.acquire()  </span><br><span class=\"line\">rLock.acquire() #在同一线程内，程序不会堵塞。  </span><br><span class=\"line\">rLock.release()  </span><br><span class=\"line\">rLock.release()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  使用 <code>Lock</code> 锁：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">lock = threading.Lock() #Lock对象  </span><br><span class=\"line\">lock.acquire()  </span><br><span class=\"line\">lock.acquire()  #产生了死琐。  </span><br><span class=\"line\">lock.release()  </span><br><span class=\"line\">lock.release()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"semaphore（信号量）\"><a href=\"#semaphore（信号量）\" class=\"headerlink\" title=\"semaphore（信号量）\"></a>semaphore（信号量）</h3><ul>\n<li><p>说明：</p>\n<p>信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为<strong>负值</strong>时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成<strong>非负值</strong>时。</p>\n<p>本质上，信号量就是一个计数器，当计数器的值为 <strong>非负值</strong> 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 <strong>负值</strong> 时，所有待获取共享资源的线程挂起状态。</p>\n</li>\n</ul>\n<ul>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">semaphore = threading.Semaphore(0)</span><br><span class=\"line\"></span><br><span class=\"line\"># Thread1:</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">    semaphore.acquire()  # 线程1 对信号量进行获取操作</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># Thread2:</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">  semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。</p>\n<ul>\n<li><p>缺点：</p>\n<p>导致死锁</p>\n<p>有多个线程（比如：<code>t1</code> ， <code>t2</code>），竞争多个信号量（比如：<code>s1</code> , <code>s2</code>）。 假如，现在有一个线程 <code>t1</code> 先等待信号量 <code>s1</code> ，然后等待信号量 <code>s2</code> ，而线程 <code>t2</code> 会先等待信号量 <code>s2</code> ，然后再等待信号量 <code>s1</code> ，这样就可能会发生死锁，导致 <code>t1</code> 等待 <code>s2</code> ，但是 <code>t2</code> 在等待 <code>s1</code> 。</p>\n</li>\n</ul>\n<h3 id=\"Condition-条件同步\"><a href=\"#Condition-条件同步\" class=\"headerlink\" title=\"Condition - 条件同步\"></a>Condition - 条件同步</h3><ul>\n<li><p>说明：</p>\n<p>当多个线程<strong>等待</strong>同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。</p>\n</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\"></span><br><span class=\"line\">condition = threading.Condition()</span><br><span class=\"line\"></span><br><span class=\"line\">#  生产者</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">  condition.acquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">      condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\">  </span><br><span class=\"line\">  # TODO do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()  # 释放资源</span><br><span class=\"line\"></span><br><span class=\"line\"># 消费者</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">   </span><br><span class=\"line\">  condition.accquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">       condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\"></span><br><span class=\"line\">  # 条件满足</span><br><span class=\"line\">  # TODO  do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()   # 释放资源</span><br></pre></td></tr></table></figure>\n<p><code>wait</code> 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。</p>\n<p><code>notify</code> 唤醒一个挂起的线程（如果存在挂起的线程）。注意：<code>notify()</code>方法不会释放所占用的琐。需要通过 <code>release()</code> 方法释放锁。</p>\n</li>\n</ul>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"Event-事件\"><a href=\"#Event-事件\" class=\"headerlink\" title=\"Event - 事件\"></a>Event - 事件</h3><ul>\n<li>说明：</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">event = threading.Event()</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺点：</p>\n</li>\n</ul>\n<p><strong>参考：</strong></p>\n<ul>\n<li><p><a href=\"https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html\" target=\"_blank\" rel=\"noopener\">基于线程的并行</a></p>\n</li>\n<li><p><a href=\"https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock\" target=\"_blank\" rel=\"noopener\">What is the difference between Lock and RLock\n</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h3><ul>\n<li>说明：</li>\n</ul>\n<p>对共享内存（资源），进行加锁，释放锁。保证同一时间，只有一个线程对共享资源进行操作。即保证了对共享资源的原子操作。</p>\n<ul>\n<li>使用：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">_lock = threading.lock() # 定义锁 _local</span><br><span class=\"line\"></span><br><span class=\"line\">_lock.accquire()  # 获取锁</span><br><span class=\"line\"># TODO do something</span><br><span class=\"line\">do_somthing(share_var)   # 操作共享资源</span><br><span class=\"line\">_lock.release()  #释放锁</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>缺点：</p>\n<p>死锁</p>\n<p>当有多个共享资源（比如：<code>R_A</code>, <code>R_B</code>），多个线程（比如：<code>T_A</code>, <code>T_B</code>），每个线程都需要操作共享资源。假如线程 <code>T_A</code> 已经获取了共享资源 <code>R_A</code>，<code>T_B</code> 获取了共享资源 <code>R_B</code> ， 而线程 <code>T_A</code> 等待 <code>T_B</code> 释放共享资源 <code>R_B</code> 。 同时，线程 <code>T_B</code> 等待 <code>T_A</code> 释放共享资源 <code>R_A</code> ，此时就陷入死锁状态。</p>\n</li>\n</ul>\n<h3 id=\"RLock\"><a href=\"#RLock\" class=\"headerlink\" title=\"RLock\"></a>RLock</h3><ul>\n<li><p>说明：</p>\n<p>RLock 其实叫做“Reentrant Lock”，就是可以重复进入的锁，也叫做“递归锁”。这种锁对比 <code>Lock</code> 有是四个特点：</p>\n<ol>\n<li>谁获取谁释放。如果线程A获取锁，线程B无法释放这个锁，只有A可以释放；而 <code>Lock</code> 锁，可以被另外一个线程所释放。</li>\n<li>同一线程可以多次获取到该锁，即可以acquire多次；</li>\n<li>如果使用RLock，那么acquire和release必须成对出现。acquire多少次就必须release多少次，只有最后一次release才能改变RLock的状态为unlocked）</li>\n<li>相对 <code>Rlock</code> ， <code>Lock</code> 速度更快。</li>\n</ol>\n</li>\n<li><p>使用：</p>\n<p>使用 <code>Rlock</code> 锁</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">rLock = threading.RLock()  #RLock对象  </span><br><span class=\"line\">rLock.acquire()  </span><br><span class=\"line\">rLock.acquire() #在同一线程内，程序不会堵塞。  </span><br><span class=\"line\">rLock.release()  </span><br><span class=\"line\">rLock.release()</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  使用 <code>Lock</code> 锁：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading  </span><br><span class=\"line\">lock = threading.Lock() #Lock对象  </span><br><span class=\"line\">lock.acquire()  </span><br><span class=\"line\">lock.acquire()  #产生了死琐。  </span><br><span class=\"line\">lock.release()  </span><br><span class=\"line\">lock.release()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"semaphore（信号量）\"><a href=\"#semaphore（信号量）\" class=\"headerlink\" title=\"semaphore（信号量）\"></a>semaphore（信号量）</h3><ul>\n<li><p>说明：</p>\n<p>信号量是由操作系统管理的一个内部的数据结构，用于表示共享资源当前支持有多少并发线程进行操作。当信号量为<strong>负值</strong>时，那么所有想获取共享资源的线程被挂起，直到有线程释放信号量，信号量的值变成<strong>非负值</strong>时。</p>\n<p>本质上，信号量就是一个计数器，当计数器的值为 <strong>非负值</strong> 时， 通知其他线程，可以对共享资源进行竞争。当计数器的值为 <strong>负值</strong> 时，所有待获取共享资源的线程挂起状态。</p>\n</li>\n</ul>\n<ul>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">semaphore = threading.Semaphore(0)</span><br><span class=\"line\"></span><br><span class=\"line\"># Thread1:</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">    semaphore.acquire()  # 线程1 对信号量进行获取操作</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># Thread2:</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">  semaphore.release()  # 线程2 对信号量进行释放操作，可以提高计数器</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>  信号量的 release() 可以对计数器加 1 操作。然后通知其他的线程，如果信号量的计数器到了0，就会阻塞 acquire() 方法，直到得到另一个线程的release()操作，通知。如果信号量的计数器大于0，就会对这个值 -1 然后分配资源。</p>\n<ul>\n<li><p>缺点：</p>\n<p>导致死锁</p>\n<p>有多个线程（比如：<code>t1</code> ， <code>t2</code>），竞争多个信号量（比如：<code>s1</code> , <code>s2</code>）。 假如，现在有一个线程 <code>t1</code> 先等待信号量 <code>s1</code> ，然后等待信号量 <code>s2</code> ，而线程 <code>t2</code> 会先等待信号量 <code>s2</code> ，然后再等待信号量 <code>s1</code> ，这样就可能会发生死锁，导致 <code>t1</code> 等待 <code>s2</code> ，但是 <code>t2</code> 在等待 <code>s1</code> 。</p>\n</li>\n</ul>\n<h3 id=\"Condition-条件同步\"><a href=\"#Condition-条件同步\" class=\"headerlink\" title=\"Condition - 条件同步\"></a>Condition - 条件同步</h3><ul>\n<li><p>说明：</p>\n<p>当多个线程<strong>等待</strong>同一个条件时，当条件发生的时候，会通知所有等待该条件的线程。比如生产者消费者里的例子：在消费者线程里，只要篮子（共享资源）不满（条件），消费者线程通知生产者线程可以操作该篮子（共享资源）；在生产者线程里，只要篮子不空（条件），生产者线程通知消费者线程可操作该篮子。</p>\n</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\"></span><br><span class=\"line\">condition = threading.Condition()</span><br><span class=\"line\"></span><br><span class=\"line\">#  生产者</span><br><span class=\"line\">def thread1_method():</span><br><span class=\"line\">  condition.acquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">      condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\">  </span><br><span class=\"line\">  # TODO do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()  # 释放资源</span><br><span class=\"line\"></span><br><span class=\"line\"># 消费者</span><br><span class=\"line\">def thread2_method():</span><br><span class=\"line\">   </span><br><span class=\"line\">  condition.accquire()</span><br><span class=\"line\">  # 条件判断</span><br><span class=\"line\">  if (condition_var == False)：  # 条件不满足       </span><br><span class=\"line\">       condition.wait()  # 释放锁，线程挂起，等待被其他线程唤醒</span><br><span class=\"line\"></span><br><span class=\"line\">  # 条件满足</span><br><span class=\"line\">  # TODO  do something</span><br><span class=\"line\"></span><br><span class=\"line\">  condition.notify()  # 条件满足，通知其他线程</span><br><span class=\"line\">  condition.release()   # 释放资源</span><br></pre></td></tr></table></figure>\n<p><code>wait</code> 方法释放内部所占用的琐，同时线程被挂起，直至接收到通知被唤醒或超时（如果提供了timeout参数的话）。当线程被唤醒并重新占有琐的时候，程序才会继续执行下去。</p>\n<p><code>notify</code> 唤醒一个挂起的线程（如果存在挂起的线程）。注意：<code>notify()</code>方法不会释放所占用的琐。需要通过 <code>release()</code> 方法释放锁。</p>\n</li>\n</ul>\n<ul>\n<li>缺点：</li>\n</ul>\n<h3 id=\"Event-事件\"><a href=\"#Event-事件\" class=\"headerlink\" title=\"Event - 事件\"></a>Event - 事件</h3><ul>\n<li>说明：</li>\n<li><p>使用：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import threading</span><br><span class=\"line\">event = threading.Event()</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺点：</p>\n</li>\n</ul>\n<p><strong>参考：</strong></p>\n<ul>\n<li><p><a href=\"https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter2/index.html\" target=\"_blank\" rel=\"noopener\">基于线程的并行</a></p>\n</li>\n<li><p><a href=\"https://stackoverflow.com/questions/22885775/what-is-the-difference-between-lock-and-rlock\" target=\"_blank\" rel=\"noopener\">What is the difference between Lock and RLock\n</a></p>\n</li>\n</ul>\n"},{"title":"合并两个有序数组——java实现","date":"2019-03-25T14:03:49.000Z","_content":"### 合并有序数组\n\n将两个有序数组合并成一个数组\n\n\n```\n/**\n * @function 合并两个有序数组arr1[] arr2[]\n * @author PC\n *\n */\npublic class MergeOrderList {\n\tpublic static void merge(int [] arr1,int [] arr2){\n\t\tint len1 = arr1.length;//数组1长度\n\t\tint len2 = arr2.length;//数组2长度\n\t\tint len = len1 + len2;//合并后数组长度\n\t\tint arr[] = new int[len];//合并后的数组\n\t\tint j = len1-1;\n\t\tint i = len2-1;\n\t\tlen--;\n\t\twhile(i>=0&&j>=0){//从后向前比较\n\t\t\tif(arr2[i]>arr1[j]){//将第二个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr2[i];\n\t\t\t\ti--;//“指针”后移一位\n\t\t\t}else if(arr2[i]<=arr1[j]){//将第一个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr1[j];\n\t\t\t\tj--;//“指针”后移一位\n\t\t\t}\n\t\t}\n\t\tif(i>j){//将剩余的数组1或者数组2的元素全部追加到数组arr\n\t\t\twhile(i>=0){\n\t\t\t\tarr[len--] = arr2[i--];\n\t\t\t}\n\t\t}else{\n\t\t\twhile(j>=0){\n\t\t\t\tarr[len--] = arr1[j--];\n\t\t\t}\n\t\t}\n\t\tfor (int k = 0; k < arr.length; k++) {\n\t\t\tSystem.out.print(arr[k]+\" \");\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint arr1[] = {1,4,5,7,10,11,15};\n\t\tint arr2[] = {2,3,6,8,9,13,14,17};\n\t\tmerge(arr1,arr2);\n\t}\n}\n\n```\n","source":"_posts/2019-03-25-algorithm-two-order-list-merge.md","raw":"---\ntitle: 合并两个有序数组——java实现\ndate: 2019-03-25 14:03:49\ntags:\n  - 算法\ncategories:\n  - 常见算法\n---\n### 合并有序数组\n\n将两个有序数组合并成一个数组\n\n\n```\n/**\n * @function 合并两个有序数组arr1[] arr2[]\n * @author PC\n *\n */\npublic class MergeOrderList {\n\tpublic static void merge(int [] arr1,int [] arr2){\n\t\tint len1 = arr1.length;//数组1长度\n\t\tint len2 = arr2.length;//数组2长度\n\t\tint len = len1 + len2;//合并后数组长度\n\t\tint arr[] = new int[len];//合并后的数组\n\t\tint j = len1-1;\n\t\tint i = len2-1;\n\t\tlen--;\n\t\twhile(i>=0&&j>=0){//从后向前比较\n\t\t\tif(arr2[i]>arr1[j]){//将第二个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr2[i];\n\t\t\t\ti--;//“指针”后移一位\n\t\t\t}else if(arr2[i]<=arr1[j]){//将第一个数组的最后第i个元素放入arr中\n\t\t\t\tarr[len--] = arr1[j];\n\t\t\t\tj--;//“指针”后移一位\n\t\t\t}\n\t\t}\n\t\tif(i>j){//将剩余的数组1或者数组2的元素全部追加到数组arr\n\t\t\twhile(i>=0){\n\t\t\t\tarr[len--] = arr2[i--];\n\t\t\t}\n\t\t}else{\n\t\t\twhile(j>=0){\n\t\t\t\tarr[len--] = arr1[j--];\n\t\t\t}\n\t\t}\n\t\tfor (int k = 0; k < arr.length; k++) {\n\t\t\tSystem.out.print(arr[k]+\" \");\n\t\t}\n\t}\n\tpublic static void main(String[] args) {\n\t\tint arr1[] = {1,4,5,7,10,11,15};\n\t\tint arr2[] = {2,3,6,8,9,13,14,17};\n\t\tmerge(arr1,arr2);\n\t}\n}\n\n```\n","slug":"algorithm-two-order-list-merge","published":1,"updated":"2019-03-25T08:34:33.291Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09ox70008t2xuo3xokjai","content":"<h3 id=\"合并有序数组\"><a href=\"#合并有序数组\" class=\"headerlink\" title=\"合并有序数组\"></a>合并有序数组</h3><p>将两个有序数组合并成一个数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * @function 合并两个有序数组arr1[] arr2[]</span><br><span class=\"line\"> * @author PC</span><br><span class=\"line\"> *</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class MergeOrderList &#123;</span><br><span class=\"line\">\tpublic static void merge(int [] arr1,int [] arr2)&#123;</span><br><span class=\"line\">\t\tint len1 = arr1.length;//数组1长度</span><br><span class=\"line\">\t\tint len2 = arr2.length;//数组2长度</span><br><span class=\"line\">\t\tint len = len1 + len2;//合并后数组长度</span><br><span class=\"line\">\t\tint arr[] = new int[len];//合并后的数组</span><br><span class=\"line\">\t\tint j = len1-1;</span><br><span class=\"line\">\t\tint i = len2-1;</span><br><span class=\"line\">\t\tlen--;</span><br><span class=\"line\">\t\twhile(i&gt;=0&amp;&amp;j&gt;=0)&#123;//从后向前比较</span><br><span class=\"line\">\t\t\tif(arr2[i]&gt;arr1[j])&#123;//将第二个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i];</span><br><span class=\"line\">\t\t\t\ti--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;else if(arr2[i]&lt;=arr1[j])&#123;//将第一个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j];</span><br><span class=\"line\">\t\t\t\tj--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif(i&gt;j)&#123;//将剩余的数组1或者数组2的元素全部追加到数组arr</span><br><span class=\"line\">\t\t\twhile(i&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;else&#123;</span><br><span class=\"line\">\t\t\twhile(j&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfor (int k = 0; k &lt; arr.length; k++) &#123;</span><br><span class=\"line\">\t\t\tSystem.out.print(arr[k]+&quot; &quot;);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpublic static void main(String[] args) &#123;</span><br><span class=\"line\">\t\tint arr1[] = &#123;1,4,5,7,10,11,15&#125;;</span><br><span class=\"line\">\t\tint arr2[] = &#123;2,3,6,8,9,13,14,17&#125;;</span><br><span class=\"line\">\t\tmerge(arr1,arr2);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"合并有序数组\"><a href=\"#合并有序数组\" class=\"headerlink\" title=\"合并有序数组\"></a>合并有序数组</h3><p>将两个有序数组合并成一个数组</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/**</span><br><span class=\"line\"> * @function 合并两个有序数组arr1[] arr2[]</span><br><span class=\"line\"> * @author PC</span><br><span class=\"line\"> *</span><br><span class=\"line\"> */</span><br><span class=\"line\">public class MergeOrderList &#123;</span><br><span class=\"line\">\tpublic static void merge(int [] arr1,int [] arr2)&#123;</span><br><span class=\"line\">\t\tint len1 = arr1.length;//数组1长度</span><br><span class=\"line\">\t\tint len2 = arr2.length;//数组2长度</span><br><span class=\"line\">\t\tint len = len1 + len2;//合并后数组长度</span><br><span class=\"line\">\t\tint arr[] = new int[len];//合并后的数组</span><br><span class=\"line\">\t\tint j = len1-1;</span><br><span class=\"line\">\t\tint i = len2-1;</span><br><span class=\"line\">\t\tlen--;</span><br><span class=\"line\">\t\twhile(i&gt;=0&amp;&amp;j&gt;=0)&#123;//从后向前比较</span><br><span class=\"line\">\t\t\tif(arr2[i]&gt;arr1[j])&#123;//将第二个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i];</span><br><span class=\"line\">\t\t\t\ti--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;else if(arr2[i]&lt;=arr1[j])&#123;//将第一个数组的最后第i个元素放入arr中</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j];</span><br><span class=\"line\">\t\t\t\tj--;//“指针”后移一位</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif(i&gt;j)&#123;//将剩余的数组1或者数组2的元素全部追加到数组arr</span><br><span class=\"line\">\t\t\twhile(i&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr2[i--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;else&#123;</span><br><span class=\"line\">\t\t\twhile(j&gt;=0)&#123;</span><br><span class=\"line\">\t\t\t\tarr[len--] = arr1[j--];</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tfor (int k = 0; k &lt; arr.length; k++) &#123;</span><br><span class=\"line\">\t\t\tSystem.out.print(arr[k]+&quot; &quot;);</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpublic static void main(String[] args) &#123;</span><br><span class=\"line\">\t\tint arr1[] = &#123;1,4,5,7,10,11,15&#125;;</span><br><span class=\"line\">\t\tint arr2[] = &#123;2,3,6,8,9,13,14,17&#125;;</span><br><span class=\"line\">\t\tmerge(arr1,arr2);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"},{"title":"gRPC教程——gRPC简介","date":"2019-03-25T18:00:58.000Z","_content":"\n\n## RPC\n\n`RPC` 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。\n\n`RPC`只是描绘了 `Client` 与 `Server` 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 `RPC` 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 `RPC` 框架有： `Thrift` （Facebook捐赠给Apache公司）、 `gRPC`（Google公司）， 国内优秀的 `RPC`框架有：`Dubbo` (Alibaba), `Motan` (sina) 。但是各个框架侧重点并不同，比如 `gRPC` 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 `Dubbo` 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。\n\n下面着重对 `RPC` 代表 `gRPC` 进行介绍：\n\n## gRPC\n`gRPC` 是一种使用`protocol buffer`接口定义语言（`Interface Definition Language, IDL`）定义服务的方法。\n\n在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 `RPC` 系统类似，`gRPC` 也是基于以下理念：定义一个服务(`service`)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 `gRPC` 服务器来处理客户端调用。在客户端拥有一个存根(`Stub`)能够像服务端一样的方法。\n\n`gRPC` 由三部分组成：\n\n - `gRPC Stub`, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口（数据结构）。\n - `gRPC server`, 定义：为远程过程调用提供服务的实际服务器。类似于HTTP服务器\n - `gRPC client`, 定义：使用 `gRPC` 客户端访问远程 `gRPC` 服务器。这就是使用 `gRPC` 简单的原因。调用 `gRPC` 方法就像调用另一个函数一样。\n\n\n![](/images/2019-03-25_180320.png)\n\n\n\n### Protocol Buffer\n\n `gRPC` 不使用 `JSON` 或 `XML` （非常庞大），而是使用Google `ProtocolBuffers` 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。\n\n默认情况下，`gRPC`使用协议缓冲区（`Protocol Buffers`），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。\n\n该协议缓冲区可以理解成**客户端**和**服务器**约定好的通信数据结构。\n\n使用`Protocol Buffers`，首选定义一个数据结构，后续用于序列化为`proto`类型文件——以`.proto`为后缀的文本文件。`Protocol Buffer`数据被结构化为 `messages` 。每个`message`包含一系列 `key-value`对，被称为域（field）：\n\n```\nmessage Person {\n    string name = 1;\n    int32 id = 2;\n    bool has_ponycopter = 3;\n}\n\n```\n\n然后，一旦定义了`Protocol Buffer`数据结构，可以使用`protocol buffer`编译器`protoc` 将定义的`proto file`编译成各个语言的数据访问类。这些方法为每个字段（比如 `name()`、`set_name()`）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择`C++`语言，对上述举例经过编译后，生成一个`Person`类，可以使用该类填充、序列化和检索`Person`协议缓冲区消息。\n\n正如您将在我们的示例中看到的那样，您在普通`proto`文件中定义`grpc`服务，并将 `rpc` 方法参数和返回类型指定为协议缓冲消息：\n\n```\n// 定义协议缓冲版本, 比如： syntax='proto3'\nsyntax=''\n\n// 定义服务端服务greeter service\nservice Greeter {\n  // 发送 greeter\n  //HelloRequest 请求的数据结构  HelloReply 返回的数据类型\n  // SayHello为服务端方法\n  rpc SayHello (HelloRequest) returns (HelloReply) {}  \n}\n\n// (请求消息结构)  request message\nmessage HelloRequest {\n  string name = 1;\n}\n\n// (响应消息结构) response  message\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n\n\n\n`gRPC`针对不同的语言，通过插件`protoc`通过`.proto`文件生成对应语言的代码。\n\n**`Protocol buffer` 版本**\n\n通常，虽然您可以使用`proto2`（当前的默认协议缓冲版本），但我们建议您将 `proto3` 与 `gRPC` 一起使用，因为它允许您使用全系列的 `gRPC` 支持的语言，以及避免与 `proto2` 客户端通信时的兼容性问题`proto3`服务器，反之亦然\n\n## RPC vs RESTful\n\n1. RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.\n2. RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的**方法**和**过程**进行调用。而RESTful操作的对象是**资源**，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。\n3. 操作的对象不一样。 `RPC` 操作的是方法和过程，它要操作的是方法对象。 `RESTful` 操作的是资源(resource)，而不是方法。\n4. RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。\n\n\n## 参考：\n - [gRPC官方文档](https://grpc.io/docs/)\n - [gRPC 官方文档中文版](https://doc.oschina.net/grpc)\n - [MicroServices on gRPC](https://technokeeda.com/programming/microservices-on-grpc/)","source":"_posts/2019-03-25-grpc-introduction.md","raw":"---\ntitle: gRPC教程——gRPC简介\ndate: 2019-03-25 18:00:58\ntags:\n  - gRPC\ncategories:\n  - gRPC\n---\n\n\n## RPC\n\n`RPC` 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。\n\n`RPC`只是描绘了 `Client` 与 `Server` 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 `RPC` 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 `RPC` 框架有： `Thrift` （Facebook捐赠给Apache公司）、 `gRPC`（Google公司）， 国内优秀的 `RPC`框架有：`Dubbo` (Alibaba), `Motan` (sina) 。但是各个框架侧重点并不同，比如 `gRPC` 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 `Dubbo` 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。\n\n下面着重对 `RPC` 代表 `gRPC` 进行介绍：\n\n## gRPC\n`gRPC` 是一种使用`protocol buffer`接口定义语言（`Interface Definition Language, IDL`）定义服务的方法。\n\n在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 `RPC` 系统类似，`gRPC` 也是基于以下理念：定义一个服务(`service`)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 `gRPC` 服务器来处理客户端调用。在客户端拥有一个存根(`Stub`)能够像服务端一样的方法。\n\n`gRPC` 由三部分组成：\n\n - `gRPC Stub`, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口（数据结构）。\n - `gRPC server`, 定义：为远程过程调用提供服务的实际服务器。类似于HTTP服务器\n - `gRPC client`, 定义：使用 `gRPC` 客户端访问远程 `gRPC` 服务器。这就是使用 `gRPC` 简单的原因。调用 `gRPC` 方法就像调用另一个函数一样。\n\n\n![](/images/2019-03-25_180320.png)\n\n\n\n### Protocol Buffer\n\n `gRPC` 不使用 `JSON` 或 `XML` （非常庞大），而是使用Google `ProtocolBuffers` 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。\n\n默认情况下，`gRPC`使用协议缓冲区（`Protocol Buffers`），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。\n\n该协议缓冲区可以理解成**客户端**和**服务器**约定好的通信数据结构。\n\n使用`Protocol Buffers`，首选定义一个数据结构，后续用于序列化为`proto`类型文件——以`.proto`为后缀的文本文件。`Protocol Buffer`数据被结构化为 `messages` 。每个`message`包含一系列 `key-value`对，被称为域（field）：\n\n```\nmessage Person {\n    string name = 1;\n    int32 id = 2;\n    bool has_ponycopter = 3;\n}\n\n```\n\n然后，一旦定义了`Protocol Buffer`数据结构，可以使用`protocol buffer`编译器`protoc` 将定义的`proto file`编译成各个语言的数据访问类。这些方法为每个字段（比如 `name()`、`set_name()`）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择`C++`语言，对上述举例经过编译后，生成一个`Person`类，可以使用该类填充、序列化和检索`Person`协议缓冲区消息。\n\n正如您将在我们的示例中看到的那样，您在普通`proto`文件中定义`grpc`服务，并将 `rpc` 方法参数和返回类型指定为协议缓冲消息：\n\n```\n// 定义协议缓冲版本, 比如： syntax='proto3'\nsyntax=''\n\n// 定义服务端服务greeter service\nservice Greeter {\n  // 发送 greeter\n  //HelloRequest 请求的数据结构  HelloReply 返回的数据类型\n  // SayHello为服务端方法\n  rpc SayHello (HelloRequest) returns (HelloReply) {}  \n}\n\n// (请求消息结构)  request message\nmessage HelloRequest {\n  string name = 1;\n}\n\n// (响应消息结构) response  message\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n\n\n\n`gRPC`针对不同的语言，通过插件`protoc`通过`.proto`文件生成对应语言的代码。\n\n**`Protocol buffer` 版本**\n\n通常，虽然您可以使用`proto2`（当前的默认协议缓冲版本），但我们建议您将 `proto3` 与 `gRPC` 一起使用，因为它允许您使用全系列的 `gRPC` 支持的语言，以及避免与 `proto2` 客户端通信时的兼容性问题`proto3`服务器，反之亦然\n\n## RPC vs RESTful\n\n1. RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.\n2. RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的**方法**和**过程**进行调用。而RESTful操作的对象是**资源**，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。\n3. 操作的对象不一样。 `RPC` 操作的是方法和过程，它要操作的是方法对象。 `RESTful` 操作的是资源(resource)，而不是方法。\n4. RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。\n\n\n## 参考：\n - [gRPC官方文档](https://grpc.io/docs/)\n - [gRPC 官方文档中文版](https://doc.oschina.net/grpc)\n - [MicroServices on gRPC](https://technokeeda.com/programming/microservices-on-grpc/)","slug":"grpc-introduction","published":1,"updated":"2019-03-25T13:14:50.011Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09ox90009t2xux9wvjdzn","content":"<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p><code>RPC</code> 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。</p>\n<p><code>RPC</code>只是描绘了 <code>Client</code> 与 <code>Server</code> 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 <code>RPC</code> 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 <code>RPC</code> 框架有： <code>Thrift</code> （Facebook捐赠给Apache公司）、 <code>gRPC</code>（Google公司）， 国内优秀的 <code>RPC</code>框架有：<code>Dubbo</code> (Alibaba), <code>Motan</code> (sina) 。但是各个框架侧重点并不同，比如 <code>gRPC</code> 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 <code>Dubbo</code> 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p>\n<p>下面着重对 <code>RPC</code> 代表 <code>gRPC</code> 进行介绍：</p>\n<h2 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a>gRPC</h2><p><code>gRPC</code> 是一种使用<code>protocol buffer</code>接口定义语言（<code>Interface Definition Language, IDL</code>）定义服务的方法。</p>\n<p>在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 <code>RPC</code> 系统类似，<code>gRPC</code> 也是基于以下理念：定义一个服务(<code>service</code>)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 <code>gRPC</code> 服务器来处理客户端调用。在客户端拥有一个存根(<code>Stub</code>)能够像服务端一样的方法。</p>\n<p><code>gRPC</code> 由三部分组成：</p>\n<ul>\n<li><code>gRPC Stub</code>, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口（数据结构）。</li>\n<li><code>gRPC server</code>, 定义：为远程过程调用提供服务的实际服务器。类似于HTTP服务器</li>\n<li><code>gRPC client</code>, 定义：使用 <code>gRPC</code> 客户端访问远程 <code>gRPC</code> 服务器。这就是使用 <code>gRPC</code> 简单的原因。调用 <code>gRPC</code> 方法就像调用另一个函数一样。</li>\n</ul>\n<p><img src=\"/images/2019-03-25_180320.png\" alt></p>\n<h3 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h3><p> <code>gRPC</code> 不使用 <code>JSON</code> 或 <code>XML</code> （非常庞大），而是使用Google <code>ProtocolBuffers</code> 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。</p>\n<p>默认情况下，<code>gRPC</code>使用协议缓冲区（<code>Protocol Buffers</code>），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。</p>\n<p>该协议缓冲区可以理解成<strong>客户端</strong>和<strong>服务器</strong>约定好的通信数据结构。</p>\n<p>使用<code>Protocol Buffers</code>，首选定义一个数据结构，后续用于序列化为<code>proto</code>类型文件——以<code>.proto</code>为后缀的文本文件。<code>Protocol Buffer</code>数据被结构化为 <code>messages</code> 。每个<code>message</code>包含一系列 <code>key-value</code>对，被称为域（field）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message Person &#123;</span><br><span class=\"line\">    string name = 1;</span><br><span class=\"line\">    int32 id = 2;</span><br><span class=\"line\">    bool has_ponycopter = 3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后，一旦定义了<code>Protocol Buffer</code>数据结构，可以使用<code>protocol buffer</code>编译器<code>protoc</code> 将定义的<code>proto file</code>编译成各个语言的数据访问类。这些方法为每个字段（比如 <code>name()</code>、<code>set_name()</code>）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择<code>C++</code>语言，对上述举例经过编译后，生成一个<code>Person</code>类，可以使用该类填充、序列化和检索<code>Person</code>协议缓冲区消息。</p>\n<p>正如您将在我们的示例中看到的那样，您在普通<code>proto</code>文件中定义<code>grpc</code>服务，并将 <code>rpc</code> 方法参数和返回类型指定为协议缓冲消息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 定义协议缓冲版本, 比如： syntax=&apos;proto3&apos;</span><br><span class=\"line\">syntax=&apos;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">// 定义服务端服务greeter service</span><br><span class=\"line\">service Greeter &#123;</span><br><span class=\"line\">  // 发送 greeter</span><br><span class=\"line\">  //HelloRequest 请求的数据结构  HelloReply 返回的数据类型</span><br><span class=\"line\">  // SayHello为服务端方法</span><br><span class=\"line\">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (请求消息结构)  request message</span><br><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string name = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (响应消息结构) response  message</span><br><span class=\"line\">message HelloReply &#123;</span><br><span class=\"line\">  string message = 1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>gRPC</code>针对不同的语言，通过插件<code>protoc</code>通过<code>.proto</code>文件生成对应语言的代码。</p>\n<p><strong><code>Protocol buffer</code> 版本</strong></p>\n<p>通常，虽然您可以使用<code>proto2</code>（当前的默认协议缓冲版本），但我们建议您将 <code>proto3</code> 与 <code>gRPC</code> 一起使用，因为它允许您使用全系列的 <code>gRPC</code> 支持的语言，以及避免与 <code>proto2</code> 客户端通信时的兼容性问题<code>proto3</code>服务器，反之亦然</p>\n<h2 id=\"RPC-vs-RESTful\"><a href=\"#RPC-vs-RESTful\" class=\"headerlink\" title=\"RPC vs RESTful\"></a>RPC vs RESTful</h2><ol>\n<li>RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.</li>\n<li>RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的<strong>方法</strong>和<strong>过程</strong>进行调用。而RESTful操作的对象是<strong>资源</strong>，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。</li>\n<li>操作的对象不一样。 <code>RPC</code> 操作的是方法和过程，它要操作的是方法对象。 <code>RESTful</code> 操作的是资源(resource)，而不是方法。</li>\n<li>RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。</li>\n</ol>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><ul>\n<li><a href=\"https://grpc.io/docs/\" target=\"_blank\" rel=\"noopener\">gRPC官方文档</a></li>\n<li><a href=\"https://doc.oschina.net/grpc\" target=\"_blank\" rel=\"noopener\">gRPC 官方文档中文版</a></li>\n<li><a href=\"https://technokeeda.com/programming/microservices-on-grpc/\" target=\"_blank\" rel=\"noopener\">MicroServices on gRPC</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p><code>RPC</code> 远程过程调用（Remote Procedure Call，缩写为 RPC）是一个计算机通信协议，该协议允许一台主机上的应用程序调用另一台主机上的应用程序中的方法。 远程过程调用总是由客户端对服务器发出一个执行若干过程请求，并用客户端提供的参数。执行结果将返回给客户端。</p>\n<p><code>RPC</code>只是描绘了 <code>Client</code> 与 <code>Server</code> 之间的点对点调用流程，还需要考虑服务的高可用、负载均衡等问题。在开发 <code>RPC</code> 框架时，还应当考虑到服务的发现与注册，负载均衡，服务高可用等功能。目前市场上比较优秀的 <code>RPC</code> 框架有： <code>Thrift</code> （Facebook捐赠给Apache公司）、 <code>gRPC</code>（Google公司）， 国内优秀的 <code>RPC</code>框架有：<code>Dubbo</code> (Alibaba), <code>Motan</code> (sina) 。但是各个框架侧重点并不同，比如 <code>gRPC</code> 侧重于跨语言特性，适合于为不同语言提供通用远程服务。 <code>Dubbo</code> 侧重于高性能的远程调用以及服务发现和治理功能，适用于大型服务的微服务化拆分以及管理，对于特定语言（Java）的项目可以十分友好的透明化接入。但缺点是语言耦合度较高，跨语言支持难度较大。</p>\n<p>下面着重对 <code>RPC</code> 代表 <code>gRPC</code> 进行介绍：</p>\n<h2 id=\"gRPC\"><a href=\"#gRPC\" class=\"headerlink\" title=\"gRPC\"></a>gRPC</h2><p><code>gRPC</code> 是一种使用<code>protocol buffer</code>接口定义语言（<code>Interface Definition Language, IDL</code>）定义服务的方法。</p>\n<p>在 gRPC 里，客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，能够更容易地创建分布式应用和服务。与许多 <code>RPC</code> 系统类似，<code>gRPC</code> 也是基于以下理念：定义一个服务(<code>service</code>)，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 <code>gRPC</code> 服务器来处理客户端调用。在客户端拥有一个存根(<code>Stub</code>)能够像服务端一样的方法。</p>\n<p><code>gRPC</code> 由三部分组成：</p>\n<ul>\n<li><code>gRPC Stub</code>, 定义: 这是一个包含所有原型定义的配置文件，它还包含要提供的所有远程过程调用的声明。通过该配置文件，生成服务端和客户端通信的接口（数据结构）。</li>\n<li><code>gRPC server</code>, 定义：为远程过程调用提供服务的实际服务器。类似于HTTP服务器</li>\n<li><code>gRPC client</code>, 定义：使用 <code>gRPC</code> 客户端访问远程 <code>gRPC</code> 服务器。这就是使用 <code>gRPC</code> 简单的原因。调用 <code>gRPC</code> 方法就像调用另一个函数一样。</li>\n</ul>\n<p><img src=\"/images/2019-03-25_180320.png\" alt></p>\n<h3 id=\"Protocol-Buffer\"><a href=\"#Protocol-Buffer\" class=\"headerlink\" title=\"Protocol Buffer\"></a>Protocol Buffer</h3><p> <code>gRPC</code> 不使用 <code>JSON</code> 或 <code>XML</code> （非常庞大），而是使用Google <code>ProtocolBuffers</code> 发送数据。这可以使通过网络传输的消息的大小平均减少 30％ 以上，并且在某些情况下，消息大小可以小于原始消息的 20％。这直接转换为您的系统使用比以前少 30％-80％ 的带宽。</p>\n<p>默认情况下，<code>gRPC</code>使用协议缓冲区（<code>Protocol Buffers</code>），这是Google成熟的开放源码机制，用于序列化结构化数据（尽管它可以与其他数据格式（如JSON）一起使用）。</p>\n<p>该协议缓冲区可以理解成<strong>客户端</strong>和<strong>服务器</strong>约定好的通信数据结构。</p>\n<p>使用<code>Protocol Buffers</code>，首选定义一个数据结构，后续用于序列化为<code>proto</code>类型文件——以<code>.proto</code>为后缀的文本文件。<code>Protocol Buffer</code>数据被结构化为 <code>messages</code> 。每个<code>message</code>包含一系列 <code>key-value</code>对，被称为域（field）：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message Person &#123;</span><br><span class=\"line\">    string name = 1;</span><br><span class=\"line\">    int32 id = 2;</span><br><span class=\"line\">    bool has_ponycopter = 3;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>然后，一旦定义了<code>Protocol Buffer</code>数据结构，可以使用<code>protocol buffer</code>编译器<code>protoc</code> 将定义的<code>proto file</code>编译成各个语言的数据访问类。这些方法为每个字段（比如 <code>name()</code>、<code>set_name()</code>）提供访问器，对整个数据结构进行序列化或者解析为原始字节，或者相反操作。比如选择<code>C++</code>语言，对上述举例经过编译后，生成一个<code>Person</code>类，可以使用该类填充、序列化和检索<code>Person</code>协议缓冲区消息。</p>\n<p>正如您将在我们的示例中看到的那样，您在普通<code>proto</code>文件中定义<code>grpc</code>服务，并将 <code>rpc</code> 方法参数和返回类型指定为协议缓冲消息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 定义协议缓冲版本, 比如： syntax=&apos;proto3&apos;</span><br><span class=\"line\">syntax=&apos;&apos;</span><br><span class=\"line\"></span><br><span class=\"line\">// 定义服务端服务greeter service</span><br><span class=\"line\">service Greeter &#123;</span><br><span class=\"line\">  // 发送 greeter</span><br><span class=\"line\">  //HelloRequest 请求的数据结构  HelloReply 返回的数据类型</span><br><span class=\"line\">  // SayHello为服务端方法</span><br><span class=\"line\">  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (请求消息结构)  request message</span><br><span class=\"line\">message HelloRequest &#123;</span><br><span class=\"line\">  string name = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// (响应消息结构) response  message</span><br><span class=\"line\">message HelloReply &#123;</span><br><span class=\"line\">  string message = 1;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>gRPC</code>针对不同的语言，通过插件<code>protoc</code>通过<code>.proto</code>文件生成对应语言的代码。</p>\n<p><strong><code>Protocol buffer</code> 版本</strong></p>\n<p>通常，虽然您可以使用<code>proto2</code>（当前的默认协议缓冲版本），但我们建议您将 <code>proto3</code> 与 <code>gRPC</code> 一起使用，因为它允许您使用全系列的 <code>gRPC</code> 支持的语言，以及避免与 <code>proto2</code> 客户端通信时的兼容性问题<code>proto3</code>服务器，反之亦然</p>\n<h2 id=\"RPC-vs-RESTful\"><a href=\"#RPC-vs-RESTful\" class=\"headerlink\" title=\"RPC vs RESTful\"></a>RPC vs RESTful</h2><ol>\n<li>RPC 可以基于TCP、UDP或者HTTP进行消息传输，而RESTful只能基于HTTP协议进行消息传输.</li>\n<li>RPC 客户端和服务端紧耦合，客户端需要通过参数以及过程名称对服务端的<strong>方法</strong>和<strong>过程</strong>进行调用。而RESTful操作的对象是<strong>资源</strong>，RESTful对资源进行操作：增加、查找、删除等，主要是CRUD。</li>\n<li>操作的对象不一样。 <code>RPC</code> 操作的是方法和过程，它要操作的是方法对象。 <code>RESTful</code> 操作的是资源(resource)，而不是方法。</li>\n<li>RPC实现长连接：RPC over TCP （性能优越，适用于高并发）。RESTful实现长连接，必须通过HTTP协议的keep-alive实现长连接，但是遇到一个问题是 request-response模式是阻塞的。</li>\n</ol>\n<h2 id=\"参考：\"><a href=\"#参考：\" class=\"headerlink\" title=\"参考：\"></a>参考：</h2><ul>\n<li><a href=\"https://grpc.io/docs/\" target=\"_blank\" rel=\"noopener\">gRPC官方文档</a></li>\n<li><a href=\"https://doc.oschina.net/grpc\" target=\"_blank\" rel=\"noopener\">gRPC 官方文档中文版</a></li>\n<li><a href=\"https://technokeeda.com/programming/microservices-on-grpc/\" target=\"_blank\" rel=\"noopener\">MicroServices on gRPC</a></li>\n</ul>\n"},{"title":"Centos 安装 docker","date":"2019-03-25T13:35:59.000Z","_content":"\n>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。\n\n#### 移除旧版本docker\n卸载旧版本docker，如果未安装，可以跳过\n```\n$ yum remove -y docker docker-client \\\n   docker-client-latest  \\\n   docker-common \\\n   docker-latest \\\n   docker-latest-logrotate \\\n   docker-logrotate \\\n   docker-selinux \\\n   docker-engine-selinux \\\n   docker-engine\n```\n#### 安装依赖软件\n```\n$ yum install -y yum-utils \\\n    device-mapper-persistent-data \\\n    lvm2\n```\n#### 配置yum源为阿里云提供的yum源\n```\n$ yum-config-manager \\\n--add-repo \\\nhttps://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n#### 查看该yum源提供的可用docker-ce版本\n```\n$ yum list docker-ce –showduplicates | sort -r\n\ndocker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable\ndocker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable \ndocker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable\n```\n\n 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce\n 安装docker-ce 18.06版本\n\n - 安装docker-ce 18.06版本\n\n   `$ yum install docker-ce-18.06.1.ce -y`\n\n - 启动docker\n\n   `$ systemctl start docker`\n\n - 设置开机启动\n\n   `$ systemctl enable docker`\n\n - 授权用户\n   \n   将用户添加到docker组\n\n   `$ sudo usermod -aG docker $USER`\n\n- 配置镜像仓库加速\n\n  配置镜像加速：使用aliyun提供的镜像加速\n\n  通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\n   ```\n   $ sudo mkdir -p /etc/docker\n   $ sudo tee /etc/docker/daemon.json <<-'EOF' {\n       \"registry-mirrors\":[\"https://xxxxxx.mirror.aliyuncs.com\"] }\n     EOF\n   ```\n\n   注意 https://xxxxxx.mirror.aliyuncs.com 需要注册阿里云申请镜像仓库\n   如果没有，可以使用作者的：https://hjjs2fuv.mirror.aliyuncs.com\n\n- 重新加载docker service使其生效\n\n  `$ systemctl daemon-reload`\n\n  `$ systemctl restart docker`\n\n\n","source":"_posts/2019-03-25-install-docker-yum.md","raw":"---\ntitle: Centos 安装 docker\ndate: 2019-03-25 13:35:59\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\n>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。\n\n#### 移除旧版本docker\n卸载旧版本docker，如果未安装，可以跳过\n```\n$ yum remove -y docker docker-client \\\n   docker-client-latest  \\\n   docker-common \\\n   docker-latest \\\n   docker-latest-logrotate \\\n   docker-logrotate \\\n   docker-selinux \\\n   docker-engine-selinux \\\n   docker-engine\n```\n#### 安装依赖软件\n```\n$ yum install -y yum-utils \\\n    device-mapper-persistent-data \\\n    lvm2\n```\n#### 配置yum源为阿里云提供的yum源\n```\n$ yum-config-manager \\\n--add-repo \\\nhttps://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n#### 查看该yum源提供的可用docker-ce版本\n```\n$ yum list docker-ce –showduplicates | sort -r\n\ndocker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable\ndocker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable \ndocker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable \ndocker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable \ndocker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable\n```\n\n 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce\n 安装docker-ce 18.06版本\n\n - 安装docker-ce 18.06版本\n\n   `$ yum install docker-ce-18.06.1.ce -y`\n\n - 启动docker\n\n   `$ systemctl start docker`\n\n - 设置开机启动\n\n   `$ systemctl enable docker`\n\n - 授权用户\n   \n   将用户添加到docker组\n\n   `$ sudo usermod -aG docker $USER`\n\n- 配置镜像仓库加速\n\n  配置镜像加速：使用aliyun提供的镜像加速\n\n  通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\n   ```\n   $ sudo mkdir -p /etc/docker\n   $ sudo tee /etc/docker/daemon.json <<-'EOF' {\n       \"registry-mirrors\":[\"https://xxxxxx.mirror.aliyuncs.com\"] }\n     EOF\n   ```\n\n   注意 https://xxxxxx.mirror.aliyuncs.com 需要注册阿里云申请镜像仓库\n   如果没有，可以使用作者的：https://hjjs2fuv.mirror.aliyuncs.com\n\n- 重新加载docker service使其生效\n\n  `$ systemctl daemon-reload`\n\n  `$ systemctl restart docker`\n\n\n","slug":"install-docker-yum","published":1,"updated":"2019-03-25T05:37:02.708Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oxc000ct2xur7oqqc9q","content":"<blockquote>\n<p>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。</p>\n</blockquote>\n<h4 id=\"移除旧版本docker\"><a href=\"#移除旧版本docker\" class=\"headerlink\" title=\"移除旧版本docker\"></a>移除旧版本docker</h4><p>卸载旧版本docker，如果未安装，可以跳过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove -y docker docker-client \\</span><br><span class=\"line\">   docker-client-latest  \\</span><br><span class=\"line\">   docker-common \\</span><br><span class=\"line\">   docker-latest \\</span><br><span class=\"line\">   docker-latest-logrotate \\</span><br><span class=\"line\">   docker-logrotate \\</span><br><span class=\"line\">   docker-selinux \\</span><br><span class=\"line\">   docker-engine-selinux \\</span><br><span class=\"line\">   docker-engine</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"安装依赖软件\"><a href=\"#安装依赖软件\" class=\"headerlink\" title=\"安装依赖软件\"></a>安装依赖软件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y yum-utils \\</span><br><span class=\"line\">    device-mapper-persistent-data \\</span><br><span class=\"line\">    lvm2</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置yum源为阿里云提供的yum源\"><a href=\"#配置yum源为阿里云提供的yum源\" class=\"headerlink\" title=\"配置yum源为阿里云提供的yum源\"></a>配置yum源为阿里云提供的yum源</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum-config-manager \\</span><br><span class=\"line\">--add-repo \\</span><br><span class=\"line\">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看该yum源提供的可用docker-ce版本\"><a href=\"#查看该yum源提供的可用docker-ce版本\" class=\"headerlink\" title=\"查看该yum源提供的可用docker-ce版本\"></a>查看该yum源提供的可用docker-ce版本</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum list docker-ce –showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\">docker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable</span><br><span class=\"line\">docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</span><br></pre></td></tr></table></figure>\n<p> 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce<br> 安装docker-ce 18.06版本</p>\n<ul>\n<li><p>安装docker-ce 18.06版本</p>\n<p><code>$ yum install docker-ce-18.06.1.ce -y</code></p>\n</li>\n<li><p>启动docker</p>\n<p><code>$ systemctl start docker</code></p>\n</li>\n<li><p>设置开机启动</p>\n<p><code>$ systemctl enable docker</code></p>\n</li>\n<li><p>授权用户</p>\n<p>将用户添加到docker组</p>\n<p><code>$ sudo usermod -aG docker $USER</code></p>\n</li>\n</ul>\n<ul>\n<li><p>配置镜像仓库加速</p>\n<p>配置镜像加速：使用aliyun提供的镜像加速</p>\n<p>通过修改daemon配置文件/etc/docker/daemon.json来使用加速器</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir -p /etc/docker</span><br><span class=\"line\">$ sudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos; &#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;:[&quot;https://xxxxxx.mirror.aliyuncs.com&quot;] &#125;</span><br><span class=\"line\">  EOF</span><br></pre></td></tr></table></figure>\n<p> 注意 <a href=\"https://xxxxxx.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://xxxxxx.mirror.aliyuncs.com</a> 需要注册阿里云申请镜像仓库<br> 如果没有，可以使用作者的：<a href=\"https://hjjs2fuv.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://hjjs2fuv.mirror.aliyuncs.com</a></p>\n</li>\n<li><p>重新加载docker service使其生效</p>\n<p><code>$ systemctl daemon-reload</code></p>\n<p><code>$ systemctl restart docker</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本教程适用于对docker入门新手，在学习docker时，安装部署docker是第一步，然后跟着教程一步一步练习。</p>\n</blockquote>\n<h4 id=\"移除旧版本docker\"><a href=\"#移除旧版本docker\" class=\"headerlink\" title=\"移除旧版本docker\"></a>移除旧版本docker</h4><p>卸载旧版本docker，如果未安装，可以跳过<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum remove -y docker docker-client \\</span><br><span class=\"line\">   docker-client-latest  \\</span><br><span class=\"line\">   docker-common \\</span><br><span class=\"line\">   docker-latest \\</span><br><span class=\"line\">   docker-latest-logrotate \\</span><br><span class=\"line\">   docker-logrotate \\</span><br><span class=\"line\">   docker-selinux \\</span><br><span class=\"line\">   docker-engine-selinux \\</span><br><span class=\"line\">   docker-engine</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"安装依赖软件\"><a href=\"#安装依赖软件\" class=\"headerlink\" title=\"安装依赖软件\"></a>安装依赖软件</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y yum-utils \\</span><br><span class=\"line\">    device-mapper-persistent-data \\</span><br><span class=\"line\">    lvm2</span><br></pre></td></tr></table></figure>\n<h4 id=\"配置yum源为阿里云提供的yum源\"><a href=\"#配置yum源为阿里云提供的yum源\" class=\"headerlink\" title=\"配置yum源为阿里云提供的yum源\"></a>配置yum源为阿里云提供的yum源</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum-config-manager \\</span><br><span class=\"line\">--add-repo \\</span><br><span class=\"line\">https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>\n<h4 id=\"查看该yum源提供的可用docker-ce版本\"><a href=\"#查看该yum源提供的可用docker-ce版本\" class=\"headerlink\" title=\"查看该yum源提供的可用docker-ce版本\"></a>查看该yum源提供的可用docker-ce版本</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum list docker-ce –showduplicates | sort -r</span><br><span class=\"line\"></span><br><span class=\"line\">docker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.06.1.ce-3.el7                   @docker-ce-stable</span><br><span class=\"line\">docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable </span><br><span class=\"line\">docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable</span><br></pre></td></tr></table></figure>\n<p> 查看可用docker-ce版本，根据需求，安装指定版本的docker-ce<br> 安装docker-ce 18.06版本</p>\n<ul>\n<li><p>安装docker-ce 18.06版本</p>\n<p><code>$ yum install docker-ce-18.06.1.ce -y</code></p>\n</li>\n<li><p>启动docker</p>\n<p><code>$ systemctl start docker</code></p>\n</li>\n<li><p>设置开机启动</p>\n<p><code>$ systemctl enable docker</code></p>\n</li>\n<li><p>授权用户</p>\n<p>将用户添加到docker组</p>\n<p><code>$ sudo usermod -aG docker $USER</code></p>\n</li>\n</ul>\n<ul>\n<li><p>配置镜像仓库加速</p>\n<p>配置镜像加速：使用aliyun提供的镜像加速</p>\n<p>通过修改daemon配置文件/etc/docker/daemon.json来使用加速器</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir -p /etc/docker</span><br><span class=\"line\">$ sudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos; &#123;</span><br><span class=\"line\">    &quot;registry-mirrors&quot;:[&quot;https://xxxxxx.mirror.aliyuncs.com&quot;] &#125;</span><br><span class=\"line\">  EOF</span><br></pre></td></tr></table></figure>\n<p> 注意 <a href=\"https://xxxxxx.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://xxxxxx.mirror.aliyuncs.com</a> 需要注册阿里云申请镜像仓库<br> 如果没有，可以使用作者的：<a href=\"https://hjjs2fuv.mirror.aliyuncs.com\" target=\"_blank\" rel=\"noopener\">https://hjjs2fuv.mirror.aliyuncs.com</a></p>\n</li>\n<li><p>重新加载docker service使其生效</p>\n<p><code>$ systemctl daemon-reload</code></p>\n<p><code>$ systemctl restart docker</code></p>\n</li>\n</ul>\n"},{"title":"精通Oracle SQL（第二版）读书笔记   -  第一章 SQL核心","date":"2016-12-05T13:52:54.000Z","_content":"\n\nracle SQL（第二版）读书笔记\n## 第一章 SQL核心\n### 数据库接口\n> 1.数据库接口:\n> Oracle数据库的本地接口界面是**OCI**,**OCI** 将由 **Oracle内核**传递而来的查询语句发送到数据库。其他语言对应的接口：*Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动*。\n\n### SQL*Plus\n>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。\n\n\n### 常用命令：\n> * sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。\n\n> * help index： 显示可用的命令\n\n> * help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。\n\n### 在login.sql文件中修改配置\n\n> 在sql* plus启动时默认读取的两个文件，1.**$ORACLE_HOME/sqlplus/admin** 目录下的 **glogin.sql**和**login.sql** 文件。其中，**login.sql**中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。\n\n### 执行命令\n>在sql* plus中执行的是两种命令：**sql语句** 和 **SQL * Plus命令**\n\n>SQL语句用**；** 和 **/** 结束输入\n\n -  1.  可在命令后和另起一行使用；\n -  2.  /只能在下行中被识别。\n>sqlplus缓冲区\n>sqlplus执行 *.sql 文件方式：1.直接输入 *.sql,2.输入@或者START *，可以省略后缀。\n\n### 五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\n#### 1. SELECT 语句\n##### Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\n##### - select语句\n> 处理过程中首先处理的是**From**子句，多个**From**则每个步骤想象成一个临时数据集，每经过一个**FROM**，则进行一步筛选，得最终结果数据集。\n\n##### - From子句\n> 子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。\n\n##### - HAVING子句\n> 将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。\n\n##### - ORDER BY子句\n> Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。\n\n#### 2. INSERT 语句\n##### Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\n\tINSERT ALL WHEN 条件1 THEN INTO table1\n\t\t\t   WHEN 条件2 THEN INTO table2\n\t\t\t   WHEN 条件3 THEN INTO table3\n\t\t\t\t...\n\t\t\t   SELECT ** FROM table4;\n> 当指定**ALL**时，这个语句就会执行无条件的多表插入，可以用**FIRST**替换，此时指定按照**WHEN**子句在语句中的顺序进行判断\t。\n\n#### 3. UPDATE 语句\t\t\n\n##### 该语法由 **UPDATE、SET、WHERE** 组成\t\n\n#### 4. DELETE 语句\n\n##### 由 DELETE、WHERE、FROM 组成\n\n#### 5. MERGE 语句\n\n##### MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\n\n\n","source":"_posts/2019-03-25-oracle-sql-second-version-note.md","raw":"---\ntitle: 精通Oracle SQL（第二版）读书笔记   -  第一章 SQL核心\ndate: 2016-12-05 13:52:54\ntags:\n  - Oracle\ncategories:\n  - Oracle\n---\n\n\nracle SQL（第二版）读书笔记\n## 第一章 SQL核心\n### 数据库接口\n> 1.数据库接口:\n> Oracle数据库的本地接口界面是**OCI**,**OCI** 将由 **Oracle内核**传递而来的查询语句发送到数据库。其他语言对应的接口：*Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动*。\n\n### SQL*Plus\n>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。\n\n\n### 常用命令：\n> * sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。\n\n> * help index： 显示可用的命令\n\n> * help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。\n\n### 在login.sql文件中修改配置\n\n> 在sql* plus启动时默认读取的两个文件，1.**$ORACLE_HOME/sqlplus/admin** 目录下的 **glogin.sql**和**login.sql** 文件。其中，**login.sql**中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。\n\n### 执行命令\n>在sql* plus中执行的是两种命令：**sql语句** 和 **SQL * Plus命令**\n\n>SQL语句用**；** 和 **/** 结束输入\n\n -  1.  可在命令后和另起一行使用；\n -  2.  /只能在下行中被识别。\n>sqlplus缓冲区\n>sqlplus执行 *.sql 文件方式：1.直接输入 *.sql,2.输入@或者START *，可以省略后缀。\n\n### 五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\n#### 1. SELECT 语句\n##### Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\n##### - select语句\n> 处理过程中首先处理的是**From**子句，多个**From**则每个步骤想象成一个临时数据集，每经过一个**FROM**，则进行一步筛选，得最终结果数据集。\n\n##### - From子句\n> 子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。\n\n##### - HAVING子句\n> 将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。\n\n##### - ORDER BY子句\n> Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。\n\n#### 2. INSERT 语句\n##### Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\n\tINSERT ALL WHEN 条件1 THEN INTO table1\n\t\t\t   WHEN 条件2 THEN INTO table2\n\t\t\t   WHEN 条件3 THEN INTO table3\n\t\t\t\t...\n\t\t\t   SELECT ** FROM table4;\n> 当指定**ALL**时，这个语句就会执行无条件的多表插入，可以用**FIRST**替换，此时指定按照**WHEN**子句在语句中的顺序进行判断\t。\n\n#### 3. UPDATE 语句\t\t\n\n##### 该语法由 **UPDATE、SET、WHERE** 组成\t\n\n#### 4. DELETE 语句\n\n##### 由 DELETE、WHERE、FROM 组成\n\n#### 5. MERGE 语句\n\n##### MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\n\n\n","slug":"oracle-sql-second-version-note","published":1,"updated":"2019-03-25T09:21:13.093Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oxe000dt2xufeoz863d","content":"<p>racle SQL（第二版）读书笔记</p>\n<h2 id=\"第一章-SQL核心\"><a href=\"#第一章-SQL核心\" class=\"headerlink\" title=\"第一章 SQL核心\"></a>第一章 SQL核心</h2><h3 id=\"数据库接口\"><a href=\"#数据库接口\" class=\"headerlink\" title=\"数据库接口\"></a>数据库接口</h3><blockquote>\n<p>1.数据库接口:<br>Oracle数据库的本地接口界面是<strong>OCI</strong>,<strong>OCI</strong> 将由 <strong>Oracle内核</strong>传递而来的查询语句发送到数据库。其他语言对应的接口：<em>Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动</em>。</p>\n</blockquote>\n<h3 id=\"SQL-Plus\"><a href=\"#SQL-Plus\" class=\"headerlink\" title=\"SQL*Plus\"></a>SQL*Plus</h3><blockquote>\n<p>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。</p>\n</blockquote>\n<h3 id=\"常用命令：\"><a href=\"#常用命令：\" class=\"headerlink\" title=\"常用命令：\"></a>常用命令：</h3><blockquote>\n<ul>\n<li>sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help index： 显示可用的命令</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。</li>\n</ul>\n</blockquote>\n<h3 id=\"在login-sql文件中修改配置\"><a href=\"#在login-sql文件中修改配置\" class=\"headerlink\" title=\"在login.sql文件中修改配置\"></a>在login.sql文件中修改配置</h3><blockquote>\n<p>在sql* plus启动时默认读取的两个文件，1.<strong>$ORACLE_HOME/sqlplus/admin</strong> 目录下的 <strong>glogin.sql</strong>和<strong>login.sql</strong> 文件。其中，<strong>login.sql</strong>中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。</p>\n</blockquote>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><blockquote>\n<p>在sql<em> plus中执行的是两种命令：<strong>sql语句</strong> 和 **SQL </em> Plus命令**</p>\n</blockquote>\n<blockquote>\n<p>SQL语句用<strong>；</strong> 和 <strong>/</strong> 结束输入</p>\n</blockquote>\n<ul>\n<li><ol>\n<li>可在命令后和另起一行使用；</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>/只能在下行中被识别。<blockquote>\n<p>sqlplus缓冲区<br>sqlplus执行 <em>.sql 文件方式：1.直接输入 </em>.sql,2.输入@或者START *，可以省略后缀。</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\"><a href=\"#五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\" class=\"headerlink\" title=\"五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\"></a>五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)</h3><h4 id=\"1-SELECT-语句\"><a href=\"#1-SELECT-语句\" class=\"headerlink\" title=\"1. SELECT 语句\"></a>1. SELECT 语句</h4><h5 id=\"Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\"><a href=\"#Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\" class=\"headerlink\" title=\"Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\"></a>Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。</h5><h5 id=\"select语句\"><a href=\"#select语句\" class=\"headerlink\" title=\"- select语句\"></a>- select语句</h5><blockquote>\n<p>处理过程中首先处理的是<strong>From</strong>子句，多个<strong>From</strong>则每个步骤想象成一个临时数据集，每经过一个<strong>FROM</strong>，则进行一步筛选，得最终结果数据集。</p>\n</blockquote>\n<h5 id=\"From子句\"><a href=\"#From子句\" class=\"headerlink\" title=\"- From子句\"></a>- From子句</h5><blockquote>\n<p>子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。</p>\n</blockquote>\n<h5 id=\"HAVING子句\"><a href=\"#HAVING子句\" class=\"headerlink\" title=\"- HAVING子句\"></a>- HAVING子句</h5><blockquote>\n<p>将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。</p>\n</blockquote>\n<h5 id=\"ORDER-BY子句\"><a href=\"#ORDER-BY子句\" class=\"headerlink\" title=\"- ORDER BY子句\"></a>- ORDER BY子句</h5><blockquote>\n<p>Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。</p>\n</blockquote>\n<h4 id=\"2-INSERT-语句\"><a href=\"#2-INSERT-语句\" class=\"headerlink\" title=\"2. INSERT 语句\"></a>2. INSERT 语句</h4><h5 id=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"><a href=\"#Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\" class=\"headerlink\" title=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"></a>Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。</h5><pre><code>INSERT ALL WHEN 条件1 THEN INTO table1\n           WHEN 条件2 THEN INTO table2\n           WHEN 条件3 THEN INTO table3\n            ...\n           SELECT ** FROM table4;\n</code></pre><blockquote>\n<p>当指定<strong>ALL</strong>时，这个语句就会执行无条件的多表插入，可以用<strong>FIRST</strong>替换，此时指定按照<strong>WHEN</strong>子句在语句中的顺序进行判断    。</p>\n</blockquote>\n<h4 id=\"3-UPDATE-语句\"><a href=\"#3-UPDATE-语句\" class=\"headerlink\" title=\"3. UPDATE 语句\"></a>3. UPDATE 语句</h4><h5 id=\"该语法由-UPDATE、SET、WHERE-组成\"><a href=\"#该语法由-UPDATE、SET、WHERE-组成\" class=\"headerlink\" title=\"该语法由 UPDATE、SET、WHERE 组成\"></a>该语法由 <strong>UPDATE、SET、WHERE</strong> 组成</h5><h4 id=\"4-DELETE-语句\"><a href=\"#4-DELETE-语句\" class=\"headerlink\" title=\"4. DELETE 语句\"></a>4. DELETE 语句</h4><h5 id=\"由-DELETE、WHERE、FROM-组成\"><a href=\"#由-DELETE、WHERE、FROM-组成\" class=\"headerlink\" title=\"由 DELETE、WHERE、FROM 组成\"></a>由 DELETE、WHERE、FROM 组成</h5><h4 id=\"5-MERGE-语句\"><a href=\"#5-MERGE-语句\" class=\"headerlink\" title=\"5. MERGE 语句\"></a>5. MERGE 语句</h4><h5 id=\"MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\"><a href=\"#MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\" class=\"headerlink\" title=\"MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\"></a>MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。</h5>","site":{"data":{}},"excerpt":"","more":"<p>racle SQL（第二版）读书笔记</p>\n<h2 id=\"第一章-SQL核心\"><a href=\"#第一章-SQL核心\" class=\"headerlink\" title=\"第一章 SQL核心\"></a>第一章 SQL核心</h2><h3 id=\"数据库接口\"><a href=\"#数据库接口\" class=\"headerlink\" title=\"数据库接口\"></a>数据库接口</h3><blockquote>\n<p>1.数据库接口:<br>Oracle数据库的本地接口界面是<strong>OCI</strong>,<strong>OCI</strong> 将由 <strong>Oracle内核</strong>传递而来的查询语句发送到数据库。其他语言对应的接口：<em>Oracle JDBC-OCI、ODD.Net、Oracle 预编译器、Oracle ODBC以及Oracle C++ 调用接口OCCI驱动</em>。</p>\n</blockquote>\n<h3 id=\"SQL-Plus\"><a href=\"#SQL-Plus\" class=\"headerlink\" title=\"SQL*Plus\"></a>SQL*Plus</h3><blockquote>\n<p>配置：$ORACLE_HOME/network/admin/tnsnames.ora 文件中登记想要连接的数据库。</p>\n</blockquote>\n<h3 id=\"常用命令：\"><a href=\"#常用命令：\" class=\"headerlink\" title=\"常用命令：\"></a>常用命令：</h3><blockquote>\n<ul>\n<li>sqlplus /nolog: 启动sqlplus但不显示登录到数据库后的提示。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help index： 显示可用的命令</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>help set： 用来定制工作环境最基本的命令，但退出sqlplus或者关闭时，这些设置命令不会被保存。可在login.sql文件中修改sqlplus环境设置。</li>\n</ul>\n</blockquote>\n<h3 id=\"在login-sql文件中修改配置\"><a href=\"#在login-sql文件中修改配置\" class=\"headerlink\" title=\"在login.sql文件中修改配置\"></a>在login.sql文件中修改配置</h3><blockquote>\n<p>在sql* plus启动时默认读取的两个文件，1.<strong>$ORACLE_HOME/sqlplus/admin</strong> 目录下的 <strong>glogin.sql</strong>和<strong>login.sql</strong> 文件。其中，<strong>login.sql</strong>中所有命令的优先级比glogin.sql高。Oracle log之后，启动sqlplus和在sqlplus中运行connect都会同时读取这两个文件。</p>\n</blockquote>\n<h3 id=\"执行命令\"><a href=\"#执行命令\" class=\"headerlink\" title=\"执行命令\"></a>执行命令</h3><blockquote>\n<p>在sql<em> plus中执行的是两种命令：<strong>sql语句</strong> 和 **SQL </em> Plus命令**</p>\n</blockquote>\n<blockquote>\n<p>SQL语句用<strong>；</strong> 和 <strong>/</strong> 结束输入</p>\n</blockquote>\n<ul>\n<li><ol>\n<li>可在命令后和另起一行使用；</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>/只能在下行中被识别。<blockquote>\n<p>sqlplus缓冲区<br>sqlplus执行 <em>.sql 文件方式：1.直接输入 </em>.sql,2.输入@或者START *，可以省略后缀。</p>\n</blockquote>\n</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\"><a href=\"#五大核心SQL语句-SELECT-INSERT-UPDATE-DELETE-MERGE\" class=\"headerlink\" title=\"五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)\"></a>五大核心SQL语句(SELECT, INSERT, UPDATE, DELETE, MERGE)</h3><h4 id=\"1-SELECT-语句\"><a href=\"#1-SELECT-语句\" class=\"headerlink\" title=\"1. SELECT 语句\"></a>1. SELECT 语句</h4><h5 id=\"Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\"><a href=\"#Oracle基于查询成本的优化器-Cost-Based-Optimizer-CBO-用来产生实际的执行计划。\" class=\"headerlink\" title=\"Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。\"></a>Oracle基于查询成本的优化器(Cost-Based Optimizer,CBO)用来产生实际的执行计划。</h5><h5 id=\"select语句\"><a href=\"#select语句\" class=\"headerlink\" title=\"- select语句\"></a>- select语句</h5><blockquote>\n<p>处理过程中首先处理的是<strong>From</strong>子句，多个<strong>From</strong>则每个步骤想象成一个临时数据集，每经过一个<strong>FROM</strong>，则进行一步筛选，得最终结果数据集。</p>\n</blockquote>\n<h5 id=\"From子句\"><a href=\"#From子句\" class=\"headerlink\" title=\"- From子句\"></a>- From子句</h5><blockquote>\n<p>子句可以包含表、视图、物化视图、分区或者子分区。处理联结时：交叉联结（笛卡尔乘积）、内联结、外联结。</p>\n</blockquote>\n<h5 id=\"HAVING子句\"><a href=\"#HAVING子句\" class=\"headerlink\" title=\"- HAVING子句\"></a>- HAVING子句</h5><blockquote>\n<p>将分组汇总后的查询结果限定为只满足该条件的数据行。GROUP BY 和 HAVING 子句的位置可以互换，但是一般情况下GROUP BY 放在前面。</p>\n</blockquote>\n<h5 id=\"ORDER-BY子句\"><a href=\"#ORDER-BY子句\" class=\"headerlink\" title=\"- ORDER BY子句\"></a>- ORDER BY子句</h5><blockquote>\n<p>Oracle必须在其他所有子句都执行完毕之后按指定的列进行排序结果集。</p>\n</blockquote>\n<h4 id=\"2-INSERT-语句\"><a href=\"#2-INSERT-语句\" class=\"headerlink\" title=\"2. INSERT 语句\"></a>2. INSERT 语句</h4><h5 id=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"><a href=\"#Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\" class=\"headerlink\" title=\"Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。\"></a>Insert语句可以向表、分区或者视图中添加行，可单表或者多表插入。</h5><pre><code>INSERT ALL WHEN 条件1 THEN INTO table1\n           WHEN 条件2 THEN INTO table2\n           WHEN 条件3 THEN INTO table3\n            ...\n           SELECT ** FROM table4;\n</code></pre><blockquote>\n<p>当指定<strong>ALL</strong>时，这个语句就会执行无条件的多表插入，可以用<strong>FIRST</strong>替换，此时指定按照<strong>WHEN</strong>子句在语句中的顺序进行判断    。</p>\n</blockquote>\n<h4 id=\"3-UPDATE-语句\"><a href=\"#3-UPDATE-语句\" class=\"headerlink\" title=\"3. UPDATE 语句\"></a>3. UPDATE 语句</h4><h5 id=\"该语法由-UPDATE、SET、WHERE-组成\"><a href=\"#该语法由-UPDATE、SET、WHERE-组成\" class=\"headerlink\" title=\"该语法由 UPDATE、SET、WHERE 组成\"></a>该语法由 <strong>UPDATE、SET、WHERE</strong> 组成</h5><h4 id=\"4-DELETE-语句\"><a href=\"#4-DELETE-语句\" class=\"headerlink\" title=\"4. DELETE 语句\"></a>4. DELETE 语句</h4><h5 id=\"由-DELETE、WHERE、FROM-组成\"><a href=\"#由-DELETE、WHERE、FROM-组成\" class=\"headerlink\" title=\"由 DELETE、WHERE、FROM 组成\"></a>由 DELETE、WHERE、FROM 组成</h5><h4 id=\"5-MERGE-语句\"><a href=\"#5-MERGE-语句\" class=\"headerlink\" title=\"5. MERGE 语句\"></a>5. MERGE 语句</h4><h5 id=\"MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\"><a href=\"#MERGE-语句可以按条件获取要更新或者插入到表中的数据行，然后从-1-个或者多个源头对表进行更新或插入行。\" class=\"headerlink\" title=\"MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。\"></a>MERGE 语句可以按条件获取要更新或者插入到表中的数据行，然后从 1 个或者多个源头对表进行更新或插入行。</h5>"},{"title":"精通Oracle SQL（第二版）读书笔记  -  第二章 SQL执行","date":"2017-08-17T13:58:59.000Z","_content":"\n# 精通Oracle SQL（第二版）读书笔记\n## 第二章 SQL执行\n### 数据库和数据库文件、实例等概念\n> **数据库** 归属于 数据库文件\n\n> **实  例** 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。\n\n> **PGA** 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。\n\n> **SGA** 包含共享池（库高速缓存）、数据库高速缓存。\n\n### SGA\n###### 共享池\n1. 存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。\n2. Oracle 使用的系统参数，在一块被称为数据字典的区域。\n###### 高速缓存区域\n- 存储所有的数据库对象信息。\n\n###### 管理共享池：\n- 共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。\n\n### 执行SQL语句 \n\n![执行SQL语句](http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n### 绑定变量 \n-  在SQL语句中，有时使用**绑定变量**比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。\n\n>    SQL> varible v_dept number  #定义变量 v_dept 为 number 类型\n\t\n>\t SQL> exec : v_dept = 10\n\n>    SQL> SELECT * FROM employees WHERE departent_id = :v_dept;    \n### 锁存器\n- 锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。\n### 互斥锁\n- 一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：\n\n      **1.** 占内存少，且可快速获取和释放；\n\n      **2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n### SGA缓冲区缓存\n![SGA缓冲区缓存](http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- **块:** Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。\n\n- **缓冲区缓存**\n\n![SGA缓冲区缓存空间管理](http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- 刷新（清空）共享池和缓冲区缓存\n> SQL> alter system flush buffer_cache;\n\n> SQL> alter system flush shared_pool;\n\n- 硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。\n\n### 查询转换\n- 在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。\n- 查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。\n##### 查询块\n- 查询块可以由 Oracle 自动生成系统名称，也可以通过 **QB_NAME** 提示命名。\n- 可以在**V$SQL_PLAN**视图中查询所使用的查询块名称，即之前执行的 SQL 语句。\n##### 视图合并 —— 类型转换\n- 视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。\n- 阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）\n##### 子嵌套解嵌套—— 类型转换\n- 子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。\n##### 联结消除 —— 类型转换\n- Oracle 消除冗余表的两种情况\n  1. 存在主 —— 外键约束\n  2. 外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。\n- 如果一张表没有出现在执行计划中，就是发生了联结消除转换。\n- 限制\n  1. 如果在查询的任何地方引用了联结键，则不支持联结消除；\n  2. 如果主外键约束包含多个列，则不支持联结消除。\n##### 排序消除 —— 类型转换\n- 与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。\n- 优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。\n##### 谓词推进（谓语即所谓的条件）\n- 谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。\n- 如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。\n##### 使用物化视图进行查询重写\n- 查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。\n- 物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。\n\n##### 确定执行计划\n- 执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。\n","source":"_posts/2019-03-25-oracle-sql-seconds-notes-sec-2-sql-exec.md","raw":"---\ntitle: 精通Oracle SQL（第二版）读书笔记  -  第二章 SQL执行\ndate: 2017-08-17 13:58:59\ntags:\n  - Oracle\ncategories:\n  - Oracle\n---\n\n# 精通Oracle SQL（第二版）读书笔记\n## 第二章 SQL执行\n### 数据库和数据库文件、实例等概念\n> **数据库** 归属于 数据库文件\n\n> **实  例** 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。\n\n> **PGA** 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。\n\n> **SGA** 包含共享池（库高速缓存）、数据库高速缓存。\n\n### SGA\n###### 共享池\n1. 存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。\n2. Oracle 使用的系统参数，在一块被称为数据字典的区域。\n###### 高速缓存区域\n- 存储所有的数据库对象信息。\n\n###### 管理共享池：\n- 共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。\n\n### 执行SQL语句 \n\n![执行SQL语句](http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n### 绑定变量 \n-  在SQL语句中，有时使用**绑定变量**比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。\n\n>    SQL> varible v_dept number  #定义变量 v_dept 为 number 类型\n\t\n>\t SQL> exec : v_dept = 10\n\n>    SQL> SELECT * FROM employees WHERE departent_id = :v_dept;    \n### 锁存器\n- 锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。\n### 互斥锁\n- 一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：\n\n      **1.** 占内存少，且可快速获取和释放；\n\n      **2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n### SGA缓冲区缓存\n![SGA缓冲区缓存](http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- **块:** Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。\n\n- **缓冲区缓存**\n\n![SGA缓冲区缓存空间管理](http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n- 刷新（清空）共享池和缓冲区缓存\n> SQL> alter system flush buffer_cache;\n\n> SQL> alter system flush shared_pool;\n\n- 硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。\n\n### 查询转换\n- 在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。\n- 查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。\n##### 查询块\n- 查询块可以由 Oracle 自动生成系统名称，也可以通过 **QB_NAME** 提示命名。\n- 可以在**V$SQL_PLAN**视图中查询所使用的查询块名称，即之前执行的 SQL 语句。\n##### 视图合并 —— 类型转换\n- 视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。\n- 阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）\n##### 子嵌套解嵌套—— 类型转换\n- 子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。\n##### 联结消除 —— 类型转换\n- Oracle 消除冗余表的两种情况\n  1. 存在主 —— 外键约束\n  2. 外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。\n- 如果一张表没有出现在执行计划中，就是发生了联结消除转换。\n- 限制\n  1. 如果在查询的任何地方引用了联结键，则不支持联结消除；\n  2. 如果主外键约束包含多个列，则不支持联结消除。\n##### 排序消除 —— 类型转换\n- 与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。\n- 优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。\n##### 谓词推进（谓语即所谓的条件）\n- 谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。\n- 如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。\n##### 使用物化视图进行查询重写\n- 查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。\n- 物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。\n\n##### 确定执行计划\n- 执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。\n","slug":"oracle-sql-seconds-notes-sec-2-sql-exec","published":1,"updated":"2019-03-25T06:00:05.626Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oxl000ht2xuulfmcgi5","content":"<h1 id=\"精通Oracle-SQL（第二版）读书笔记\"><a href=\"#精通Oracle-SQL（第二版）读书笔记\" class=\"headerlink\" title=\"精通Oracle SQL（第二版）读书笔记\"></a>精通Oracle SQL（第二版）读书笔记</h1><h2 id=\"第二章-SQL执行\"><a href=\"#第二章-SQL执行\" class=\"headerlink\" title=\"第二章 SQL执行\"></a>第二章 SQL执行</h2><h3 id=\"数据库和数据库文件、实例等概念\"><a href=\"#数据库和数据库文件、实例等概念\" class=\"headerlink\" title=\"数据库和数据库文件、实例等概念\"></a>数据库和数据库文件、实例等概念</h3><blockquote>\n<p><strong>数据库</strong> 归属于 数据库文件</p>\n</blockquote>\n<blockquote>\n<p><strong>实  例</strong> 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。</p>\n</blockquote>\n<blockquote>\n<p><strong>PGA</strong> 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。</p>\n</blockquote>\n<blockquote>\n<p><strong>SGA</strong> 包含共享池（库高速缓存）、数据库高速缓存。</p>\n</blockquote>\n<h3 id=\"SGA\"><a href=\"#SGA\" class=\"headerlink\" title=\"SGA\"></a>SGA</h3><h6 id=\"共享池\"><a href=\"#共享池\" class=\"headerlink\" title=\"共享池\"></a>共享池</h6><ol>\n<li>存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。</li>\n<li>Oracle 使用的系统参数，在一块被称为数据字典的区域。<h6 id=\"高速缓存区域\"><a href=\"#高速缓存区域\" class=\"headerlink\" title=\"高速缓存区域\"></a>高速缓存区域</h6></li>\n</ol>\n<ul>\n<li>存储所有的数据库对象信息。</li>\n</ul>\n<h6 id=\"管理共享池：\"><a href=\"#管理共享池：\" class=\"headerlink\" title=\"管理共享池：\"></a>管理共享池：</h6><ul>\n<li>共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。</li>\n</ul>\n<h3 id=\"执行SQL语句\"><a href=\"#执行SQL语句\" class=\"headerlink\" title=\"执行SQL语句\"></a>执行SQL语句</h3><p><img src=\"http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"执行SQL语句\"></p>\n<h3 id=\"绑定变量\"><a href=\"#绑定变量\" class=\"headerlink\" title=\"绑定变量\"></a>绑定变量</h3><ul>\n<li>在SQL语句中，有时使用<strong>绑定变量</strong>比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。</li>\n</ul>\n<blockquote>\n<p>   SQL&gt; varible v_dept number  #定义变量 v_dept 为 number 类型</p>\n</blockquote>\n<blockquote>\n<pre><code>SQL&gt; exec : v_dept = 10\n</code></pre></blockquote>\n<blockquote>\n<p>   SQL&gt; SELECT * FROM employees WHERE departent_id = :v_dept;    </p>\n</blockquote>\n<h3 id=\"锁存器\"><a href=\"#锁存器\" class=\"headerlink\" title=\"锁存器\"></a>锁存器</h3><ul>\n<li>锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。<h3 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h3></li>\n<li><p>一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：</p>\n<pre><code>**1.** 占内存少，且可快速获取和释放；\n\n**2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n</code></pre><h3 id=\"SGA缓冲区缓存\"><a href=\"#SGA缓冲区缓存\" class=\"headerlink\" title=\"SGA缓冲区缓存\"></a>SGA缓冲区缓存</h3><p><img src=\"http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存\"></p>\n</li>\n<li><p><strong>块:</strong> Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。</p>\n</li>\n<li><p><strong>缓冲区缓存</strong></p>\n</li>\n</ul>\n<p><img src=\"http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存空间管理\"></p>\n<ul>\n<li>刷新（清空）共享池和缓冲区缓存<blockquote>\n<p>SQL&gt; alter system flush buffer_cache;</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>SQL&gt; alter system flush shared_pool;</p>\n</blockquote>\n<ul>\n<li>硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。</li>\n</ul>\n<h3 id=\"查询转换\"><a href=\"#查询转换\" class=\"headerlink\" title=\"查询转换\"></a>查询转换</h3><ul>\n<li>在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。</li>\n<li>查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。<h5 id=\"查询块\"><a href=\"#查询块\" class=\"headerlink\" title=\"查询块\"></a>查询块</h5></li>\n<li>查询块可以由 Oracle 自动生成系统名称，也可以通过 <strong>QB_NAME</strong> 提示命名。</li>\n<li>可以在<strong>V$SQL_PLAN</strong>视图中查询所使用的查询块名称，即之前执行的 SQL 语句。<h5 id=\"视图合并-——-类型转换\"><a href=\"#视图合并-——-类型转换\" class=\"headerlink\" title=\"视图合并 —— 类型转换\"></a>视图合并 —— 类型转换</h5></li>\n<li>视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。</li>\n<li>阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）<h5 id=\"子嵌套解嵌套——-类型转换\"><a href=\"#子嵌套解嵌套——-类型转换\" class=\"headerlink\" title=\"子嵌套解嵌套—— 类型转换\"></a>子嵌套解嵌套—— 类型转换</h5></li>\n<li>子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。<h5 id=\"联结消除-——-类型转换\"><a href=\"#联结消除-——-类型转换\" class=\"headerlink\" title=\"联结消除 —— 类型转换\"></a>联结消除 —— 类型转换</h5></li>\n<li>Oracle 消除冗余表的两种情况<ol>\n<li>存在主 —— 外键约束</li>\n<li>外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。</li>\n</ol>\n</li>\n<li>如果一张表没有出现在执行计划中，就是发生了联结消除转换。</li>\n<li>限制<ol>\n<li>如果在查询的任何地方引用了联结键，则不支持联结消除；</li>\n<li>如果主外键约束包含多个列，则不支持联结消除。<h5 id=\"排序消除-——-类型转换\"><a href=\"#排序消除-——-类型转换\" class=\"headerlink\" title=\"排序消除 —— 类型转换\"></a>排序消除 —— 类型转换</h5></li>\n</ol>\n</li>\n<li>与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。</li>\n<li>优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。<h5 id=\"谓词推进（谓语即所谓的条件）\"><a href=\"#谓词推进（谓语即所谓的条件）\" class=\"headerlink\" title=\"谓词推进（谓语即所谓的条件）\"></a>谓词推进（谓语即所谓的条件）</h5></li>\n<li>谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。</li>\n<li>如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。<h5 id=\"使用物化视图进行查询重写\"><a href=\"#使用物化视图进行查询重写\" class=\"headerlink\" title=\"使用物化视图进行查询重写\"></a>使用物化视图进行查询重写</h5></li>\n<li>查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。</li>\n<li>物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。</li>\n</ul>\n<h5 id=\"确定执行计划\"><a href=\"#确定执行计划\" class=\"headerlink\" title=\"确定执行计划\"></a>确定执行计划</h5><ul>\n<li>执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"精通Oracle-SQL（第二版）读书笔记\"><a href=\"#精通Oracle-SQL（第二版）读书笔记\" class=\"headerlink\" title=\"精通Oracle SQL（第二版）读书笔记\"></a>精通Oracle SQL（第二版）读书笔记</h1><h2 id=\"第二章-SQL执行\"><a href=\"#第二章-SQL执行\" class=\"headerlink\" title=\"第二章 SQL执行\"></a>第二章 SQL执行</h2><h3 id=\"数据库和数据库文件、实例等概念\"><a href=\"#数据库和数据库文件、实例等概念\" class=\"headerlink\" title=\"数据库和数据库文件、实例等概念\"></a>数据库和数据库文件、实例等概念</h3><blockquote>\n<p><strong>数据库</strong> 归属于 数据库文件</p>\n</blockquote>\n<blockquote>\n<p><strong>实  例</strong> 归属于内存结构，是由SGA(System Global Area)及一系列后台进程组成的。</p>\n</blockquote>\n<blockquote>\n<p><strong>PGA</strong> 客户端进程是与服务器进程相关联的，每个服务器进程都会被分配一块私有的内存区域，称为程序共享区域或进程共享内存区域（Process Global Area）。</p>\n</blockquote>\n<blockquote>\n<p><strong>SGA</strong> 包含共享池（库高速缓存）、数据库高速缓存。</p>\n</blockquote>\n<h3 id=\"SGA\"><a href=\"#SGA\" class=\"headerlink\" title=\"SGA\"></a>SGA</h3><h6 id=\"共享池\"><a href=\"#共享池\" class=\"headerlink\" title=\"共享池\"></a>共享池</h6><ol>\n<li>存储解析后的SQL语句，不管有多少个用户想执行同样的SQL语句，Oracle都会只解析该语句一次，将其放在共享池中，共享。</li>\n<li>Oracle 使用的系统参数，在一块被称为数据字典的区域。<h6 id=\"高速缓存区域\"><a href=\"#高速缓存区域\" class=\"headerlink\" title=\"高速缓存区域\"></a>高速缓存区域</h6></li>\n</ol>\n<ul>\n<li>存储所有的数据库对象信息。</li>\n</ul>\n<h6 id=\"管理共享池：\"><a href=\"#管理共享池：\" class=\"headerlink\" title=\"管理共享池：\"></a>管理共享池：</h6><ul>\n<li>共享池的内存大小是由限制的，需要通过最近最少使用（LRU）算法进行共享池内存的管理，即保留那些使用频繁以及最近使用的解析语句。</li>\n</ul>\n<h3 id=\"执行SQL语句\"><a href=\"#执行SQL语句\" class=\"headerlink\" title=\"执行SQL语句\"></a>执行SQL语句</h3><p><img src=\"http://img.blog.csdn.net/20170331085505286?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"执行SQL语句\"></p>\n<h3 id=\"绑定变量\"><a href=\"#绑定变量\" class=\"headerlink\" title=\"绑定变量\"></a>绑定变量</h3><ul>\n<li>在SQL语句中，有时使用<strong>绑定变量</strong>比使用常量更节约SQL语句执行时间，因为:在使用了绑定变量时，即使改变了变量的值，Oracle还是可以使用共享池的该SQL语句。</li>\n</ul>\n<blockquote>\n<p>   SQL&gt; varible v_dept number  #定义变量 v_dept 为 number 类型</p>\n</blockquote>\n<blockquote>\n<pre><code>SQL&gt; exec : v_dept = 10\n</code></pre></blockquote>\n<blockquote>\n<p>   SQL&gt; SELECT * FROM employees WHERE departent_id = :v_dept;    </p>\n</blockquote>\n<h3 id=\"锁存器\"><a href=\"#锁存器\" class=\"headerlink\" title=\"锁存器\"></a>锁存器</h3><ul>\n<li>锁存器是为了Oracle读取存在库高速还粗或者其他内存结构中的信息时必须获得的一种锁，其他回话必须等待，锁存器是串行的。<h3 id=\"互斥锁\"><a href=\"#互斥锁\" class=\"headerlink\" title=\"互斥锁\"></a>互斥锁</h3></li>\n<li><p>一个序列化组件，阻止多个线程同时访问一个共享结构，与锁存器相比，互斥锁的优点：</p>\n<pre><code>**1.** 占内存少，且可快速获取和释放；\n\n**2.** 可直接修改游标的互斥锁引用计数，避免为已经打开的游标获取库高速缓存锁。\n</code></pre><h3 id=\"SGA缓冲区缓存\"><a href=\"#SGA缓冲区缓存\" class=\"headerlink\" title=\"SGA缓冲区缓存\"></a>SGA缓冲区缓存</h3><p><img src=\"http://img.blog.csdn.net/20170331085311877?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存\"></p>\n</li>\n<li><p><strong>块:</strong> Oracle进行操作的最小单位。典型的块大小：4KB，8KB，16KB；这取决于操作系统。</p>\n</li>\n<li><p><strong>缓冲区缓存</strong></p>\n</li>\n</ul>\n<p><img src=\"http://img.blog.csdn.net/20170331085413757?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvenNkNDk4NTM3ODA2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast\" alt=\"SGA缓冲区缓存空间管理\"></p>\n<ul>\n<li>刷新（清空）共享池和缓冲区缓存<blockquote>\n<p>SQL&gt; alter system flush buffer_cache;</p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>SQL&gt; alter system flush shared_pool;</p>\n</blockquote>\n<ul>\n<li>硬解析的物理存取和软解析的逻辑读取，我们的目标是开发出能够更多重用共享池和缓冲区缓存中信息的代码。</li>\n</ul>\n<h3 id=\"查询转换\"><a href=\"#查询转换\" class=\"headerlink\" title=\"查询转换\"></a>查询转换</h3><ul>\n<li>在查询通过了语法和权限的检查之后，查询就进入了转换为一系列的查询块的转换阶段（SELECT 关键字定义查询块）。</li>\n<li>查询块嵌套在另一个查询块中或者以某种方式与另一个查询块相连结。查询转换的目的是确定如果改变查询的写法会不会提供更好的查询计划。<h5 id=\"查询块\"><a href=\"#查询块\" class=\"headerlink\" title=\"查询块\"></a>查询块</h5></li>\n<li>查询块可以由 Oracle 自动生成系统名称，也可以通过 <strong>QB_NAME</strong> 提示命名。</li>\n<li>可以在<strong>V$SQL_PLAN</strong>视图中查询所使用的查询块名称，即之前执行的 SQL 语句。<h5 id=\"视图合并-——-类型转换\"><a href=\"#视图合并-——-类型转换\" class=\"headerlink\" title=\"视图合并 —— 类型转换\"></a>视图合并 —— 类型转换</h5></li>\n<li>视图合并是一种能将内嵌或存储式视图展开为能够独立分析或者与查询剩余部分合并成总体执行计划的独立查询块的转换。</li>\n<li>阻止视图合并的情况：查询块中包含分析函数、聚合函数、集合运算（例：UNION 、 INTERSECT 、MINUS）、ORDER BY 子句或使用了ROWNUM。（但可以使用MERGE 提示来强制执行视图合并）<h5 id=\"子嵌套解嵌套——-类型转换\"><a href=\"#子嵌套解嵌套——-类型转换\" class=\"headerlink\" title=\"子嵌套解嵌套—— 类型转换\"></a>子嵌套解嵌套—— 类型转换</h5></li>\n<li>子查询解嵌套与视图合并的相似之处在于子查询也是通过一个单独的查询块来表示的，它们的区别：位置不同，子查询位于WHERE 子句，由转换器执行的解嵌套审查。最典型的转换就是将子查询转换为表联接。<h5 id=\"联结消除-——-类型转换\"><a href=\"#联结消除-——-类型转换\" class=\"headerlink\" title=\"联结消除 —— 类型转换\"></a>联结消除 —— 类型转换</h5></li>\n<li>Oracle 消除冗余表的两种情况<ol>\n<li>存在主 —— 外键约束</li>\n<li>外联接，即使没有任何主 —— 外键约束，如果想消除的表在联结列上具有唯一键约束，并且没有任何列出现在查询列表中，则这张表也是可以消除的。</li>\n</ol>\n</li>\n<li>如果一张表没有出现在执行计划中，就是发生了联结消除转换。</li>\n<li>限制<ol>\n<li>如果在查询的任何地方引用了联结键，则不支持联结消除；</li>\n<li>如果主外键约束包含多个列，则不支持联结消除。<h5 id=\"排序消除-——-类型转换\"><a href=\"#排序消除-——-类型转换\" class=\"headerlink\" title=\"排序消除 —— 类型转换\"></a>排序消除 —— 类型转换</h5></li>\n</ol>\n</li>\n<li>与联结消除类似，排序消除也会移除不必要的运算，在这里不必要的运算就是排序。</li>\n<li>优化器选择使用在 ORDEY BY 子句的列上的索引，因为索引本事就是按照排序后的顺序存储的，此时，会发生类似的类型转换。<h5 id=\"谓词推进（谓语即所谓的条件）\"><a href=\"#谓词推进（谓语即所谓的条件）\" class=\"headerlink\" title=\"谓词推进（谓语即所谓的条件）\"></a>谓词推进（谓语即所谓的条件）</h5></li>\n<li>谓词推进就是将谓词从一个内含查询块中应用到不可合并的查询块中，目的是允许索引的使用或让其他数据集筛选能够在查询中尽早的进行。</li>\n<li>如果可以将谓词推进到不可合并查询块中尽早的执行，再剩下的执行计划中所需要抓取的数据就会更少。<h5 id=\"使用物化视图进行查询重写\"><a href=\"#使用物化视图进行查询重写\" class=\"headerlink\" title=\"使用物化视图进行查询重写\"></a>使用物化视图进行查询重写</h5></li>\n<li>查询重写的前提是某个查询被保存为物化视图。转换器重写该查询以使用预先计算好的物化视图数据而不需要执行当前查询的转换。</li>\n<li>物化视图与普通视图的区别是：查询已经执行，并将查询结果保存在了一张表中。也就是说，所有的确定执行计划、执行查询以及收集所有数据的工作已经完成，当同样的查询再次发起时就不需要再做一遍了。</li>\n</ul>\n<h5 id=\"确定执行计划\"><a href=\"#确定执行计划\" class=\"headerlink\" title=\"确定执行计划\"></a>确定执行计划</h5><ul>\n<li>执行计划定义：就是Oracle访问查询所使用的对象并返回相应结果数据将会采用的一系列的步骤。</li>\n</ul>\n"},{"title":"Centos搭建Docker私有仓库, Registry","date":"2018-09-13T13:47:14.000Z","author":"weshzhu","_content":"\n\n关于docker的安装：\n[CENTOS7二进制安装DOCKER-CE](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/)\n[CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速](http://www.weshzhu.com/2019/03/25/install-docker-yum/)\n\n1. 覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （**对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库**）\n\tcp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\n\n2. 修改openssl.cnf文件\n\tvi /etc/pki/tls/openssl.cnf\n\t在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11\n\t\n3. openssl生成私有证书\n\topenssl req [-subj \"/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11\"] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\topenssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\t\n4. 将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书\n\tcat /certs/registry.crt >> /etc/pki/tls/certs/ca-bundle.crt\n\t\n5. 重启docker\n\tsystemctl restart docker\n\n6. 运行registry\n\tdocker run -d -p 443:443 --name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2\n\t\n7. push镜像到registry\n\tdocker push 192.168.0.11/nginx\n\t常见错误\n\ta. Get https://192.168.0.11/v2/: x509: cannot validate certificate for 192.168.0.11 because it doesn't contain any IP SANs  未操作第4步\n\tb. Get https://<IpAddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步\n\n具体教程可参考[x509: cannot validate certificate because of not containing any IP SANs](http://blog.csdn.net/zsd498537806/article/details/79290732)\n","source":"_posts/2019-03-25-private-registry-docker.md","raw":"---\ntitle: Centos搭建Docker私有仓库, Registry\ndate: 2018-09-13 13:47:14\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\nauthor: weshzhu\n\n---\n\n\n关于docker的安装：\n[CENTOS7二进制安装DOCKER-CE](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/)\n[CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速](http://www.weshzhu.com/2019/03/25/install-docker-yum/)\n\n1. 覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （**对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库**）\n\tcp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\n\n2. 修改openssl.cnf文件\n\tvi /etc/pki/tls/openssl.cnf\n\t在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11\n\t\n3. openssl生成私有证书\n\topenssl req [-subj \"/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11\"] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\topenssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt\n\t\n4. 将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书\n\tcat /certs/registry.crt >> /etc/pki/tls/certs/ca-bundle.crt\n\t\n5. 重启docker\n\tsystemctl restart docker\n\n6. 运行registry\n\tdocker run -d -p 443:443 --name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2\n\t\n7. push镜像到registry\n\tdocker push 192.168.0.11/nginx\n\t常见错误\n\ta. Get https://192.168.0.11/v2/: x509: cannot validate certificate for 192.168.0.11 because it doesn't contain any IP SANs  未操作第4步\n\tb. Get https://<IpAddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步\n\n具体教程可参考[x509: cannot validate certificate because of not containing any IP SANs](http://blog.csdn.net/zsd498537806/article/details/79290732)\n","slug":"private-registry-docker","published":1,"updated":"2019-03-25T05:50:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oxn000jt2xuu3wyj2st","content":"<p>关于docker的安装：<br><a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">CENTOS7二进制安装DOCKER-CE</a><br><a href=\"http://www.weshzhu.com/2019/03/25/install-docker-yum/\" target=\"_blank\" rel=\"noopener\">CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速</a></p>\n<ol>\n<li><p>覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （<strong>对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库</strong>）<br> cp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem</p>\n</li>\n<li><p>修改openssl.cnf文件<br> vi /etc/pki/tls/openssl.cnf<br> 在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11</p>\n</li>\n<li><p>openssl生成私有证书<br> openssl req [-subj “/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11”] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt<br> openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt</p>\n</li>\n<li><p>将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书<br> cat /certs/registry.crt &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt</p>\n</li>\n<li><p>重启docker<br> systemctl restart docker</p>\n</li>\n<li><p>运行registry<br> docker run -d -p 443:443 –name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2</p>\n</li>\n<li><p>push镜像到registry<br> docker push 192.168.0.11/nginx<br> 常见错误<br> a. Get <a href=\"https://192.168.0.11/v2/\" target=\"_blank\" rel=\"noopener\">https://192.168.0.11/v2/</a>: x509: cannot validate certificate for 192.168.0.11 because it doesn’t contain any IP SANs  未操作第4步<br> b. Get https://<ipaddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步</ipaddress></p>\n</li>\n</ol>\n<p>具体教程可参考<a href=\"http://blog.csdn.net/zsd498537806/article/details/79290732\" target=\"_blank\" rel=\"noopener\">x509: cannot validate certificate because of not containing any IP SANs</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>关于docker的安装：<br><a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">CENTOS7二进制安装DOCKER-CE</a><br><a href=\"http://www.weshzhu.com/2019/03/25/install-docker-yum/\" target=\"_blank\" rel=\"noopener\">CENTOS7 安装DOCKER-CE，并且配置 ALIYUN 加速</a></p>\n<ol>\n<li><p>覆盖掉目录/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem （<strong>对于刚拿到的系统，一定要先备份，切记！本教程适用于 循环创建Docker支持https的私有仓库</strong>）<br> cp /home/zsd/tls-ca-bundle.pem /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem</p>\n</li>\n<li><p>修改openssl.cnf文件<br> vi /etc/pki/tls/openssl.cnf<br> 在[v3_ca]下面添加 subjectAltName = IP:192.168.0.11</p>\n</li>\n<li><p>openssl生成私有证书<br> openssl req [-subj “/C=CN/ST=BeiJing/L=Dongcheng/CN=192.168.0.11”] -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt<br> openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout registry.key -out registry.crt</p>\n</li>\n<li><p>将生成证书内容追加到该服务器上的证书存放目录的内置信任的证书<br> cat /certs/registry.crt &gt;&gt; /etc/pki/tls/certs/ca-bundle.crt</p>\n</li>\n<li><p>重启docker<br> systemctl restart docker</p>\n</li>\n<li><p>运行registry<br> docker run -d -p 443:443 –name registry -v /deploy/certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/registry.crt -e REGISTRY_HTTP_TLS_KEY=/certs/registry.key registry:2</p>\n</li>\n<li><p>push镜像到registry<br> docker push 192.168.0.11/nginx<br> 常见错误<br> a. Get <a href=\"https://192.168.0.11/v2/\" target=\"_blank\" rel=\"noopener\">https://192.168.0.11/v2/</a>: x509: cannot validate certificate for 192.168.0.11 because it doesn’t contain any IP SANs  未操作第4步<br> b. Get https://<ipaddress>/v2/: x509: certificate signed by unknown authority  #未操作第6步</ipaddress></p>\n</li>\n</ol>\n<p>具体教程可参考<a href=\"http://blog.csdn.net/zsd498537806/article/details/79290732\" target=\"_blank\" rel=\"noopener\">x509: cannot validate certificate because of not containing any IP SANs</a></p>\n"},{"title":"docker网络驱动之--overlay网络","date":"2019-03-21T20:23:46.000Z","_content":"\n\n\n>`docker overlay`网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将`swarm`集群服务和`containers`容器与`overlay`网络进行连接，使各个服务或者服务与容器之间进行通信。\n\n#### 创建或加入`swarm`服务\n\n在创建和使用`overlay`之前，必须初始化一个[`swarm`](https://docs.docker.com/engine/swarm/)或者加入某个`swarm`:\n\n- 创建一个`swarm`集群服务\n\n  用法：`docker swarm init [OPTIONS]`，针对常用的`[OPTIONS]`介绍见下方表格：\n  \n  参数说明\n\n  |参数|类型|默认值|说明|\n  |-----|-----|-----|-----|\n  |`--advertise-addr`| string ||多块网卡时对应多个IP地址时，需要指定|\n  |`--data-path-addr`|string||用于数据流量传输的IP地址或者网卡名称（例：`eth0`）|\n  |`--listen-addr`|node-addr|0.0.0.0:2377|监听地址|\n\n\n  **示例：创建`swarm`服务**\n \n  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：\n\n   ```\n   node1 : 192.168.0.190  (manager & worker)\n   node2 : 192.168.0.191 (worker)\n   ```\n   \n   ![swarm架构](/images/swarmcluster.png)\n   \n   - 创建`swarm`集群服务\n\n     ```\n     $ docker swarm init --advertise-addr 192.168.0.190\n     Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.\n     To add a worker to this swarm, run the following      command:\n       docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377\n     To add a manager to this swarm, run 'docker swarm      join-tokenmanager' and follow the instructions.\n   \n     ```\n \n     注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n \n     ```\n     docker swarm join --token xxxx <manager-ip>:<port>\n     ```\n     \n     可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n   \n     查看docker网络\n   \n     ```\n     $docker network ls\n     NETWORK ID          NAME                DRIVER                 SCOPE\n     ba18dbad1160        bridge              bridge                 local\n     58886c346808        docker_gwbridge     bridge                 local\n     7966432ad37e        host                host                   local\n     yryhkokko1tk        ingress             overlay                swarm\n     d1ab833f3555        none                null                   local\n     ```\n \n     可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n   \n     - `ingress`\n\n       一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n       使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n     \n       ```\n       $ docker inspect ingress\n       [\n           {\n               \"Name\": \"ingress\",\n               \"Id\": \"yryhkokko1tkpkhx0pf0e1zm3\",\n               \"Created\": \"2019-01-08T17:05:50.511486192+08:00\",\n               \"Scope\": \"swarm\",\n               \"Driver\": \"overlay\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"10.255.0.0/16\",\n                           \"Gateway\": \"10.255.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": true,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"ingress-endpoint\",\n                       \"EndpointID\": \"75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb\",\n                       \"MacAddress\": \"02:42:0a:ff:00:03\",\n                       \"IPv4Address\": \"10.255.0.3/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.driver.overlay.vxlanid_list\": \"4096\"\n               },\n               \"Labels\": {},\n               \"Peers\": [\n                   {\n                       \"Name\": \"5e8427535708\",\n                       \"IP\": \"192.168.0.190\"\n                   },\n                   {\n                       \"Name\": \"42c5607b0c46\",\n                       \"IP\": \"192.168.0.191\"\n                   }\n               ]\n           }\n       ]\n       ```\n\n     - `docker_gwbridge`\n\n       一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n     \n       ```\n       $ docker inspect docker_gwbridge\n       [\n           {\n               \"Name\": \"docker_gwbridge\",\n               \"Id\": \"2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4\",\n               \"Created\": \"2019-01-08T17:05:51.263715613+08:00\",\n               \"Scope\": \"local\",\n               \"Driver\": \"bridge\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"172.18.0.0/16\",\n                           \"Gateway\": \"172.18.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": false,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"gateway_ingress-sbox\",\n                       \"EndpointID\": \"4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af\",\n                       \"MacAddress\": \"02:42:ac:12:00:02\",\n                       \"IPv4Address\": \"172.18.0.2/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.bridge.enable_icc\": \"false\",\n                   \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n                   \"com.docker.network.bridge.name\": \"docker_gwbridge\"\n               },\n               \"Labels\": {}\n           }\n       ]\n       ```\n\n- 增加工作（`worker`）节点\n   \n    将node2(192.168.0.191)加入到该`swarm`：\n\n    ```\n    $ docker swarm join --token \\\n      SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\\n      192.168.0.190:2377\n\n      This node joined a swarm as a worker.\n    ```\n\n    查看node\n\n    ```\n    $ docker node ls\n      ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\n      se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce\n      timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce\n    ```\n   \n     查看**工作节点**的docker网络\n   \n     ```\n     $ docker network ls \n       NETWORK ID          NAME                DRIVER                    SCOPE\n       e39a5d50e807        bridge              bridge                    local\n       2c7254c25f76        docker_gwbridge     bridge                    local\n       a284efd6e1f2        host                host                      local\n       yryhkokko1tk        ingress             overlay                   swarm\n       13bd88a34632        none                null                  local\n     ```\n\n#### `overlay`网络\n \n - 创建`overlay`网络\n\n   在创建`overlay`网络前，需要初始化或者加入`swarm`服务。即使可能后续不会使用`swarm`服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。\n\n   要创建用于swarm服务的覆盖网络，请使用如下命令：\n   \n   ```\n   $ docker network create -d overlay my-overlay\n   ```\n\n   要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的`overlay`网络，必须添加`--attachable`标志：\n\n   ```\n   $ docker network create -d overlay --attachable my-attachable-overlay\n   ```\n\n   在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create --help\n  \n - `overlay`网络流量加密（不支持windows操作系统）\n   \n   在`swarm`服务中的管理流量默认是通过`GCM-AES`加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加`--opt encrypted`属性，Docker会在各个工作节点之间建立`IPSEC`隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。\n\n\n - 自定义默认`ingress`\n\n   Docker 17.05之后的版本，才支持用户修改默认`ingress`网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他`low-level`底层网络设置（如MTU），则此功能非常有用。\n\n   - 创建`ingress`网络\n\n     使用--ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。\n\n     ```\n     $ docker network create \\\n       --driver overlay \\\n       --ingress \\\n       --subnet=10.11.0.0/16 \\\n       --gateway=10.11.0.2 \\\n       --opt com.docker.network.driver.mtu=1200 \\\n       my-ingress\n     ```\n     注意：您可以对`ingress`网络重新命名，但您只能拥有一个`ingress`网络。\n\n   - 删除`ingress`网络\n\n     如果现有服务有发布端口，则需要先删除这些服务，然后才能删除`ingress`网络。\n\n     ```\n     $ docker network rm ingress\n \n       WARNING! Before removing the routing-mesh   network, make sure all the nodes\n       in your swarm run the same docker engine   version. Otherwise, removal may not\n       be effective and functionality of newly created   ingress networks will be\n       impaired.\n       Are you sure you want to continue? [y/N]\n     ```\n\n- 自定义`docker_gwbridge`\n\n  `docker_gwbridge`是一个虚拟网桥，将覆盖网络（包括`ingress`网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。\n\n  ```\n  $ ip addr | grep docker_gwbridge\n    docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP>   mtu 1500 qdisc noqueue state UP \n      inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge\n  ```\n  \n  1. Stop Docker service\n     \n     ```\n     $ systemctl stop docker\n     ```\n  \n  2. 删除`docker_gwbridge`网桥\n  \n     ```\n     $ ip link set  docker_gwbridge down\n     $ ip link del dev docker_gwbridge\n     ```\n  3. 启动Docker，但是不要初始化`swarm`或者加入任何`swarm`  服务网络\n  \n     ```\n     $ systemctl start docker\n     ```\n  4. 使用`docker network create`命令，使用自定义设置手动  创建或重新创建`docker_gwbridge`桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (https://docs.docker.com/engine/reference/commandline/  network_create/#bridge-driver-options)。\n     \n     ```\n     $ docker network create  \\\n       --subnet 10.11.0.0/16 \\\n       --opt    com.docker.network.bridge.name=docker_gwbridge \\\n       --opt com.docker.network.bridge.enable_icc=false  \\\n       --opt    com.docker.network.bridge.enable_ip_masquerade=true \\\n       docker_gwbridge\n     ```\n  5. 初始化或加入`swarm`服务集群。由`docker_gwbridge`网桥已经存在，初始化时Docker不再创建它。\n\n#### 创建用于`swarm`服务的`overlay`网络\n\n- 在`overlay`网络上，暴露服务端口号\n\n  连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用`docker service create`或`docker service update`上的`-p`或`--publish`参数发布端口。\n\n  ```\n  $ docker service create \n  ```\n\n  默认情况下，发布端口的`swarm`服务使用路由网格(`routing mesh`)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。\n\n- `swram`服务区（`swarm service`）绕过网格路由（`routing mesh`）\n\n  默认情况下，发布端口的`swarm`服务使用路由网格来实现负载均衡。 当您连接到任意一个`swarm`节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的`worker`节点上。实际上，Docker充当您的群服务的负载均衡器（`load balancer`）。 默认情况下，使用`routing mesh`的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过`--mode global`）也使用路由网格。使用`routing mesh`时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将`--endpoint-mode`标志设置为`dnsrr`。若使用`dnsrr`，需要在服务前运行自己的负载均衡器（常用的：有`nginx`、`HAproxy`）。通过DNS查询返回运行在`swarm`集群服务的所有节点的IP地址列表。\n  \n  >`routing mesh` 将外部请求路由到不同主机的容器，从而实现了外部网络对 `service` 的访问。\n\n- 分离控制流量和数据流量\n  \n  默认情况下，与`swarm`管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入`swarm`时，每个节点（管理节点和工作节点）需要分别指定`--advertise-addr`和`--data-path-addr`。\n\n#### 创建用于独立容器使用的`overlay`网络\n\n- 将独立容器连接到覆盖网络\n\n  在创建`ingress`网络时，若未指定`--attachable`（比如初始化`swarm`服务，或加入`swarm`时默认创建的`ingress`）意味着只有`swarm`服务可以使用它，独立运行的容器无法使用`ingress`。您可以将独立容器连接到使用--attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。\n\n\n- 容器发现\n\n  在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用`DNS lookup` 查找`tasks.<service-name>`\n\n\n","source":"_posts/2019-03-21-docker-network-overlay.md","raw":"---\ntitle: docker网络驱动之--overlay网络\ndate: 2019-03-21 20:23:46\ntags: \n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\n\n\n>`docker overlay`网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将`swarm`集群服务和`containers`容器与`overlay`网络进行连接，使各个服务或者服务与容器之间进行通信。\n\n#### 创建或加入`swarm`服务\n\n在创建和使用`overlay`之前，必须初始化一个[`swarm`](https://docs.docker.com/engine/swarm/)或者加入某个`swarm`:\n\n- 创建一个`swarm`集群服务\n\n  用法：`docker swarm init [OPTIONS]`，针对常用的`[OPTIONS]`介绍见下方表格：\n  \n  参数说明\n\n  |参数|类型|默认值|说明|\n  |-----|-----|-----|-----|\n  |`--advertise-addr`| string ||多块网卡时对应多个IP地址时，需要指定|\n  |`--data-path-addr`|string||用于数据流量传输的IP地址或者网卡名称（例：`eth0`）|\n  |`--listen-addr`|node-addr|0.0.0.0:2377|监听地址|\n\n\n  **示例：创建`swarm`服务**\n \n  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：\n\n   ```\n   node1 : 192.168.0.190  (manager & worker)\n   node2 : 192.168.0.191 (worker)\n   ```\n   \n   ![swarm架构](/images/swarmcluster.png)\n   \n   - 创建`swarm`集群服务\n\n     ```\n     $ docker swarm init --advertise-addr 192.168.0.190\n     Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.\n     To add a worker to this swarm, run the following      command:\n       docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377\n     To add a manager to this swarm, run 'docker swarm      join-tokenmanager' and follow the instructions.\n   \n     ```\n \n     注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n \n     ```\n     docker swarm join --token xxxx <manager-ip>:<port>\n     ```\n     \n     可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n   \n     查看docker网络\n   \n     ```\n     $docker network ls\n     NETWORK ID          NAME                DRIVER                 SCOPE\n     ba18dbad1160        bridge              bridge                 local\n     58886c346808        docker_gwbridge     bridge                 local\n     7966432ad37e        host                host                   local\n     yryhkokko1tk        ingress             overlay                swarm\n     d1ab833f3555        none                null                   local\n     ```\n \n     可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n   \n     - `ingress`\n\n       一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n       使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n     \n       ```\n       $ docker inspect ingress\n       [\n           {\n               \"Name\": \"ingress\",\n               \"Id\": \"yryhkokko1tkpkhx0pf0e1zm3\",\n               \"Created\": \"2019-01-08T17:05:50.511486192+08:00\",\n               \"Scope\": \"swarm\",\n               \"Driver\": \"overlay\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"10.255.0.0/16\",\n                           \"Gateway\": \"10.255.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": true,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"ingress-endpoint\",\n                       \"EndpointID\": \"75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb\",\n                       \"MacAddress\": \"02:42:0a:ff:00:03\",\n                       \"IPv4Address\": \"10.255.0.3/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.driver.overlay.vxlanid_list\": \"4096\"\n               },\n               \"Labels\": {},\n               \"Peers\": [\n                   {\n                       \"Name\": \"5e8427535708\",\n                       \"IP\": \"192.168.0.190\"\n                   },\n                   {\n                       \"Name\": \"42c5607b0c46\",\n                       \"IP\": \"192.168.0.191\"\n                   }\n               ]\n           }\n       ]\n       ```\n\n     - `docker_gwbridge`\n\n       一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n     \n       ```\n       $ docker inspect docker_gwbridge\n       [\n           {\n               \"Name\": \"docker_gwbridge\",\n               \"Id\": \"2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4\",\n               \"Created\": \"2019-01-08T17:05:51.263715613+08:00\",\n               \"Scope\": \"local\",\n               \"Driver\": \"bridge\",\n               \"EnableIPv6\": false,\n               \"IPAM\": {\n                   \"Driver\": \"default\",\n                   \"Options\": null,\n                   \"Config\": [\n                       {\n                           \"Subnet\": \"172.18.0.0/16\",\n                           \"Gateway\": \"172.18.0.1\"\n                       }\n                   ]\n               },\n               \"Internal\": false,\n               \"Attachable\": false,\n               \"Ingress\": false,\n               \"ConfigFrom\": {\n                   \"Network\": \"\"\n               },\n               \"ConfigOnly\": false,\n               \"Containers\": {\n                   \"ingress-sbox\": {\n                       \"Name\": \"gateway_ingress-sbox\",\n                       \"EndpointID\": \"4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af\",\n                       \"MacAddress\": \"02:42:ac:12:00:02\",\n                       \"IPv4Address\": \"172.18.0.2/16\",\n                       \"IPv6Address\": \"\"\n                   }\n               },\n               \"Options\": {\n                   \"com.docker.network.bridge.enable_icc\": \"false\",\n                   \"com.docker.network.bridge.enable_ip_masquerade\": \"true\",\n                   \"com.docker.network.bridge.name\": \"docker_gwbridge\"\n               },\n               \"Labels\": {}\n           }\n       ]\n       ```\n\n- 增加工作（`worker`）节点\n   \n    将node2(192.168.0.191)加入到该`swarm`：\n\n    ```\n    $ docker swarm join --token \\\n      SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\\n      192.168.0.190:2377\n\n      This node joined a swarm as a worker.\n    ```\n\n    查看node\n\n    ```\n    $ docker node ls\n      ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\n      se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce\n      timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce\n    ```\n   \n     查看**工作节点**的docker网络\n   \n     ```\n     $ docker network ls \n       NETWORK ID          NAME                DRIVER                    SCOPE\n       e39a5d50e807        bridge              bridge                    local\n       2c7254c25f76        docker_gwbridge     bridge                    local\n       a284efd6e1f2        host                host                      local\n       yryhkokko1tk        ingress             overlay                   swarm\n       13bd88a34632        none                null                  local\n     ```\n\n#### `overlay`网络\n \n - 创建`overlay`网络\n\n   在创建`overlay`网络前，需要初始化或者加入`swarm`服务。即使可能后续不会使用`swarm`服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。\n\n   要创建用于swarm服务的覆盖网络，请使用如下命令：\n   \n   ```\n   $ docker network create -d overlay my-overlay\n   ```\n\n   要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的`overlay`网络，必须添加`--attachable`标志：\n\n   ```\n   $ docker network create -d overlay --attachable my-attachable-overlay\n   ```\n\n   在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create --help\n  \n - `overlay`网络流量加密（不支持windows操作系统）\n   \n   在`swarm`服务中的管理流量默认是通过`GCM-AES`加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加`--opt encrypted`属性，Docker会在各个工作节点之间建立`IPSEC`隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。\n\n\n - 自定义默认`ingress`\n\n   Docker 17.05之后的版本，才支持用户修改默认`ingress`网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他`low-level`底层网络设置（如MTU），则此功能非常有用。\n\n   - 创建`ingress`网络\n\n     使用--ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。\n\n     ```\n     $ docker network create \\\n       --driver overlay \\\n       --ingress \\\n       --subnet=10.11.0.0/16 \\\n       --gateway=10.11.0.2 \\\n       --opt com.docker.network.driver.mtu=1200 \\\n       my-ingress\n     ```\n     注意：您可以对`ingress`网络重新命名，但您只能拥有一个`ingress`网络。\n\n   - 删除`ingress`网络\n\n     如果现有服务有发布端口，则需要先删除这些服务，然后才能删除`ingress`网络。\n\n     ```\n     $ docker network rm ingress\n \n       WARNING! Before removing the routing-mesh   network, make sure all the nodes\n       in your swarm run the same docker engine   version. Otherwise, removal may not\n       be effective and functionality of newly created   ingress networks will be\n       impaired.\n       Are you sure you want to continue? [y/N]\n     ```\n\n- 自定义`docker_gwbridge`\n\n  `docker_gwbridge`是一个虚拟网桥，将覆盖网络（包括`ingress`网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。\n\n  ```\n  $ ip addr | grep docker_gwbridge\n    docker_gwbridge: <BROADCAST,MULTICAST,UP,LOWER_UP>   mtu 1500 qdisc noqueue state UP \n      inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge\n  ```\n  \n  1. Stop Docker service\n     \n     ```\n     $ systemctl stop docker\n     ```\n  \n  2. 删除`docker_gwbridge`网桥\n  \n     ```\n     $ ip link set  docker_gwbridge down\n     $ ip link del dev docker_gwbridge\n     ```\n  3. 启动Docker，但是不要初始化`swarm`或者加入任何`swarm`  服务网络\n  \n     ```\n     $ systemctl start docker\n     ```\n  4. 使用`docker network create`命令，使用自定义设置手动  创建或重新创建`docker_gwbridge`桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (https://docs.docker.com/engine/reference/commandline/  network_create/#bridge-driver-options)。\n     \n     ```\n     $ docker network create  \\\n       --subnet 10.11.0.0/16 \\\n       --opt    com.docker.network.bridge.name=docker_gwbridge \\\n       --opt com.docker.network.bridge.enable_icc=false  \\\n       --opt    com.docker.network.bridge.enable_ip_masquerade=true \\\n       docker_gwbridge\n     ```\n  5. 初始化或加入`swarm`服务集群。由`docker_gwbridge`网桥已经存在，初始化时Docker不再创建它。\n\n#### 创建用于`swarm`服务的`overlay`网络\n\n- 在`overlay`网络上，暴露服务端口号\n\n  连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用`docker service create`或`docker service update`上的`-p`或`--publish`参数发布端口。\n\n  ```\n  $ docker service create \n  ```\n\n  默认情况下，发布端口的`swarm`服务使用路由网格(`routing mesh`)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。\n\n- `swram`服务区（`swarm service`）绕过网格路由（`routing mesh`）\n\n  默认情况下，发布端口的`swarm`服务使用路由网格来实现负载均衡。 当您连接到任意一个`swarm`节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的`worker`节点上。实际上，Docker充当您的群服务的负载均衡器（`load balancer`）。 默认情况下，使用`routing mesh`的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过`--mode global`）也使用路由网格。使用`routing mesh`时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将`--endpoint-mode`标志设置为`dnsrr`。若使用`dnsrr`，需要在服务前运行自己的负载均衡器（常用的：有`nginx`、`HAproxy`）。通过DNS查询返回运行在`swarm`集群服务的所有节点的IP地址列表。\n  \n  >`routing mesh` 将外部请求路由到不同主机的容器，从而实现了外部网络对 `service` 的访问。\n\n- 分离控制流量和数据流量\n  \n  默认情况下，与`swarm`管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入`swarm`时，每个节点（管理节点和工作节点）需要分别指定`--advertise-addr`和`--data-path-addr`。\n\n#### 创建用于独立容器使用的`overlay`网络\n\n- 将独立容器连接到覆盖网络\n\n  在创建`ingress`网络时，若未指定`--attachable`（比如初始化`swarm`服务，或加入`swarm`时默认创建的`ingress`）意味着只有`swarm`服务可以使用它，独立运行的容器无法使用`ingress`。您可以将独立容器连接到使用--attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。\n\n\n- 容器发现\n\n  在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用`DNS lookup` 查找`tasks.<service-name>`\n\n\n","slug":"docker-network-overlay","published":1,"updated":"2019-03-21T12:25:46.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oz1001jt2xuk2f5jmn9","content":"<blockquote>\n<p><code>docker overlay</code>网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将<code>swarm</code>集群服务和<code>containers</code>容器与<code>overlay</code>网络进行连接，使各个服务或者服务与容器之间进行通信。</p>\n</blockquote>\n<h4 id=\"创建或加入swarm服务\"><a href=\"#创建或加入swarm服务\" class=\"headerlink\" title=\"创建或加入swarm服务\"></a>创建或加入<code>swarm</code>服务</h4><p>在创建和使用<code>overlay</code>之前，必须初始化一个<a href=\"https://docs.docker.com/engine/swarm/\" target=\"_blank\" rel=\"noopener\"><code>swarm</code></a>或者加入某个<code>swarm</code>:</p>\n<ul>\n<li><p>创建一个<code>swarm</code>集群服务</p>\n<p>用法：<code>docker swarm init [OPTIONS]</code>，针对常用的<code>[OPTIONS]</code>介绍见下方表格：</p>\n<p>参数说明</p>\n<p>|参数|类型|默认值|说明|<br>|—–|—–|—–|—–|<br>|<code>--advertise-addr</code>| string ||多块网卡时对应多个IP地址时，需要指定|<br>|<code>--data-path-addr</code>|string||用于数据流量传输的IP地址或者网卡名称（例：<code>eth0</code>）|<br>|<code>--listen-addr</code>|node-addr|0.0.0.0:2377|监听地址|</p>\n</li>\n</ul>\n<p>  <strong>示例：创建<code>swarm</code>服务</strong></p>\n<p>  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：</p>\n   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1 : 192.168.0.190  (manager &amp; worker)</span><br><span class=\"line\">node2 : 192.168.0.191 (worker)</span><br></pre></td></tr></table></figure>\n<p>   <img src=\"/images/swarmcluster.png\" alt=\"swarm架构\"></p>\n<ul>\n<li><p>创建<code>swarm</code>集群服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm init --advertise-addr 192.168.0.190</span><br><span class=\"line\">Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.</span><br><span class=\"line\">To add a worker to this swarm, run the following      command:</span><br><span class=\"line\">  docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377</span><br><span class=\"line\">To add a manager to this swarm, run &apos;docker swarm      join-tokenmanager&apos; and follow the instructions.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker swarm join --token xxxx &lt;manager-ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>\n\n\n可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n\n查看docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER                 SCOPE</span><br><span class=\"line\">ba18dbad1160        bridge              bridge                 local</span><br><span class=\"line\">58886c346808        docker_gwbridge     bridge                 local</span><br><span class=\"line\">7966432ad37e        host                host                   local</span><br><span class=\"line\">yryhkokko1tk        ingress             overlay                swarm</span><br><span class=\"line\">d1ab833f3555        none                null                   local</span><br></pre></td></tr></table></figure>\n\n\n可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n\n- `ingress`\n\n  一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n  使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect ingress</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;ingress&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;yryhkokko1tkpkhx0pf0e1zm3&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:50.511486192+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;swarm&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;overlay&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;10.255.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;10.255.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: true,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;ingress-endpoint&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:0a:ff:00:03&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;10.255.0.3/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4096&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Peers&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;5e8427535708&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.190&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;42c5607b0c46&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.191&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n- `docker_gwbridge`\n\n  一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect docker_gwbridge</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;docker_gwbridge&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:51.263715613+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: false,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;gateway_ingress-sbox&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;false&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.name&quot;: &quot;docker_gwbridge&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n</code></pre><ul>\n<li><p>增加工作（<code>worker</code>）节点</p>\n<p>  将node2(192.168.0.191)加入到该<code>swarm</code>：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm join --token \\</span><br><span class=\"line\">  SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\</span><br><span class=\"line\">  192.168.0.190:2377</span><br><span class=\"line\"></span><br><span class=\"line\">  This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>\n<p>  查看node</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker node ls</span><br><span class=\"line\">  ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class=\"line\">  se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce</span><br><span class=\"line\">  timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>查看**工作节点**的docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls </span><br><span class=\"line\">  NETWORK ID          NAME                DRIVER                    SCOPE</span><br><span class=\"line\">  e39a5d50e807        bridge              bridge                    local</span><br><span class=\"line\">  2c7254c25f76        docker_gwbridge     bridge                    local</span><br><span class=\"line\">  a284efd6e1f2        host                host                      local</span><br><span class=\"line\">  yryhkokko1tk        ingress             overlay                   swarm</span><br><span class=\"line\">  13bd88a34632        none                null                  local</span><br></pre></td></tr></table></figure>\n</code></pre><h4 id=\"overlay网络\"><a href=\"#overlay网络\" class=\"headerlink\" title=\"overlay网络\"></a><code>overlay</code>网络</h4><ul>\n<li><p>创建<code>overlay</code>网络</p>\n<p>在创建<code>overlay</code>网络前，需要初始化或者加入<code>swarm</code>服务。即使可能后续不会使用<code>swarm</code>服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。</p>\n<p>要创建用于swarm服务的覆盖网络，请使用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay my-overlay</span><br></pre></td></tr></table></figure>\n<p>要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的<code>overlay</code>网络，必须添加<code>--attachable</code>标志：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay --attachable my-attachable-overlay</span><br></pre></td></tr></table></figure>\n<p>在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create –help</p>\n</li>\n<li><p><code>overlay</code>网络流量加密（不支持windows操作系统）</p>\n<p>在<code>swarm</code>服务中的管理流量默认是通过<code>GCM-AES</code>加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加<code>--opt encrypted</code>属性，Docker会在各个工作节点之间建立<code>IPSEC</code>隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。</p>\n</li>\n</ul>\n<ul>\n<li><p>自定义默认<code>ingress</code></p>\n<p>Docker 17.05之后的版本，才支持用户修改默认<code>ingress</code>网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他<code>low-level</code>底层网络设置（如MTU），则此功能非常有用。</p>\n<ul>\n<li><p>创建<code>ingress</code>网络</p>\n<p>使用–ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\">  --driver overlay \\</span><br><span class=\"line\">  --ingress \\</span><br><span class=\"line\">  --subnet=10.11.0.0/16 \\</span><br><span class=\"line\">  --gateway=10.11.0.2 \\</span><br><span class=\"line\">  --opt com.docker.network.driver.mtu=1200 \\</span><br><span class=\"line\">  my-ingress</span><br></pre></td></tr></table></figure>\n<p>注意：您可以对<code>ingress</code>网络重新命名，但您只能拥有一个<code>ingress</code>网络。</p>\n</li>\n<li><p>删除<code>ingress</code>网络</p>\n<p>如果现有服务有发布端口，则需要先删除这些服务，然后才能删除<code>ingress</code>网络。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm ingress</span><br><span class=\"line\"> </span><br><span class=\"line\">  WARNING! Before removing the routing-mesh   network, make sure all the nodes</span><br><span class=\"line\">  in your swarm run the same docker engine   version. Otherwise, removal may not</span><br><span class=\"line\">  be effective and functionality of newly created   ingress networks will be</span><br><span class=\"line\">  impaired.</span><br><span class=\"line\">  Are you sure you want to continue? [y/N]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>自定义<code>docker_gwbridge</code></p>\n<p><code>docker_gwbridge</code>是一个虚拟网桥，将覆盖网络（包括<code>ingress</code>网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr | grep docker_gwbridge</span><br><span class=\"line\">  docker_gwbridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;   mtu 1500 qdisc noqueue state UP </span><br><span class=\"line\">    inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li><p>Stop Docker service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop docker</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>删除<code>docker_gwbridge</code>网桥</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link set  docker_gwbridge down</span><br><span class=\"line\">$ ip link del dev docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动Docker，但是不要初始化<code>swarm</code>或者加入任何<code>swarm</code>  服务网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl start docker</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用<code>docker network create</code>命令，使用自定义设置手动  创建或重新创建<code>docker_gwbridge</code>桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (<a href=\"https://docs.docker.com/engine/reference/commandline/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/</a>  network_create/#bridge-driver-options)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create  \\</span><br><span class=\"line\">  --subnet 10.11.0.0/16 \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.name=docker_gwbridge \\</span><br><span class=\"line\">  --opt com.docker.network.bridge.enable_icc=false  \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.enable_ip_masquerade=true \\</span><br><span class=\"line\">  docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>初始化或加入<code>swarm</code>服务集群。由<code>docker_gwbridge</code>网桥已经存在，初始化时Docker不再创建它。</p>\n</li>\n</ol>\n<h4 id=\"创建用于swarm服务的overlay网络\"><a href=\"#创建用于swarm服务的overlay网络\" class=\"headerlink\" title=\"创建用于swarm服务的overlay网络\"></a>创建用于<code>swarm</code>服务的<code>overlay</code>网络</h4><ul>\n<li><p>在<code>overlay</code>网络上，暴露服务端口号</p>\n<p>连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用<code>docker service create</code>或<code>docker service update</code>上的<code>-p</code>或<code>--publish</code>参数发布端口。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker service create</span><br></pre></td></tr></table></figure>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格(<code>routing mesh</code>)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。</p>\n</li>\n<li><p><code>swram</code>服务区（<code>swarm service</code>）绕过网格路由（<code>routing mesh</code>）</p>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格来实现负载均衡。 当您连接到任意一个<code>swarm</code>节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的<code>worker</code>节点上。实际上，Docker充当您的群服务的负载均衡器（<code>load balancer</code>）。 默认情况下，使用<code>routing mesh</code>的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过<code>--mode global</code>）也使用路由网格。使用<code>routing mesh</code>时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将<code>--endpoint-mode</code>标志设置为<code>dnsrr</code>。若使用<code>dnsrr</code>，需要在服务前运行自己的负载均衡器（常用的：有<code>nginx</code>、<code>HAproxy</code>）。通过DNS查询返回运行在<code>swarm</code>集群服务的所有节点的IP地址列表。</p>\n<blockquote>\n<p><code>routing mesh</code> 将外部请求路由到不同主机的容器，从而实现了外部网络对 <code>service</code> 的访问。</p>\n</blockquote>\n</li>\n<li><p>分离控制流量和数据流量</p>\n<p>默认情况下，与<code>swarm</code>管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入<code>swarm</code>时，每个节点（管理节点和工作节点）需要分别指定<code>--advertise-addr</code>和<code>--data-path-addr</code>。</p>\n</li>\n</ul>\n<h4 id=\"创建用于独立容器使用的overlay网络\"><a href=\"#创建用于独立容器使用的overlay网络\" class=\"headerlink\" title=\"创建用于独立容器使用的overlay网络\"></a>创建用于独立容器使用的<code>overlay</code>网络</h4><ul>\n<li><p>将独立容器连接到覆盖网络</p>\n<p>在创建<code>ingress</code>网络时，若未指定<code>--attachable</code>（比如初始化<code>swarm</code>服务，或加入<code>swarm</code>时默认创建的<code>ingress</code>）意味着只有<code>swarm</code>服务可以使用它，独立运行的容器无法使用<code>ingress</code>。您可以将独立容器连接到使用–attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。</p>\n</li>\n</ul>\n<ul>\n<li><p>容器发现</p>\n<p>在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用<code>DNS lookup</code> 查找<code>tasks.&lt;service-name&gt;</code></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p><code>docker overlay</code>网络用于创建多个docker主机之间的分布式网络。该网络位于（覆盖）特定于主机的网络之上，可以将<code>swarm</code>集群服务和<code>containers</code>容器与<code>overlay</code>网络进行连接，使各个服务或者服务与容器之间进行通信。</p>\n</blockquote>\n<h4 id=\"创建或加入swarm服务\"><a href=\"#创建或加入swarm服务\" class=\"headerlink\" title=\"创建或加入swarm服务\"></a>创建或加入<code>swarm</code>服务</h4><p>在创建和使用<code>overlay</code>之前，必须初始化一个<a href=\"https://docs.docker.com/engine/swarm/\" target=\"_blank\" rel=\"noopener\"><code>swarm</code></a>或者加入某个<code>swarm</code>:</p>\n<ul>\n<li><p>创建一个<code>swarm</code>集群服务</p>\n<p>用法：<code>docker swarm init [OPTIONS]</code>，针对常用的<code>[OPTIONS]</code>介绍见下方表格：</p>\n<p>参数说明</p>\n<p>|参数|类型|默认值|说明|<br>|—–|—–|—–|—–|<br>|<code>--advertise-addr</code>| string ||多块网卡时对应多个IP地址时，需要指定|<br>|<code>--data-path-addr</code>|string||用于数据流量传输的IP地址或者网卡名称（例：<code>eth0</code>）|<br>|<code>--listen-addr</code>|node-addr|0.0.0.0:2377|监听地址|</p>\n</li>\n</ul>\n<p>  <strong>示例：创建<code>swarm</code>服务</strong></p>\n<p>  我们用两个节点进行演示，一个node既是管理节点，工作节点；一个node仅是工作节点：</p>\n   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node1 : 192.168.0.190  (manager &amp; worker)</span><br><span class=\"line\">node2 : 192.168.0.191 (worker)</span><br></pre></td></tr></table></figure>\n<p>   <img src=\"/images/swarmcluster.png\" alt=\"swarm架构\"></p>\n<ul>\n<li><p>创建<code>swarm</code>集群服务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm init --advertise-addr 192.168.0.190</span><br><span class=\"line\">Swarm initialized: current node      (se5tsje7l9oibpsx54bbe7nuf) is now amanager.</span><br><span class=\"line\">To add a worker to this swarm, run the following      command:</span><br><span class=\"line\">  docker swarm join      --tokenSWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951kns  t fq  n7ok98hizonw9s-e5p7e5yjfit5tx6l1kp3e6d9      192.168.0.190:2377</span><br><span class=\"line\">To add a manager to this swarm, run &apos;docker swarm      join-tokenmanager&apos; and follow the instructions.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>注意到执行初始化`swarm`语句时，会打印出其他node节点加 入该`swarm`的方式：\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker swarm join --token xxxx &lt;manager-ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>\n\n\n可以将其保存到文档，以便于后续`swarm`Node的[join]   (https://docs.docker.   com/engine/reference/commandline/swarm_join/)。\n\n查看docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER                 SCOPE</span><br><span class=\"line\">ba18dbad1160        bridge              bridge                 local</span><br><span class=\"line\">58886c346808        docker_gwbridge     bridge                 local</span><br><span class=\"line\">7966432ad37e        host                host                   local</span><br><span class=\"line\">yryhkokko1tk        ingress             overlay                swarm</span><br><span class=\"line\">d1ab833f3555        none                null                   local</span><br></pre></td></tr></table></figure>\n\n\n可以看到在docker网络中，新增了`ingress`和 `docker_gwbridge`网络。\n\n- `ingress`\n\n  一个名为ingress的覆盖网络，用于处理与`swarm`服务相关   的控制和数据流量。创建`swarm`服务时，如果不将其连接   到用户定义的覆盖网络，则默认情况下会连接到该   `ingress`网络\n\n  使用 `docker network inspect ingress`查看现有的   `ingress`网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect ingress</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;ingress&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;yryhkokko1tkpkhx0pf0e1zm3&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:50.511486192+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;swarm&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;overlay&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;10.255.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;10.255.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: true,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;ingress-endpoint&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;75df50d1f8228ff64d65a6801bc2a93e31de3f72adaec01e147abd266d3d64eb&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:0a:ff:00:03&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;10.255.0.3/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.driver.overlay.vxlanid_list&quot;: &quot;4096&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;,</span><br><span class=\"line\">        &quot;Peers&quot;: [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;5e8427535708&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.190&quot;</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;42c5607b0c46&quot;,</span><br><span class=\"line\">                &quot;IP&quot;: &quot;192.168.0.191&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n- `docker_gwbridge`\n\n  一个名为`docker_gwbridge`的桥接网络，它用于各个  `swarm`中，各个node节点进行通信的桥接网络。\n\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker inspect docker_gwbridge</span><br><span class=\"line\">[</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        &quot;Name&quot;: &quot;docker_gwbridge&quot;,</span><br><span class=\"line\">        &quot;Id&quot;: &quot;2c7254c25f765b28833668e060246a813d69b8936a5db1a8cd2bc7237dfc7df4&quot;,</span><br><span class=\"line\">        &quot;Created&quot;: &quot;2019-01-08T17:05:51.263715613+08:00&quot;,</span><br><span class=\"line\">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class=\"line\">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class=\"line\">        &quot;EnableIPv6&quot;: false,</span><br><span class=\"line\">        &quot;IPAM&quot;: &#123;</span><br><span class=\"line\">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class=\"line\">            &quot;Options&quot;: null,</span><br><span class=\"line\">            &quot;Config&quot;: [</span><br><span class=\"line\">                &#123;</span><br><span class=\"line\">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class=\"line\">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">            ]</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Internal&quot;: false,</span><br><span class=\"line\">        &quot;Attachable&quot;: false,</span><br><span class=\"line\">        &quot;Ingress&quot;: false,</span><br><span class=\"line\">        &quot;ConfigFrom&quot;: &#123;</span><br><span class=\"line\">            &quot;Network&quot;: &quot;&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;ConfigOnly&quot;: false,</span><br><span class=\"line\">        &quot;Containers&quot;: &#123;</span><br><span class=\"line\">            &quot;ingress-sbox&quot;: &#123;</span><br><span class=\"line\">                &quot;Name&quot;: &quot;gateway_ingress-sbox&quot;,</span><br><span class=\"line\">                &quot;EndpointID&quot;: &quot;4f6821a4096104af4f04aea5caab7a5a3419a2b6469b31ea7a52f4c92b9023af&quot;,</span><br><span class=\"line\">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</span><br><span class=\"line\">                &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</span><br><span class=\"line\">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Options&quot;: &#123;</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;false&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class=\"line\">            &quot;com.docker.network.bridge.name&quot;: &quot;docker_gwbridge&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;Labels&quot;: &#123;&#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n</code></pre><ul>\n<li><p>增加工作（<code>worker</code>）节点</p>\n<p>  将node2(192.168.0.191)加入到该<code>swarm</code>：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker swarm join --token \\</span><br><span class=\"line\">  SWMTKN-1-45ffvnn83wrl0aprynpcs0cogtg951knstfqn7ok98hizonw9s-e5p7e50yjfit5tx6l1kp3e6d9  \\</span><br><span class=\"line\">  192.168.0.190:2377</span><br><span class=\"line\"></span><br><span class=\"line\">  This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure>\n<p>  查看node</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker node ls</span><br><span class=\"line\">  ID                            HOSTNAME             STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class=\"line\">  se5tsje7l9oibpsx54bbe7nuf *   host1                 Ready               Active              Leader              18.03.1-ce</span><br><span class=\"line\">  timpbicei0sxbsuv9rq1625eh     host2                 Ready               Active                                  18.03.1-ce</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<pre><code>查看**工作节点**的docker网络\n\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls </span><br><span class=\"line\">  NETWORK ID          NAME                DRIVER                    SCOPE</span><br><span class=\"line\">  e39a5d50e807        bridge              bridge                    local</span><br><span class=\"line\">  2c7254c25f76        docker_gwbridge     bridge                    local</span><br><span class=\"line\">  a284efd6e1f2        host                host                      local</span><br><span class=\"line\">  yryhkokko1tk        ingress             overlay                   swarm</span><br><span class=\"line\">  13bd88a34632        none                null                  local</span><br></pre></td></tr></table></figure>\n</code></pre><h4 id=\"overlay网络\"><a href=\"#overlay网络\" class=\"headerlink\" title=\"overlay网络\"></a><code>overlay</code>网络</h4><ul>\n<li><p>创建<code>overlay</code>网络</p>\n<p>在创建<code>overlay</code>网络前，需要初始化或者加入<code>swarm</code>服务。即使可能后续不会使用<code>swarm</code>服务，也需要执行此操作。之后，您可以创建其他用户定义的覆盖网络。</p>\n<p>要创建用于swarm服务的覆盖网络，请使用如下命令：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay my-overlay</span><br></pre></td></tr></table></figure>\n<p>要创建可由群集服务或独立容器用于与在其他Docker守护进程主机上运行的其他独立容器通信的<code>overlay</code>网络，必须添加<code>--attachable</code>标志：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create -d overlay --attachable my-attachable-overlay</span><br></pre></td></tr></table></figure>\n<p>在创建可以指定IP地址范围，子网，网关和其他选项。有关详细信息，请参阅docker network create –help</p>\n</li>\n<li><p><code>overlay</code>网络流量加密（不支持windows操作系统）</p>\n<p>在<code>swarm</code>服务中的管理流量默认是通过<code>GCM-AES</code>加密算法进行加密。如果尝试对容器间的流量进行加密，在创建覆盖网络时添加<code>--opt encrypted</code>属性，Docker会在各个工作节点之间建立<code>IPSEC</code>隧道。但是通常加密解密操作需要消耗一定的性能，若将网络加密应用于生产环境，一定对该性能损耗进行评估。</p>\n</li>\n</ul>\n<ul>\n<li><p>自定义默认<code>ingress</code></p>\n<p>Docker 17.05之后的版本，才支持用户修改默认<code>ingress</code>网络。如果自动选择的子网与网络上已存在的子网冲突，或者您需要自定义其他<code>low-level</code>底层网络设置（如MTU），则此功能非常有用。</p>\n<ul>\n<li><p>创建<code>ingress</code>网络</p>\n<p>使用–ingress标志创建新的覆盖网络，以及要设置的自定义  选项。此示例将MTU设置为1200，将子网设置为10.11.0.0/16，并将网关设置为10.11.0.2。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\">  --driver overlay \\</span><br><span class=\"line\">  --ingress \\</span><br><span class=\"line\">  --subnet=10.11.0.0/16 \\</span><br><span class=\"line\">  --gateway=10.11.0.2 \\</span><br><span class=\"line\">  --opt com.docker.network.driver.mtu=1200 \\</span><br><span class=\"line\">  my-ingress</span><br></pre></td></tr></table></figure>\n<p>注意：您可以对<code>ingress</code>网络重新命名，但您只能拥有一个<code>ingress</code>网络。</p>\n</li>\n<li><p>删除<code>ingress</code>网络</p>\n<p>如果现有服务有发布端口，则需要先删除这些服务，然后才能删除<code>ingress</code>网络。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm ingress</span><br><span class=\"line\"> </span><br><span class=\"line\">  WARNING! Before removing the routing-mesh   network, make sure all the nodes</span><br><span class=\"line\">  in your swarm run the same docker engine   version. Otherwise, removal may not</span><br><span class=\"line\">  be effective and functionality of newly created   ingress networks will be</span><br><span class=\"line\">  impaired.</span><br><span class=\"line\">  Are you sure you want to continue? [y/N]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>自定义<code>docker_gwbridge</code></p>\n<p><code>docker_gwbridge</code>是一个虚拟网桥，将覆盖网络（包括<code>ingress</code>网络）连接到单个Docker守护程序的物理网络，它存在于Docker主机的内核中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr | grep docker_gwbridge</span><br><span class=\"line\">  docker_gwbridge: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt;   mtu 1500 qdisc noqueue state UP </span><br><span class=\"line\">    inet 172.18.0.1/16 brd 172.18.255.255 scope   global docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<ol>\n<li><p>Stop Docker service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl stop docker</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>删除<code>docker_gwbridge</code>网桥</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip link set  docker_gwbridge down</span><br><span class=\"line\">$ ip link del dev docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>启动Docker，但是不要初始化<code>swarm</code>或者加入任何<code>swarm</code>  服务网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl start docker</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用<code>docker network create</code>命令，使用自定义设置手动  创建或重新创建<code>docker_gwbridge</code>桥。此示例使用子网  10.11.0.0/16。有关可自定义选项的完整列表，请参阅[Bridge  驱动程序选项]  (<a href=\"https://docs.docker.com/engine/reference/commandline/\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/</a>  network_create/#bridge-driver-options)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create  \\</span><br><span class=\"line\">  --subnet 10.11.0.0/16 \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.name=docker_gwbridge \\</span><br><span class=\"line\">  --opt com.docker.network.bridge.enable_icc=false  \\</span><br><span class=\"line\">  --opt    com.docker.network.bridge.enable_ip_masquerade=true \\</span><br><span class=\"line\">  docker_gwbridge</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>初始化或加入<code>swarm</code>服务集群。由<code>docker_gwbridge</code>网桥已经存在，初始化时Docker不再创建它。</p>\n</li>\n</ol>\n<h4 id=\"创建用于swarm服务的overlay网络\"><a href=\"#创建用于swarm服务的overlay网络\" class=\"headerlink\" title=\"创建用于swarm服务的overlay网络\"></a>创建用于<code>swarm</code>服务的<code>overlay</code>网络</h4><ul>\n<li><p>在<code>overlay</code>网络上，暴露服务端口号</p>\n<p>连接到同一覆盖网络的群集服务有效地将所有端口彼此暴露。对于可在服务外部访问的端口，必须使用<code>docker service create</code>或<code>docker service update</code>上的<code>-p</code>或<code>--publish</code>参数发布端口。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker service create</span><br></pre></td></tr></table></figure>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格(<code>routing mesh</code>)来实现。如果连接到当您连接到任何swarm节点上的已发布端口（无论它是否正在运行给定服务）时，您将被透明地重定向到正在运行该服务的worker。</p>\n</li>\n<li><p><code>swram</code>服务区（<code>swarm service</code>）绕过网格路由（<code>routing mesh</code>）</p>\n<p>默认情况下，发布端口的<code>swarm</code>服务使用路由网格来实现负载均衡。 当您连接到任意一个<code>swarm</code>节点（工作节点和管理节点）上的已发布端口（无论该节点上是否运行了要访问的服务）时，您将被透明地路由到正在运行该服务的<code>worker</code>节点上。实际上，Docker充当您的群服务的负载均衡器（<code>load balancer</code>）。 默认情况下，使用<code>routing mesh</code>的服务以虚拟IP（VIP）模式运行。 即使在每个节点上运行的服务（通过<code>--mode global</code>）也使用路由网格。使用<code>routing mesh</code>时，无法保证哪个Docker节点响应客户端请求。要绕过路由网格，可以使用DNS循环（DNSRR）模式启动服务，方法是将<code>--endpoint-mode</code>标志设置为<code>dnsrr</code>。若使用<code>dnsrr</code>，需要在服务前运行自己的负载均衡器（常用的：有<code>nginx</code>、<code>HAproxy</code>）。通过DNS查询返回运行在<code>swarm</code>集群服务的所有节点的IP地址列表。</p>\n<blockquote>\n<p><code>routing mesh</code> 将外部请求路由到不同主机的容器，从而实现了外部网络对 <code>service</code> 的访问。</p>\n</blockquote>\n</li>\n<li><p>分离控制流量和数据流量</p>\n<p>默认情况下，与<code>swarm</code>管理相关的控制流量以及应用程序的数据流量都在同一网络上运行，尽管群集控制流量已加密。您可以将Docker配置为使用单独的网络接口来处理两种不同类型的流量。初始化或加入<code>swarm</code>时，每个节点（管理节点和工作节点）需要分别指定<code>--advertise-addr</code>和<code>--data-path-addr</code>。</p>\n</li>\n</ul>\n<h4 id=\"创建用于独立容器使用的overlay网络\"><a href=\"#创建用于独立容器使用的overlay网络\" class=\"headerlink\" title=\"创建用于独立容器使用的overlay网络\"></a>创建用于独立容器使用的<code>overlay</code>网络</h4><ul>\n<li><p>将独立容器连接到覆盖网络</p>\n<p>在创建<code>ingress</code>网络时，若未指定<code>--attachable</code>（比如初始化<code>swarm</code>服务，或加入<code>swarm</code>时默认创建的<code>ingress</code>）意味着只有<code>swarm</code>服务可以使用它，独立运行的容器无法使用<code>ingress</code>。您可以将独立容器连接到使用–attachable标志创建的用户定义的覆盖网络。这使得在不同Docker守护程序上运行的独立容器能够进行通信，而无需在各个Docker守护程序主机上设置路由。</p>\n</li>\n</ul>\n<ul>\n<li><p>容器发现</p>\n<p>在大多数情况下，您应该连接到服务名称，该名称是负载平衡的，并由支持该服务的所有容器（“tasks”）处理。要获取支持该服务的所有任务的列表，使用<code>DNS lookup</code> 查找<code>tasks.&lt;service-name&gt;</code></p>\n</li>\n</ul>\n"},{"title":"docker存储原理——介绍","date":"2019-03-21T08:46:02.000Z","_content":"\nDocker数据存储\n---\n\n>在Docker中，有两种方式对数据进行存储：`docker volume`(存储卷) 和 `docker storage driver`（存储驱动），本文主要介绍`docker storage driver`存储驱动。\n\n准备工作：\n\nOS: centos 7.4 (kernel version > 3.10.514 )\n\nDocker: docker-ce 18.03.1 ( [docker-ce安装教程](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/))\n\n\n#### Docker 数据存储\n\n在了解`Docker storage driver`之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和`docker volume`存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。\n\n   ![](/images/container-layers.jpg)\n\n如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：`/var/lib/docker/<storage-driver>/`）。以该镜像为基础，通过`docker run`启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。\n\n - 镜像层\n   Docker镜像是由一系列的层（`layer`）构成，镜像的每个`layer`对应这个Dockerfile中的每条指令\n   \n   ```\n   FROM ubuntu:15.04\n   COPY . /app\n   RUN mkdir -p /app/conf/\n   CMD python /app/app.py\n   ```\n\n   通过`docker build -t `命令构建镜像：\n  \n   ```\n   $ docker build -t my-ubuntu:test -f Dockerfile .\n     \n     Sending build context to Docker daemon  3.584kB\n     Step 1/4 : FROM ubuntu:15.04\n     ---> d1b55fd07600\n     Step 2/4 : COPY . /app\n     ---> 6e3fe23e82f3\n     Step 3/4 : RUN mkdir -p /app/conf/\n     ---> Running in 3a9b550d957b\n     Removing intermediate container 3a9b550d957b\n     ---> 038a1543c273\n     Step 4/4 : CMD python /app/app.py\n     ---> Running in 9b56a922b87f\n     Removing intermediate container 9b56a922b87f\n     ---> 58866642a2af\n     Successfully built 58866642a2af\n     Successfully tagged my-ubuntu:test\n   ```\n   查看镜像是否存在：\n\n   ```\n   $ docker images\n     REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n     my-ubuntu           test                58866642a2af        5 minutes ago       131MB\n     ubuntu              15.04               d1b55fd07600        2 years ago         131MB\n   ```\n\n   查看镜像构建详情：\n\n   ```\n   $ docker history 58866642a2af\n     \n     IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n   58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [\"/bin/sh\" \"-c\" \"pyth…   0B                  \n   038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  \n   6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                \n   d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [\"/bin/bash\"]             0B                  \n   <missing>           2 years ago         /bin/sh -c sed -i    's/^#\\s*\\(deb.*universe\\)$…   1.88kB              \n   <missing>           2 years ago         /bin/sh -c echo    '#!/bin/sh' > /usr/sbin/poli…   701B                \n   <missing>           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB\n   ```\n\n   我们看到`58866642a2af` `038a1543c273` `6e3fe23e82f3` 是刚刚创建的层，对应着Dockerfile文件中的每条指令。`d1b55fd07600`是基础镜像的层，而`missing`则是以往他人在其他主机上构建的层，可以忽视。\n   \n   当您使用`docker pull`从`registry`（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是`/var/lib/docker`。您可以在此示例中看到这些镜像层被拉出：\n\n   ```\n   $ docker pull ubuntu:15.04\n     15.04: Pulling from library/ubuntu\n     9502adfba7f1: Pull complete \n     4332ffb06e4b: Pull complete \n     2f937cc07b5f: Pull complete \n     a3ed95caeb02: Pull complete \n     Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f\n     Status: Downloaded newer image for ubuntu:15.04\n   ```\n\n   下拉的镜像层存储在`/var/lib/docker/<storage-driver>/`目录中，本例使用的存储驱动是`overlay2`，Docker version > 1.10的版本，每层的目录名称与图层ID不对应。\n\n   ```\n   $ ls -l /var/lib/docker/overlay2/\n     drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9\n     drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c\n     drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b\n     drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226\n     drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172\n   ```\n\n - 容器层\n   \n   容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），`low-level`的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。\n   若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用`docker volume`存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。\n\n  ![](/images/sharing-layers.jpg)\n\n   当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径`/var/lib/docker/containers`\n\n   ```\n   $ ls -l /var/lib/docker/containers\n   drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28\n   drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569\n   drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a\n   drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea\n   drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509   \n   ```\n\n#### 写时复制（CoW）策略\n\n写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的`low-level`层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。\n\n对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：\n\n1. 在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。\n2. `copy_up`对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。\n3. 对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。\n\n\n\n\n\n\n\n","source":"_posts/2019-03-21-docker-storage.md","raw":"---\ntitle: docker存储原理——介绍\ndate: 2019-03-21 08:46:02\ntags:\n  - docker\n  - storage\ncategories:\n  - 运维\n  - docker\n---\n\nDocker数据存储\n---\n\n>在Docker中，有两种方式对数据进行存储：`docker volume`(存储卷) 和 `docker storage driver`（存储驱动），本文主要介绍`docker storage driver`存储驱动。\n\n准备工作：\n\nOS: centos 7.4 (kernel version > 3.10.514 )\n\nDocker: docker-ce 18.03.1 ( [docker-ce安装教程](http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/))\n\n\n#### Docker 数据存储\n\n在了解`Docker storage driver`之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和`docker volume`存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。\n\n   ![](/images/container-layers.jpg)\n\n如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：`/var/lib/docker/<storage-driver>/`）。以该镜像为基础，通过`docker run`启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。\n\n - 镜像层\n   Docker镜像是由一系列的层（`layer`）构成，镜像的每个`layer`对应这个Dockerfile中的每条指令\n   \n   ```\n   FROM ubuntu:15.04\n   COPY . /app\n   RUN mkdir -p /app/conf/\n   CMD python /app/app.py\n   ```\n\n   通过`docker build -t `命令构建镜像：\n  \n   ```\n   $ docker build -t my-ubuntu:test -f Dockerfile .\n     \n     Sending build context to Docker daemon  3.584kB\n     Step 1/4 : FROM ubuntu:15.04\n     ---> d1b55fd07600\n     Step 2/4 : COPY . /app\n     ---> 6e3fe23e82f3\n     Step 3/4 : RUN mkdir -p /app/conf/\n     ---> Running in 3a9b550d957b\n     Removing intermediate container 3a9b550d957b\n     ---> 038a1543c273\n     Step 4/4 : CMD python /app/app.py\n     ---> Running in 9b56a922b87f\n     Removing intermediate container 9b56a922b87f\n     ---> 58866642a2af\n     Successfully built 58866642a2af\n     Successfully tagged my-ubuntu:test\n   ```\n   查看镜像是否存在：\n\n   ```\n   $ docker images\n     REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n     my-ubuntu           test                58866642a2af        5 minutes ago       131MB\n     ubuntu              15.04               d1b55fd07600        2 years ago         131MB\n   ```\n\n   查看镜像构建详情：\n\n   ```\n   $ docker history 58866642a2af\n     \n     IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n   58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [\"/bin/sh\" \"-c\" \"pyth…   0B                  \n   038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  \n   6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                \n   d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [\"/bin/bash\"]             0B                  \n   <missing>           2 years ago         /bin/sh -c sed -i    's/^#\\s*\\(deb.*universe\\)$…   1.88kB              \n   <missing>           2 years ago         /bin/sh -c echo    '#!/bin/sh' > /usr/sbin/poli…   701B                \n   <missing>           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB\n   ```\n\n   我们看到`58866642a2af` `038a1543c273` `6e3fe23e82f3` 是刚刚创建的层，对应着Dockerfile文件中的每条指令。`d1b55fd07600`是基础镜像的层，而`missing`则是以往他人在其他主机上构建的层，可以忽视。\n   \n   当您使用`docker pull`从`registry`（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是`/var/lib/docker`。您可以在此示例中看到这些镜像层被拉出：\n\n   ```\n   $ docker pull ubuntu:15.04\n     15.04: Pulling from library/ubuntu\n     9502adfba7f1: Pull complete \n     4332ffb06e4b: Pull complete \n     2f937cc07b5f: Pull complete \n     a3ed95caeb02: Pull complete \n     Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f\n     Status: Downloaded newer image for ubuntu:15.04\n   ```\n\n   下拉的镜像层存储在`/var/lib/docker/<storage-driver>/`目录中，本例使用的存储驱动是`overlay2`，Docker version > 1.10的版本，每层的目录名称与图层ID不对应。\n\n   ```\n   $ ls -l /var/lib/docker/overlay2/\n     drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9\n     drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c\n     drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b\n     drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226\n     drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172\n   ```\n\n - 容器层\n   \n   容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），`low-level`的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。\n   若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用`docker volume`存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。\n\n  ![](/images/sharing-layers.jpg)\n\n   当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径`/var/lib/docker/containers`\n\n   ```\n   $ ls -l /var/lib/docker/containers\n   drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28\n   drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569\n   drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a\n   drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea\n   drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509   \n   ```\n\n#### 写时复制（CoW）策略\n\n写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的`low-level`层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。\n\n对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：\n\n1. 在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。\n2. `copy_up`对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。\n3. 对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。\n\n\n\n\n\n\n\n","slug":"docker-storage","published":1,"updated":"2019-03-21T12:19:28.918Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oz2001kt2xuxglvu2zw","content":"<h2 id=\"Docker数据存储\"><a href=\"#Docker数据存储\" class=\"headerlink\" title=\"Docker数据存储\"></a>Docker数据存储</h2><blockquote>\n<p>在Docker中，有两种方式对数据进行存储：<code>docker volume</code>(存储卷) 和 <code>docker storage driver</code>（存储驱动），本文主要介绍<code>docker storage driver</code>存储驱动。</p>\n</blockquote>\n<p>准备工作：</p>\n<p>OS: centos 7.4 (kernel version &gt; 3.10.514 )</p>\n<p>Docker: docker-ce 18.03.1 ( <a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">docker-ce安装教程</a>)</p>\n<h4 id=\"Docker-数据存储\"><a href=\"#Docker-数据存储\" class=\"headerlink\" title=\"Docker 数据存储\"></a>Docker 数据存储</h4><p>在了解<code>Docker storage driver</code>之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和<code>docker volume</code>存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。</p>\n<p>   <img src=\"/images/container-layers.jpg\" alt></p>\n<p>如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：<code>/var/lib/docker/&lt;storage-driver&gt;/</code>）。以该镜像为基础，通过<code>docker run</code>启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。</p>\n<ul>\n<li><p>镜像层<br>Docker镜像是由一系列的层（<code>layer</code>）构成，镜像的每个<code>layer</code>对应这个Dockerfile中的每条指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:15.04</span><br><span class=\"line\">COPY . /app</span><br><span class=\"line\">RUN mkdir -p /app/conf/</span><br><span class=\"line\">CMD python /app/app.py</span><br></pre></td></tr></table></figure>\n<p>通过<code>docker build -t</code>命令构建镜像：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker build -t my-ubuntu:test -f Dockerfile .</span><br><span class=\"line\">  </span><br><span class=\"line\">  Sending build context to Docker daemon  3.584kB</span><br><span class=\"line\">  Step 1/4 : FROM ubuntu:15.04</span><br><span class=\"line\">  ---&gt; d1b55fd07600</span><br><span class=\"line\">  Step 2/4 : COPY . /app</span><br><span class=\"line\">  ---&gt; 6e3fe23e82f3</span><br><span class=\"line\">  Step 3/4 : RUN mkdir -p /app/conf/</span><br><span class=\"line\">  ---&gt; Running in 3a9b550d957b</span><br><span class=\"line\">  Removing intermediate container 3a9b550d957b</span><br><span class=\"line\">  ---&gt; 038a1543c273</span><br><span class=\"line\">  Step 4/4 : CMD python /app/app.py</span><br><span class=\"line\">  ---&gt; Running in 9b56a922b87f</span><br><span class=\"line\">  Removing intermediate container 9b56a922b87f</span><br><span class=\"line\">  ---&gt; 58866642a2af</span><br><span class=\"line\">  Successfully built 58866642a2af</span><br><span class=\"line\">  Successfully tagged my-ubuntu:test</span><br></pre></td></tr></table></figure>\n<p>查看镜像是否存在：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker images</span><br><span class=\"line\">  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">  my-ubuntu           test                58866642a2af        5 minutes ago       131MB</span><br><span class=\"line\">  ubuntu              15.04               d1b55fd07600        2 years ago         131MB</span><br></pre></td></tr></table></figure>\n<p>查看镜像构建详情：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker history 58866642a2af</span><br><span class=\"line\">  </span><br><span class=\"line\">  IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class=\"line\">58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;pyth…   0B                  </span><br><span class=\"line\">038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  </span><br><span class=\"line\">6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                </span><br><span class=\"line\">d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [&quot;/bin/bash&quot;]             0B                  </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i    &apos;s/^#\\s*\\(deb.*universe\\)$…   1.88kB              </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c echo    &apos;#!/bin/sh&apos; &gt; /usr/sbin/poli…   701B                </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB</span><br></pre></td></tr></table></figure>\n<p>我们看到<code>58866642a2af</code> <code>038a1543c273</code> <code>6e3fe23e82f3</code> 是刚刚创建的层，对应着Dockerfile文件中的每条指令。<code>d1b55fd07600</code>是基础镜像的层，而<code>missing</code>则是以往他人在其他主机上构建的层，可以忽视。</p>\n<p>当您使用<code>docker pull</code>从<code>registry</code>（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是<code>/var/lib/docker</code>。您可以在此示例中看到这些镜像层被拉出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull ubuntu:15.04</span><br><span class=\"line\">  15.04: Pulling from library/ubuntu</span><br><span class=\"line\">  9502adfba7f1: Pull complete </span><br><span class=\"line\">  4332ffb06e4b: Pull complete </span><br><span class=\"line\">  2f937cc07b5f: Pull complete </span><br><span class=\"line\">  a3ed95caeb02: Pull complete </span><br><span class=\"line\">  Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f</span><br><span class=\"line\">  Status: Downloaded newer image for ubuntu:15.04</span><br></pre></td></tr></table></figure>\n<p>下拉的镜像层存储在<code>/var/lib/docker/&lt;storage-driver&gt;/</code>目录中，本例使用的存储驱动是<code>overlay2</code>，Docker version &gt; 1.10的版本，每层的目录名称与图层ID不对应。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/overlay2/</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>容器层</p>\n<p>容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），<code>low-level</code>的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。<br>若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用<code>docker volume</code>存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。</p>\n<p><img src=\"/images/sharing-layers.jpg\" alt></p>\n<p>当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径<code>/var/lib/docker/containers</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/containers</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569</span><br><span class=\"line\">drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"写时复制（CoW）策略\"><a href=\"#写时复制（CoW）策略\" class=\"headerlink\" title=\"写时复制（CoW）策略\"></a>写时复制（CoW）策略</h4><p>写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的<code>low-level</code>层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。</p>\n<p>对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：</p>\n<ol>\n<li>在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。</li>\n<li><code>copy_up</code>对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。</li>\n<li>对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Docker数据存储\"><a href=\"#Docker数据存储\" class=\"headerlink\" title=\"Docker数据存储\"></a>Docker数据存储</h2><blockquote>\n<p>在Docker中，有两种方式对数据进行存储：<code>docker volume</code>(存储卷) 和 <code>docker storage driver</code>（存储驱动），本文主要介绍<code>docker storage driver</code>存储驱动。</p>\n</blockquote>\n<p>准备工作：</p>\n<p>OS: centos 7.4 (kernel version &gt; 3.10.514 )</p>\n<p>Docker: docker-ce 18.03.1 ( <a href=\"http://www.weshzhu.com/2019/01/03/binary-install-docker-ce-on-centos7/\" target=\"_blank\" rel=\"noopener\">docker-ce安装教程</a>)</p>\n<h4 id=\"Docker-数据存储\"><a href=\"#Docker-数据存储\" class=\"headerlink\" title=\"Docker 数据存储\"></a>Docker 数据存储</h4><p>在了解<code>Docker storage driver</code>之前，我们先了解一下Docker如何存储容器数据和镜像数据。在Docker中数据分为镜像数据和容器数据，容器数据又包含容器可写层和<code>docker volume</code>存储。镜像数据是一种静态数据，存储了提供容器运行的程序、配置文件等。容器数据可以理解为动态 + 静态的数据（阅读本文后，可能有比较直观的理解），供容器运行使用。</p>\n<p>   <img src=\"/images/container-layers.jpg\" alt></p>\n<p>如上图所示，容器层（high-level）是非常小的层，允许程序对该层读写操作；镜像层(low-level)包含了大部分的数据，并且是只读的。在镜像未启动时均是以镜像层存储在host主机上（存储路径：<code>/var/lib/docker/&lt;storage-driver&gt;/</code>）。以该镜像为基础，通过<code>docker run</code>启动一个或多个容器后，针对每个启动的容器会增加一层——可读写层（容器层）。</p>\n<ul>\n<li><p>镜像层<br>Docker镜像是由一系列的层（<code>layer</code>）构成，镜像的每个<code>layer</code>对应这个Dockerfile中的每条指令</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:15.04</span><br><span class=\"line\">COPY . /app</span><br><span class=\"line\">RUN mkdir -p /app/conf/</span><br><span class=\"line\">CMD python /app/app.py</span><br></pre></td></tr></table></figure>\n<p>通过<code>docker build -t</code>命令构建镜像：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker build -t my-ubuntu:test -f Dockerfile .</span><br><span class=\"line\">  </span><br><span class=\"line\">  Sending build context to Docker daemon  3.584kB</span><br><span class=\"line\">  Step 1/4 : FROM ubuntu:15.04</span><br><span class=\"line\">  ---&gt; d1b55fd07600</span><br><span class=\"line\">  Step 2/4 : COPY . /app</span><br><span class=\"line\">  ---&gt; 6e3fe23e82f3</span><br><span class=\"line\">  Step 3/4 : RUN mkdir -p /app/conf/</span><br><span class=\"line\">  ---&gt; Running in 3a9b550d957b</span><br><span class=\"line\">  Removing intermediate container 3a9b550d957b</span><br><span class=\"line\">  ---&gt; 038a1543c273</span><br><span class=\"line\">  Step 4/4 : CMD python /app/app.py</span><br><span class=\"line\">  ---&gt; Running in 9b56a922b87f</span><br><span class=\"line\">  Removing intermediate container 9b56a922b87f</span><br><span class=\"line\">  ---&gt; 58866642a2af</span><br><span class=\"line\">  Successfully built 58866642a2af</span><br><span class=\"line\">  Successfully tagged my-ubuntu:test</span><br></pre></td></tr></table></figure>\n<p>查看镜像是否存在：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker images</span><br><span class=\"line\">  REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class=\"line\">  my-ubuntu           test                58866642a2af        5 minutes ago       131MB</span><br><span class=\"line\">  ubuntu              15.04               d1b55fd07600        2 years ago         131MB</span><br></pre></td></tr></table></figure>\n<p>查看镜像构建详情：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker history 58866642a2af</span><br><span class=\"line\">  </span><br><span class=\"line\">  IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT</span><br><span class=\"line\">58866642a2af        49 seconds ago      /bin/sh -c #(nop)     CMD [&quot;/bin/sh&quot; &quot;-c&quot; &quot;pyth…   0B                  </span><br><span class=\"line\">038a1543c273        51 seconds ago      /bin/sh -c mkdir -p    /app/conf/                  0B                  </span><br><span class=\"line\">6e3fe23e82f3        53 seconds ago      /bin/sh -c #(nop)    COPY dir:3f69c750361eacc36…   101B                </span><br><span class=\"line\">d1b55fd07600        2 years ago         /bin/sh -c #(nop)    CMD [&quot;/bin/bash&quot;]             0B                  </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c sed -i    &apos;s/^#\\s*\\(deb.*universe\\)$…   1.88kB              </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c echo    &apos;#!/bin/sh&apos; &gt; /usr/sbin/poli…   701B                </span><br><span class=\"line\">&lt;missing&gt;           2 years ago         /bin/sh -c #(nop)    ADD file:3f4708cf445dc1b53…   131MB</span><br></pre></td></tr></table></figure>\n<p>我们看到<code>58866642a2af</code> <code>038a1543c273</code> <code>6e3fe23e82f3</code> 是刚刚创建的层，对应着Dockerfile文件中的每条指令。<code>d1b55fd07600</code>是基础镜像的层，而<code>missing</code>则是以往他人在其他主机上构建的层，可以忽视。</p>\n<p>当您使用<code>docker pull</code>从<code>registry</code>（镜像仓库）中下拉镜像时，每个镜像层都会单独下拉，并存储在Docker所在host的文件系统中，Linux主机上通常是<code>/var/lib/docker</code>。您可以在此示例中看到这些镜像层被拉出：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker pull ubuntu:15.04</span><br><span class=\"line\">  15.04: Pulling from library/ubuntu</span><br><span class=\"line\">  9502adfba7f1: Pull complete </span><br><span class=\"line\">  4332ffb06e4b: Pull complete </span><br><span class=\"line\">  2f937cc07b5f: Pull complete </span><br><span class=\"line\">  a3ed95caeb02: Pull complete </span><br><span class=\"line\">  Digest:      sha256:2fb27e433b3ecccea2a14e794875b086711f5d49953ef173d8a03e8707f1510   f</span><br><span class=\"line\">  Status: Downloaded newer image for ubuntu:15.04</span><br></pre></td></tr></table></figure>\n<p>下拉的镜像层存储在<code>/var/lib/docker/&lt;storage-driver&gt;/</code>目录中，本例使用的存储驱动是<code>overlay2</code>，Docker version &gt; 1.10的版本，每层的目录名称与图层ID不对应。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/overlay2/</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:19    1e72c036bc24730abff4e3eed803c5d9c3ba67d61cc4dc0da62e880a5b23d7a9</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:14      1fd044fc33c05db1b7fddf37992788befb6e5bd5dfa6ab0f4a72f281d68b5d8c</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:20      2205c9e9efbd435b968dba2beb2390e2ddc49b5cd4efedae5a6a08a5a6d2634b</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      25e720a5f2d95330556d5f99268217045654002d0c47cc77342342c2ba4af226</span><br><span class=\"line\">  drwx------. 4 root root     55 Jan 12 10:18      277b95e43bbeb2f13ec6b7dd636b774d5e9ea56bad1414c6f1fe6c3178970172</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>容器层</p>\n<p>容器和镜像之间的主要区别在于顶部可写层，所有对容器的操作：对文件的修改和添加，都是在可写层进行操作的（写时复制CoW策略），<code>low-level</code>的镜像层不会更改。若将启动的容器进行删除，那么所有的操作将不被保留。<br>若以同一个镜像启动多个容器，则底层的镜像层是公共的层，为所有容器共用，对应每个容器有各自的可写层。对容器文件的修改保存均在容器层。对于不同的容器，容器层的数据不可共享，若想共享数据，可采用<code>docker volume</code>存储。针对该存储方案，由于内容较多，将单独作为一个章节进行介绍。</p>\n<p><img src=\"/images/sharing-layers.jpg\" alt></p>\n<p>当启动一个容器，启动容器时，会在容器层的顶部添加一个体积比较小的可写容器层。容器对文件系统所做的任何更改都存储在此处。Docker的host主机文件系统中对应的容器层存储路径<code>/var/lib/docker/containers</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls -l /var/lib/docker/containers</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    025030ca0a6d5383346d4cf5471108e5cfad22d74c3411a606baf3a902c99a28</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:26    0a19a162a971fb9364907e9d2e8d39baf47d588d9e18fc6c47f16f4bca56d569</span><br><span class=\"line\">drwx------. 4 root root 237 Jan 12 10:25    1058890a8138eafaf5b7d84d3d708c0169fcba024e27697c01952465d0fdb78a</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    152da522924bf4ebebf960c3f93897f7d582f53ba98239922bf56baec7876eea</span><br><span class=\"line\">drwx------. 4 root root 165 Jan 12 10:25    1ee87d5bc8e9a58d137cbe3f98e5fd85c7ac360e03de77d69e5fa27d315fb509</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h4 id=\"写时复制（CoW）策略\"><a href=\"#写时复制（CoW）策略\" class=\"headerlink\" title=\"写时复制（CoW）策略\"></a>写时复制（CoW）策略</h4><p>写时复制（CoW）是一种共享和复制文件的策略。如果要读取或要修改的文件或目录存在于镜像中的<code>low-level</code>层（镜像层），若对该文件进行读访问，则它只需使用镜像层中的现有文件。 如果第一次添加或修改此文件时（比如：构建镜像或运行容器时），文件将被复制到该容器层（可写层）并进行修改。容器未更改的任何文件都不会复制到此可写层，意味着可写层尽可能小。这种策略保证了容器文件系统以及I/O操作的最小化。</p>\n<p>对于aufs，overlay和overlay2存储驱动，写时复制操作遵循以下顺序：</p>\n<ol>\n<li>在镜像层中搜索要修改的文件。该过程从最新层开始，一次一层地向下移动到基础镜像层。找到结果后，会将它们复制到缓存中以加快将来的操作。</li>\n<li><code>copy_up</code>对找到的文件的第一个副本执行操作，以将文件复制到容器的可写层。</li>\n<li>对此文件副本进行任何修改，将保存在容器层，后续的操作将值针对该副本进行，对于镜像层的该文件对于容器来说，是不可见的。</li>\n</ol>\n"},{"title":"Docker网络驱动(network driver)之————网桥(bridge)","date":"2019-03-25T13:33:15.000Z","_content":"\nDocker网络驱动(network driver)之————网桥(bridge)\n>在《计算机网络》这本教材中，我们学习过，**网桥**是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。\n\n在Docker的网络系统中，**网桥**`bridge network`是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的**容器**之间进行通信，同时隔离那些未连接到该**网桥**的容器。当启动`Docker daemon`（`docker`守护进程)时，会自动创建**网桥**（`bridge network`），称为:`bridge`，即对应host上的`docker0`。`Docker network`会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。\n\n查看主机上的网络设备\n```\n$ ip addr \n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3\n       valid_lft 84147sec preferred_lft 84147sec\n    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8\n       valid_lft 996sec preferred_lft 996sec\n    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:60ff:fee0:e955/64 scope link \n       valid_lft forever preferred_lft forever\n```\n查看docker网络驱动\n```\n$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nb549b06a92e7        bridge              bridge              local\nc5149e25deea        host                host                local\nbfa90bfc3dfe        none                null                local\n```\n\n**网桥**`bridge network`适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的[覆盖网络`overlay`](https://docs.docker.com/network/overlay/)和[`macvlan`](https://docs.docker.com/network/macvlan/)。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico\n\n如果用户启动一个新的容器（`container`），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（`self-defined bridge networks`）。\n**自定义网桥**在容器安全性、容器间通信等方面优于默认网桥（`bridge`）\n\n#### 用户定义的网桥与默认网桥之间的区别\n\n - 用户定义的网桥可在容器化应用程序（`container application`）之间提供更好的隔离性和连通性\n   连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。\n\n   比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。\n   如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或--publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。\n\n - 用户定义的桥接器在容器之间提供自动DNS解析\n   默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用`--link`选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。\n   还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（`--link`）。如果容器数量达到几十或者几百，那么工作量将会非常大。\n   \n - 容器可以在运行中与用户定义的网络连接和分离\n   \n - 每个用户定义的网络都会创建一个可配置的网桥\n   如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用`docker network create`创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。\n   ```\n   $ docker network create my-net\n   ```\n\n - 默认桥接网络上的链接容器共享环境变量\n   最初，在两个容器之间共享环境变量的唯一方法是使用--link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：\n\n   - 多个容器可以挂载包含共享信息的文件或目录，使用`Docker volume`挂载卷进行文件或者变量共享。\n\n   - 可以使用`docker-compose`一起启动多个容器，并且compose文件可以定义共享变量。\n\n   - 您可以使用集群服务（`swamp service`）而不是独立容器，并利用[`secrets`](https://docs.docker.com/engine/swarm/secrets/)和[`configs`](https://docs.docker.com/engine/swarm/configs/)共享变量。\n     ```\n\t docker service create \\\n     --name nginx \\\n     --secret site.key \\\n     --secret site.crt \\\n     --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n     --publish published=3000,target=443 \\\n     nginx:latest \\\n     sh -c \"exec nginx -g 'daemon off;'\"\n\t ```\n#### 创建用户自定义网桥（self-define ）\n\n- 使用命令`docker network create ` 命令创建用户自定义网络\n   \n   具体使用方法可以使用`docker network create --help`获取帮助  \n    ```\n    $ docker network create \\\n     --driver=bridge \\\n     --subnet=172.28.0.0/16 \\\n     --ip-range=172.28.5.0/24 \\\n     --gateway=172.28.5.254 \\\n        br0\n   ```\n\n- 使用命令`docker network rm `命令删除已存在的网络\n   ```\n   $ docker network rm my-net\n   ```\n当用户**删除**或**创建**网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改`iptables`规则）。这些操作对用户来说是透明的。\n\n#### 连接容器到自定义网络\n用户在创建容器时，可以指定连接到自定义网络（使用`--network`方式）；也可以将正在运行的（runing)的容器连接到自定义网络。\n\n - 创建容器，并连接到自定义网络\n\n   例如：创建`Nginx`容器，连接到`my-net`网络中\n   ```\n   $ docker create --name my-nginx \\\n      --network my-net \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   创建一个容器`my-nginx`，连接到已存在的`my-net` 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。\n\n - `running`容器连接到自定义网络中\n\n   启动`my-nignx`容器\n   ```\n   $ docker run --name my-nginx \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   连接到`my-net`自定义网络\n   ```\n   $ docker network connect my-net my-nginx\n   ```\n   如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。\n\n#### 修改Docker默认网桥\n修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件\n\n - 修改dockerd启动配置文件\n\n   dockerd启动文件默认位置：`/usr/lib/systemd/system/docker.service`\n   ```\n   ...\n   ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\\n     -H tcp://0.0.0.0:2376 \\\n     --bip=10.2.54.1/24 \\ \n     --mtu=1450 \\ \n     --dns=[\"10.20.1.2\",\"10.20.1.3\"]\n   ...\n   ```\n\n - daemon.json文件\n   ```\n   {\n      \"bip\": \"192.168.1.5/24\",\n      \"fixed-cidr\": \"192.168.1.5/25\",\n      \"fixed-cidr-v6\": \"2001:db8::/64\",\n      \"mtu\": 1500,\n      \"default-gateway\": \"10.20.1.1\",\n      \"default-gateway-v6\": \"2001:db8:abcd::89\",\n      \"dns\": [\"10.20.1.2\",\"10.20.1.3\"]\n   }\n   ```\n使参数生效，则需要重启Docker守护进程。\n\n\n\n\n\n\n\n","source":"_posts/2019-03-25-docker-network-bridge.md","raw":"---\ntitle: Docker网络驱动(network driver)之————网桥(bridge) \ndate: 2019-03-25 13:33:15\ntags:\n  - docker\ncategories:\n  - 运维\n  - docker\n---\n\nDocker网络驱动(network driver)之————网桥(bridge)\n>在《计算机网络》这本教材中，我们学习过，**网桥**是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。\n\n在Docker的网络系统中，**网桥**`bridge network`是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的**容器**之间进行通信，同时隔离那些未连接到该**网桥**的容器。当启动`Docker daemon`（`docker`守护进程)时，会自动创建**网桥**（`bridge network`），称为:`bridge`，即对应host上的`docker0`。`Docker network`会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。\n\n查看主机上的网络设备\n```\n$ ip addr \n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3\n       valid_lft 84147sec preferred_lft 84147sec\n    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff\n    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8\n       valid_lft 996sec preferred_lft 996sec\n    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n4: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default \n    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:60ff:fee0:e955/64 scope link \n       valid_lft forever preferred_lft forever\n```\n查看docker网络驱动\n```\n$ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\nb549b06a92e7        bridge              bridge              local\nc5149e25deea        host                host                local\nbfa90bfc3dfe        none                null                local\n```\n\n**网桥**`bridge network`适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的[覆盖网络`overlay`](https://docs.docker.com/network/overlay/)和[`macvlan`](https://docs.docker.com/network/macvlan/)。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico\n\n如果用户启动一个新的容器（`container`），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（`self-defined bridge networks`）。\n**自定义网桥**在容器安全性、容器间通信等方面优于默认网桥（`bridge`）\n\n#### 用户定义的网桥与默认网桥之间的区别\n\n - 用户定义的网桥可在容器化应用程序（`container application`）之间提供更好的隔离性和连通性\n   连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。\n\n   比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。\n   如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或--publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。\n\n - 用户定义的桥接器在容器之间提供自动DNS解析\n   默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用`--link`选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。\n   还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（`--link`）。如果容器数量达到几十或者几百，那么工作量将会非常大。\n   \n - 容器可以在运行中与用户定义的网络连接和分离\n   \n - 每个用户定义的网络都会创建一个可配置的网桥\n   如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用`docker network create`创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。\n   ```\n   $ docker network create my-net\n   ```\n\n - 默认桥接网络上的链接容器共享环境变量\n   最初，在两个容器之间共享环境变量的唯一方法是使用--link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：\n\n   - 多个容器可以挂载包含共享信息的文件或目录，使用`Docker volume`挂载卷进行文件或者变量共享。\n\n   - 可以使用`docker-compose`一起启动多个容器，并且compose文件可以定义共享变量。\n\n   - 您可以使用集群服务（`swamp service`）而不是独立容器，并利用[`secrets`](https://docs.docker.com/engine/swarm/secrets/)和[`configs`](https://docs.docker.com/engine/swarm/configs/)共享变量。\n     ```\n\t docker service create \\\n     --name nginx \\\n     --secret site.key \\\n     --secret site.crt \\\n     --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\\n     --publish published=3000,target=443 \\\n     nginx:latest \\\n     sh -c \"exec nginx -g 'daemon off;'\"\n\t ```\n#### 创建用户自定义网桥（self-define ）\n\n- 使用命令`docker network create ` 命令创建用户自定义网络\n   \n   具体使用方法可以使用`docker network create --help`获取帮助  \n    ```\n    $ docker network create \\\n     --driver=bridge \\\n     --subnet=172.28.0.0/16 \\\n     --ip-range=172.28.5.0/24 \\\n     --gateway=172.28.5.254 \\\n        br0\n   ```\n\n- 使用命令`docker network rm `命令删除已存在的网络\n   ```\n   $ docker network rm my-net\n   ```\n当用户**删除**或**创建**网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改`iptables`规则）。这些操作对用户来说是透明的。\n\n#### 连接容器到自定义网络\n用户在创建容器时，可以指定连接到自定义网络（使用`--network`方式）；也可以将正在运行的（runing)的容器连接到自定义网络。\n\n - 创建容器，并连接到自定义网络\n\n   例如：创建`Nginx`容器，连接到`my-net`网络中\n   ```\n   $ docker create --name my-nginx \\\n      --network my-net \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   创建一个容器`my-nginx`，连接到已存在的`my-net` 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。\n\n - `running`容器连接到自定义网络中\n\n   启动`my-nignx`容器\n   ```\n   $ docker run --name my-nginx \\\n      --publish 8080:80 \\\n      nginx:latest\n   ```\n   连接到`my-net`自定义网络\n   ```\n   $ docker network connect my-net my-nginx\n   ```\n   如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。\n\n#### 修改Docker默认网桥\n修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件\n\n - 修改dockerd启动配置文件\n\n   dockerd启动文件默认位置：`/usr/lib/systemd/system/docker.service`\n   ```\n   ...\n   ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\\n     -H tcp://0.0.0.0:2376 \\\n     --bip=10.2.54.1/24 \\ \n     --mtu=1450 \\ \n     --dns=[\"10.20.1.2\",\"10.20.1.3\"]\n   ...\n   ```\n\n - daemon.json文件\n   ```\n   {\n      \"bip\": \"192.168.1.5/24\",\n      \"fixed-cidr\": \"192.168.1.5/25\",\n      \"fixed-cidr-v6\": \"2001:db8::/64\",\n      \"mtu\": 1500,\n      \"default-gateway\": \"10.20.1.1\",\n      \"default-gateway-v6\": \"2001:db8:abcd::89\",\n      \"dns\": [\"10.20.1.2\",\"10.20.1.3\"]\n   }\n   ```\n使参数生效，则需要重启Docker守护进程。\n\n\n\n\n\n\n\n","slug":"docker-network-bridge","published":1,"updated":"2019-03-25T05:45:06.757Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oz4001mt2xusx6hrns2","content":"<p>Docker网络驱动(network driver)之————网桥(bridge)</p>\n<blockquote>\n<p>在《计算机网络》这本教材中，我们学习过，<strong>网桥</strong>是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。</p>\n</blockquote>\n<p>在Docker的网络系统中，<strong>网桥</strong><code>bridge network</code>是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的<strong>容器</strong>之间进行通信，同时隔离那些未连接到该<strong>网桥</strong>的容器。当启动<code>Docker daemon</code>（<code>docker</code>守护进程)时，会自动创建<strong>网桥</strong>（<code>bridge network</code>），称为:<code>bridge</code>，即对应host上的<code>docker0</code>。<code>Docker network</code>会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。</p>\n<p>查看主机上的网络设备<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr </span><br><span class=\"line\">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class=\"line\">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class=\"line\">    inet 127.0.0.1/8 scope host lo</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 ::1/128 scope host </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class=\"line\">       valid_lft 84147sec preferred_lft 84147sec</span><br><span class=\"line\">    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8</span><br><span class=\"line\">       valid_lft 996sec preferred_lft 996sec</span><br><span class=\"line\">    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class=\"line\">    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 fe80::42:60ff:fee0:e955/64 scope link </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p>\n<p>查看docker网络驱动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">b549b06a92e7        bridge              bridge              local</span><br><span class=\"line\">c5149e25deea        host                host                local</span><br><span class=\"line\">bfa90bfc3dfe        none                null                local</span><br></pre></td></tr></table></figure></p>\n<p><strong>网桥</strong><code>bridge network</code>适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的<a href=\"https://docs.docker.com/network/overlay/\" target=\"_blank\" rel=\"noopener\">覆盖网络<code>overlay</code></a>和<a href=\"https://docs.docker.com/network/macvlan/\" target=\"_blank\" rel=\"noopener\"><code>macvlan</code></a>。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico</p>\n<p>如果用户启动一个新的容器（<code>container</code>），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（<code>self-defined bridge networks</code>）。<br><strong>自定义网桥</strong>在容器安全性、容器间通信等方面优于默认网桥（<code>bridge</code>）</p>\n<h4 id=\"用户定义的网桥与默认网桥之间的区别\"><a href=\"#用户定义的网桥与默认网桥之间的区别\" class=\"headerlink\" title=\"用户定义的网桥与默认网桥之间的区别\"></a>用户定义的网桥与默认网桥之间的区别</h4><ul>\n<li><p>用户定义的网桥可在容器化应用程序（<code>container application</code>）之间提供更好的隔离性和连通性<br>连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。</p>\n<p>比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。<br>如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或–publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。</p>\n</li>\n<li><p>用户定义的桥接器在容器之间提供自动DNS解析<br>默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用<code>--link</code>选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。<br>还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（<code>--link</code>）。如果容器数量达到几十或者几百，那么工作量将会非常大。</p>\n</li>\n<li><p>容器可以在运行中与用户定义的网络连接和分离</p>\n</li>\n<li><p>每个用户定义的网络都会创建一个可配置的网桥<br>如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用<code>docker network create</code>创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create my-net</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>默认桥接网络上的链接容器共享环境变量<br>最初，在两个容器之间共享环境变量的唯一方法是使用–link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：</p>\n<ul>\n<li><p>多个容器可以挂载包含共享信息的文件或目录，使用<code>Docker volume</code>挂载卷进行文件或者变量共享。</p>\n</li>\n<li><p>可以使用<code>docker-compose</code>一起启动多个容器，并且compose文件可以定义共享变量。</p>\n</li>\n<li><p>您可以使用集群服务（<code>swamp service</code>）而不是独立容器，并利用<a href=\"https://docs.docker.com/engine/swarm/secrets/\" target=\"_blank\" rel=\"noopener\"><code>secrets</code></a>和<a href=\"https://docs.docker.com/engine/swarm/configs/\" target=\"_blank\" rel=\"noopener\"><code>configs</code></a>共享变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker service create \\</span><br><span class=\"line\">   --name nginx \\</span><br><span class=\"line\">   --secret site.key \\</span><br><span class=\"line\">   --secret site.crt \\</span><br><span class=\"line\">   --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\</span><br><span class=\"line\">   --publish published=3000,target=443 \\</span><br><span class=\"line\">   nginx:latest \\</span><br><span class=\"line\">   sh -c &quot;exec nginx -g &apos;daemon off;&apos;&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"创建用户自定义网桥（self-define-）\"><a href=\"#创建用户自定义网桥（self-define-）\" class=\"headerlink\" title=\"创建用户自定义网桥（self-define ）\"></a>创建用户自定义网桥（self-define ）</h4><ul>\n<li><p>使用命令<code>docker network create</code> 命令创建用户自定义网络</p>\n<p> 具体使用方法可以使用<code>docker network create --help</code>获取帮助  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\"> --driver=bridge \\</span><br><span class=\"line\"> --subnet=172.28.0.0/16 \\</span><br><span class=\"line\"> --ip-range=172.28.5.0/24 \\</span><br><span class=\"line\"> --gateway=172.28.5.254 \\</span><br><span class=\"line\">    br0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用命令<code>docker network rm</code>命令删除已存在的网络</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm my-net</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>当用户<strong>删除</strong>或<strong>创建</strong>网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改<code>iptables</code>规则）。这些操作对用户来说是透明的。</p>\n<h4 id=\"连接容器到自定义网络\"><a href=\"#连接容器到自定义网络\" class=\"headerlink\" title=\"连接容器到自定义网络\"></a>连接容器到自定义网络</h4><p>用户在创建容器时，可以指定连接到自定义网络（使用<code>--network</code>方式）；也可以将正在运行的（runing)的容器连接到自定义网络。</p>\n<ul>\n<li><p>创建容器，并连接到自定义网络</p>\n<p>例如：创建<code>Nginx</code>容器，连接到<code>my-net</code>网络中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker create --name my-nginx \\</span><br><span class=\"line\">   --network my-net \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>创建一个容器<code>my-nginx</code>，连接到已存在的<code>my-net</code> 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。</p>\n</li>\n<li><p><code>running</code>容器连接到自定义网络中</p>\n<p>启动<code>my-nignx</code>容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --name my-nginx \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>连接到<code>my-net</code>自定义网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network connect my-net my-nginx</span><br></pre></td></tr></table></figure>\n<p>如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。</p>\n</li>\n</ul>\n<h4 id=\"修改Docker默认网桥\"><a href=\"#修改Docker默认网桥\" class=\"headerlink\" title=\"修改Docker默认网桥\"></a>修改Docker默认网桥</h4><p>修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件</p>\n<ul>\n<li><p>修改dockerd启动配置文件</p>\n<p>dockerd启动文件默认位置：<code>/usr/lib/systemd/system/docker.service</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\</span><br><span class=\"line\">  -H tcp://0.0.0.0:2376 \\</span><br><span class=\"line\">  --bip=10.2.54.1/24 \\ </span><br><span class=\"line\">  --mtu=1450 \\ </span><br><span class=\"line\">  --dns=[&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>daemon.json文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;bip&quot;: &quot;192.168.1.5/24&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,</span><br><span class=\"line\">   &quot;mtu&quot;: 1500,</span><br><span class=\"line\">   &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</span><br><span class=\"line\">   &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</span><br><span class=\"line\">   &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使参数生效，则需要重启Docker守护进程。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Docker网络驱动(network driver)之————网桥(bridge)</p>\n<blockquote>\n<p>在《计算机网络》这本教材中，我们学习过，<strong>网桥</strong>是一种工作在数据链路层，对帧进行转发的技术，它根据MAC帧的目标地址对收到的帧进行转发和过滤。网桥可以是硬件设备也可以是在主机内核（kernel）中运行的软件设备。</p>\n</blockquote>\n<p>在Docker的网络系统中，<strong>网桥</strong><code>bridge network</code>是默认的网络驱动。使用软件桥接器，允许连接到同一桥接网络的<strong>容器</strong>之间进行通信，同时隔离那些未连接到该<strong>网桥</strong>的容器。当启动<code>Docker daemon</code>（<code>docker</code>守护进程)时，会自动创建<strong>网桥</strong>（<code>bridge network</code>），称为:<code>bridge</code>，即对应host上的<code>docker0</code>。<code>Docker network</code>会自动在主机中安装规则，以阻止不同网桥上的容器进行相互通信。</p>\n<p>查看主机上的网络设备<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr </span><br><span class=\"line\">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class=\"line\">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class=\"line\">    inet 127.0.0.1/8 scope host lo</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 ::1/128 scope host </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:eb:89:b8 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 10.0.2.15/24 brd 10.0.2.255 scope global noprefixroute dynamic enp0s3</span><br><span class=\"line\">       valid_lft 84147sec preferred_lft 84147sec</span><br><span class=\"line\">    inet6 fe80::eef9:c7e0:7365:65b6/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class=\"line\">    link/ether 08:00:27:22:76:1d brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s8</span><br><span class=\"line\">       valid_lft 996sec preferred_lft 996sec</span><br><span class=\"line\">    inet6 fe80::a88:e4da:b641:f973/64 scope link noprefixroute </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class=\"line\">    link/ether 02:42:60:e0:e9:55 brd ff:ff:ff:ff:ff:ff</span><br><span class=\"line\">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br><span class=\"line\">    inet6 fe80::42:60ff:fee0:e955/64 scope link </span><br><span class=\"line\">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure></p>\n<p>查看docker网络驱动<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network ls</span><br><span class=\"line\">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class=\"line\">b549b06a92e7        bridge              bridge              local</span><br><span class=\"line\">c5149e25deea        host                host                local</span><br><span class=\"line\">bfa90bfc3dfe        none                null                local</span><br></pre></td></tr></table></figure></p>\n<p><strong>网桥</strong><code>bridge network</code>适用于在同一个Docker守护进程的主机上运行的容器。对于在不同Docker守护进程主机上运行的容器之间的通信，可以在操作系统级别管理路由，可以使用原生的<a href=\"https://docs.docker.com/network/overlay/\" target=\"_blank\" rel=\"noopener\">覆盖网络<code>overlay</code></a>和<a href=\"https://docs.docker.com/network/macvlan/\" target=\"_blank\" rel=\"noopener\"><code>macvlan</code></a>。也可使用第三方网络插件：常用的包括 flannel、weave 和 calico</p>\n<p>如果用户启动一个新的容器（<code>container</code>），则默认会连接到该网桥，除非在启动容器时指定了自定义网桥（<code>self-defined bridge networks</code>）。<br><strong>自定义网桥</strong>在容器安全性、容器间通信等方面优于默认网桥（<code>bridge</code>）</p>\n<h4 id=\"用户定义的网桥与默认网桥之间的区别\"><a href=\"#用户定义的网桥与默认网桥之间的区别\" class=\"headerlink\" title=\"用户定义的网桥与默认网桥之间的区别\"></a>用户定义的网桥与默认网桥之间的区别</h4><ul>\n<li><p>用户定义的网桥可在容器化应用程序（<code>container application</code>）之间提供更好的隔离性和连通性<br>连接到同一个用户定义的网桥的容器会自动将所有端口相互暴露，而不会向外界暴露任何端口。这使得容器中的应用程序可以轻松地相互通信，而阻止外界对容器的访问。</p>\n<p>比如：有一个web前端和db后端两个容器，集群外部需要访问web前端（比如80端口）。使用用户定义的网桥，可以实现允许外部访问web前端，阻止访问db后端（比如：3306）。而web前端可以通过自定义网桥对db容器进行访问。<br>如果在默认网桥上运行相同的应用程序（web前端和db后端），则需要同时暴露Web端口（80）和数据库端口（3306），并为每个端口使用-p或–publish标志。 这意味着Docker主机需要通过其他方式阻止对db数据库端口的访问。</p>\n</li>\n<li><p>用户定义的桥接器在容器之间提供自动DNS解析<br>默认网桥上的容器只能通过IP地址相互访问（无法直接访问IP:PORT），除非您使用<code>--link</code>选项（该属性官方建议后续不再使用）。 而在用户定义的桥接网络上，容器可以通过名称或别名相互解析。<br>还拿上个例子说明：如果在默认网桥上运行web容器和db容器，则需要在容器之间手动的创建链接（<code>--link</code>）。如果容器数量达到几十或者几百，那么工作量将会非常大。</p>\n</li>\n<li><p>容器可以在运行中与用户定义的网络连接和分离</p>\n</li>\n<li><p>每个用户定义的网络都会创建一个可配置的网桥<br>如果容器使用默认桥接网络，则可以对其进行配置，但所有容器都使用相同的设置，例如MTU（最大传输数据包大小）和iptables规则。 此外，配置默认桥接网络，需要重新启动Docker。 使用<code>docker network create</code>创建和配置用户定义的网桥。 如果不同的应用程序组具有不同的网络要求，则可以在创建时单独配置每个用户定义的网桥。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create my-net</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>默认桥接网络上的链接容器共享环境变量<br>最初，在两个容器之间共享环境变量的唯一方法是使用–link标志链接它们。 用户定义的网络无法实现这种类型的变量共享。 但是，有更好的方法来共享环境变量。 一些想法：</p>\n<ul>\n<li><p>多个容器可以挂载包含共享信息的文件或目录，使用<code>Docker volume</code>挂载卷进行文件或者变量共享。</p>\n</li>\n<li><p>可以使用<code>docker-compose</code>一起启动多个容器，并且compose文件可以定义共享变量。</p>\n</li>\n<li><p>您可以使用集群服务（<code>swamp service</code>）而不是独立容器，并利用<a href=\"https://docs.docker.com/engine/swarm/secrets/\" target=\"_blank\" rel=\"noopener\"><code>secrets</code></a>和<a href=\"https://docs.docker.com/engine/swarm/configs/\" target=\"_blank\" rel=\"noopener\"><code>configs</code></a>共享变量。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker service create \\</span><br><span class=\"line\">   --name nginx \\</span><br><span class=\"line\">   --secret site.key \\</span><br><span class=\"line\">   --secret site.crt \\</span><br><span class=\"line\">   --config source=site.conf,target=/etc/nginx/conf.d/site.conf,mode=0440 \\</span><br><span class=\"line\">   --publish published=3000,target=443 \\</span><br><span class=\"line\">   nginx:latest \\</span><br><span class=\"line\">   sh -c &quot;exec nginx -g &apos;daemon off;&apos;&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"创建用户自定义网桥（self-define-）\"><a href=\"#创建用户自定义网桥（self-define-）\" class=\"headerlink\" title=\"创建用户自定义网桥（self-define ）\"></a>创建用户自定义网桥（self-define ）</h4><ul>\n<li><p>使用命令<code>docker network create</code> 命令创建用户自定义网络</p>\n<p> 具体使用方法可以使用<code>docker network create --help</code>获取帮助  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network create \\</span><br><span class=\"line\"> --driver=bridge \\</span><br><span class=\"line\"> --subnet=172.28.0.0/16 \\</span><br><span class=\"line\"> --ip-range=172.28.5.0/24 \\</span><br><span class=\"line\"> --gateway=172.28.5.254 \\</span><br><span class=\"line\">    br0</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用命令<code>docker network rm</code>命令删除已存在的网络</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network rm my-net</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>当用户<strong>删除</strong>或<strong>创建</strong>网络，或者用户将容器连接（断开连接）到自定义网络时，操作系统会管理底层网络基础架构（创建（删除）网桥或者修改<code>iptables</code>规则）。这些操作对用户来说是透明的。</p>\n<h4 id=\"连接容器到自定义网络\"><a href=\"#连接容器到自定义网络\" class=\"headerlink\" title=\"连接容器到自定义网络\"></a>连接容器到自定义网络</h4><p>用户在创建容器时，可以指定连接到自定义网络（使用<code>--network</code>方式）；也可以将正在运行的（runing)的容器连接到自定义网络。</p>\n<ul>\n<li><p>创建容器，并连接到自定义网络</p>\n<p>例如：创建<code>Nginx</code>容器，连接到<code>my-net</code>网络中</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker create --name my-nginx \\</span><br><span class=\"line\">   --network my-net \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>创建一个容器<code>my-nginx</code>，连接到已存在的<code>my-net</code> 网络中，并且将容器内部开放的80端口映射到宿主机的8080端口上。在容器外部，可以通过8080端口访问该容器。</p>\n</li>\n<li><p><code>running</code>容器连接到自定义网络中</p>\n<p>启动<code>my-nignx</code>容器</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker run --name my-nginx \\</span><br><span class=\"line\">   --publish 8080:80 \\</span><br><span class=\"line\">   nginx:latest</span><br></pre></td></tr></table></figure>\n<p>连接到<code>my-net</code>自定义网络</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker network connect my-net my-nginx</span><br></pre></td></tr></table></figure>\n<p>如果启动docker容器时，不指定自定义网桥，则容器会连接默认网桥。连接到默认网桥的容器客户相互通信，但是只能通过IP地址进行通信。</p>\n</li>\n</ul>\n<h4 id=\"修改Docker默认网桥\"><a href=\"#修改Docker默认网桥\" class=\"headerlink\" title=\"修改Docker默认网桥\"></a>修改Docker默认网桥</h4><p>修改默认网桥，有两种方式：修改dockerd启动配置文件 和 修改Docker守护进程daemon.json文件</p>\n<ul>\n<li><p>修改dockerd启动配置文件</p>\n<p>dockerd启动文件默认位置：<code>/usr/lib/systemd/system/docker.service</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock \\</span><br><span class=\"line\">  -H tcp://0.0.0.0:2376 \\</span><br><span class=\"line\">  --bip=10.2.54.1/24 \\ </span><br><span class=\"line\">  --mtu=1450 \\ </span><br><span class=\"line\">  --dns=[&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>daemon.json文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">   &quot;bip&quot;: &quot;192.168.1.5/24&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr&quot;: &quot;192.168.1.5/25&quot;,</span><br><span class=\"line\">   &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;,</span><br><span class=\"line\">   &quot;mtu&quot;: 1500,</span><br><span class=\"line\">   &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</span><br><span class=\"line\">   &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</span><br><span class=\"line\">   &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使参数生效，则需要重启Docker守护进程。</p>\n"},{"title":"NGINX Ingress Controller教程","date":"2019-01-25T16:26:10.000Z","_content":"\n## NGINX Ingress Controller\n[TOC]\n### Bare-metal considerations\n - MetalLB\n`MetalLB`提供了一个不仅仅只有云服务商才可提供的在`kubernetes`集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。\n本教程介绍使用[ **Layer 2 configuration mode**](https://metallb.universe.tf/tutorial/layer2/) [**MetalLB**](https://metallb.universe.tf/)和`NGINX Ingress controller`在集群中有公开访问的节点。在此模式下，一个节点吸引`ingress-nginx`服务IP的所有流量。\n**MetalLB:Layer2**\n![MetalLB:Layer2](/images/metallb.jpg)\n例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <None>)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n依照下方`yaml`文件创建`ComfigMap`, MetalLB获得池中其中一个IP地址的所有权，并相应地更新`ingress-nginx`服务的`loadBalancer IP`字段。.\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 203.0.113.2-203.0.113.3\n```\n```\n$ kubectl -n ingress-nginx get svc\nNAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)\ndefault-http-backend   ClusterIP     10.0.64.249    <none>       80/TCP\ningress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP\n```\n----\n - ##### Over a NodePort Service\n 在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配`ingress-nginx service`的`Type`为`Nodeport`。\n ![Over a NodePort Service](/images/nodeport.jpg)\n 例如：Given the NodePort 30100 allocated to the ingress-nginx Service\n ```\n$ kubectl get svc -n ingress-nginx\nNAME                   TYPE        CLUSTER-IP     PORT(S)\ndefault-http-backend   ClusterIP   10.0.64.249    80/TCP\ningress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n ```\n 其中一个`Node`节点的IP地址为203.0.113.2 (`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n客户端可通过`http://myapp.example.com:30100`与配置`host`:`myapp.example.com`的`Ingress`进行通信，` myapp.example.com` 子域解析为203.0.113.2地址。\n这种方法还有一些应该注意的其他限制\n  - **Source IP address**\n    Services of type NodePort perform source address translation by default。这意味着：HTTP请求的`source IP`始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。\n\t建议通过设置`ingress-nginx Service`的`spec.externalTrafficPolicy`的属性域为`local`（[例如](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14)），来保留`source IP`\n\t```yaml\n\tkind: Service\n\tapiVersion: v1\n\tmetadata:\n\t  name: ingress-nginx\n\t  namespace: ingress-nginx\n\t  ...\n\tspec:\n\t  # this setting is t make sure the source IP address is preserved.\n\t  externalTrafficPolicy: Local\n\t  type: LoadBalancer\n\t  ...\n\t  ports:\n\t  - name: http\n\t\tport: 80\n\t\ttargetPort: http\n\t  ...\n\t```\n\t例如一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\tnginx-ingress-controller的Deployment 有两个副本集`replicas`\n\t```\n\t$ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP           NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2\n\tnginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3\n\tnginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2\n\t```\n\t到`host-2`和`host-3`的请求将被转发到 `NGINX`并且原始的客户端IP将被保留，但是请求到`host-1`的`Node`的请求将被丢弃，因为在该`Node`上没有`NGINX`副本集。\n\t\n  - **Ingress status**\n    因为`NodePort`类型的`Service`没有按定义分配`LoadBalancerIP`，`NGINX Ingress controller`不会更新`Ingress`对象的状态。\n\t```\n\t$ kubectl get ingress\n    NAME           HOSTS               ADDRESS   PORTS\n    test-ingress   myapp.example.com             80\n\t```\n\t尽管没有负载均衡器为`NGINX Ingress Controller`提供公共IP地址，但可以通过设置`ingress-nginx Service`的`externalIPs`字段来强制所有管理的Ingress对象的状态更新。\n\t例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\t可以编辑`ingress-nginx Service` 添加如下代码片段到到属性域`spec`中：\n\t```\n\t...\n\tspec:\n\t  externalIPs:\n\t  - 203.0.113.1\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n\t...\n\t```\n\t如此，将会在`Ingress`对象上生效：\n\t```\n\t$ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                               PORTS\n\ttest-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80\n\t```\n  - **Redirects**\n  > As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.\n   \n    由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。\n\t举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to www.domain, are generated without NodePort:\n\t```\n\t$ curl -D- http://myapp.example.com:30100\n\tHTTP/1.1 308 Permanent Redirect\n\tServer: nginx/1.15.2\n\tLocation: https://myapp.example.com/  #-> missing NodePort in HTTPS redirect\n\t```\n----\n - ##### Via the host network\n   在没有可用的外部负载均衡器的设置中，但不能使用`NodePorts`。还有一种方法就是，通过设置`ingress-nginx`的Pods使用**主机网络**，而不是专用的网络命名空间(`network namespace`)。该方案的好处就是，在没有额外的`NodePort Service`提供的外部网络转换情况下，`NGINX Ingress controller`可以直接绑定k8s的`Node`网络接口的端口80或443。\n   这可以通过配置Pods属性域`template.spec`的`hostNetwork`选项来实现：\n   ```\n   template:\n\t  spec:\n\t\thostNetwork: true\n   ```\n   注意：\n   启用此选项会将所有系统守护进程暴露给任何网络接口上的`NGINX Ingress Controller`，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。\n   例如：`nginx-ingress-controller`Deployment有两个副本集，`NGINX` PodsN继承其主机的IP地址，而不是内部 Pod IP\n   ```\n   $ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n   ```\n   该部署方式的主要限制是：每个群集节点上只能安排一个`NGINX Ingress Controller` Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，\n   ```\n   $ kubectl -n ingress-nginx describe pod <unschedulable-nginx-ingress-controller-pod>\n\t...\n\tEvents:\n\t  Type     Reason            From               Message\n\t  ----     ------            ----               -------\n\t  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn't have free ports for the requested pod ports.\n   ```\n   确保仅创建可调度Pod的一种方法是将`NGINX Ingress Controller`部署为`DaemonSet`而不是传统的`Deployment`。\n   ![hostnetwork](/images/hostnetwork.jpg)\n   与NodePorts一样，这种方法有一些怪癖，重要的是要注意\n     - **DNS resolution**\n     如果Pods配置了`hostNetwork: true`属性，则不使用内部DNS解析器(`kube-dns`或`CoreDns`)，除非Pods的`spec.dnsPolicy`配置了`ClusterFirstWithHostNet`属性。\n\t \n     - **Ingress status**\n     由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认--publish-service标志不适用，并且所有Ingress对象的状态保持空白。\n\t ```\n\t $ kubectl get ingress\n\tNAME           HOSTS               ADDRESS   PORTS\n\ttest-ingress   myapp.example.com             80\n\t ```\n\t 相反，由于`bare-metal`Node通常没有`Extral IP`，因此必须启用`--report-node-internal-ip-address`，它将所有Ingress对象的状态设置为运行`NGINX Ingress Controller`的所有节点的内部IP地址。\n\t Given a nginx-ingress-controller DaemonSet composed of 2 replicas\n\t ```\n\t $ kubectl -n ingress-nginx get pod -o wide\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n\t ```\n\t 控制器将其管理的所有Ingress对象的状态设置为以下值：\n\t ```\n\t $ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                   PORTS\n\ttest-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80\n\t ```\n - ##### Using a self-provisioned edge\n   与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。\n   此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。\n   边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：\n   ![Using a self-provisioned edge](/images/user_edge.jpg)\n   根据官方Kubernetes文档的“服务”页面，`externalIPs`选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的`endpoints`。这些IP地址必须属于目标节点(target node)。\n   > 例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n    ```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n    ```\n   and the following ingress-nginx NodePort Service\n   ```\n   $ kubectl -n ingress-nginx get svc\n   NAME                   TYPE        CLUSTER-IP     PORT(S)\n   ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n   ```\n   我们可以在`Service`的`spec.externalIPs`属性域中设置**externalIPs**, 则**NGINX**通过`NodePort`和`Service Port`变的可达：\n   ```\n   spec:\n\t  externalIPs:\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n   ```\n   ```\n   $ curl -D- http://myapp.example.com:30100\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   $ curl -D- http://myapp.example.com\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   ```\n   我们假设 `myapp.example.com` 域名解析成IP地址：203.0.113.2 和 203.0.113.3。\n\n\n\n","source":"_posts/2019-03-25-nginx-ingress-controller-introduct.md","raw":"---\ntitle: NGINX Ingress Controller教程\ndate: 2019-01-25 16:26:10\ntags:\n  - kubernetes\ncategories:\n  - 运维\n  - kubernetes\n\n---\n\n## NGINX Ingress Controller\n[TOC]\n### Bare-metal considerations\n - MetalLB\n`MetalLB`提供了一个不仅仅只有云服务商才可提供的在`kubernetes`集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。\n本教程介绍使用[ **Layer 2 configuration mode**](https://metallb.universe.tf/tutorial/layer2/) [**MetalLB**](https://metallb.universe.tf/)和`NGINX Ingress controller`在集群中有公开访问的节点。在此模式下，一个节点吸引`ingress-nginx`服务IP的所有流量。\n**MetalLB:Layer2**\n![MetalLB:Layer2](/images/metallb.jpg)\n例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <None>)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n依照下方`yaml`文件创建`ComfigMap`, MetalLB获得池中其中一个IP地址的所有权，并相应地更新`ingress-nginx`服务的`loadBalancer IP`字段。.\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 203.0.113.2-203.0.113.3\n```\n```\n$ kubectl -n ingress-nginx get svc\nNAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)\ndefault-http-backend   ClusterIP     10.0.64.249    <none>       80/TCP\ningress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP\n```\n----\n - ##### Over a NodePort Service\n 在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配`ingress-nginx service`的`Type`为`Nodeport`。\n ![Over a NodePort Service](/images/nodeport.jpg)\n 例如：Given the NodePort 30100 allocated to the ingress-nginx Service\n ```\n$ kubectl get svc -n ingress-nginx\nNAME                   TYPE        CLUSTER-IP     PORT(S)\ndefault-http-backend   ClusterIP   10.0.64.249    80/TCP\ningress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n ```\n 其中一个`Node`节点的IP地址为203.0.113.2 (`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n```\n$ kubectl describe node\nNAME     STATUS   ROLES    EXTERNAL-IP\nhost-1   Ready    master   203.0.113.1\nhost-2   Ready    node     203.0.113.2\nhost-3   Ready    node     203.0.113.3\n```\n客户端可通过`http://myapp.example.com:30100`与配置`host`:`myapp.example.com`的`Ingress`进行通信，` myapp.example.com` 子域解析为203.0.113.2地址。\n这种方法还有一些应该注意的其他限制\n  - **Source IP address**\n    Services of type NodePort perform source address translation by default。这意味着：HTTP请求的`source IP`始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。\n\t建议通过设置`ingress-nginx Service`的`spec.externalTrafficPolicy`的属性域为`local`（[例如](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14)），来保留`source IP`\n\t```yaml\n\tkind: Service\n\tapiVersion: v1\n\tmetadata:\n\t  name: ingress-nginx\n\t  namespace: ingress-nginx\n\t  ...\n\tspec:\n\t  # this setting is t make sure the source IP address is preserved.\n\t  externalTrafficPolicy: Local\n\t  type: LoadBalancer\n\t  ...\n\t  ports:\n\t  - name: http\n\t\tport: 80\n\t\ttargetPort: http\n\t  ...\n\t```\n\t例如一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\tnginx-ingress-controller的Deployment 有两个副本集`replicas`\n\t```\n\t$ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP           NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2\n\tnginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3\n\tnginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2\n\t```\n\t到`host-2`和`host-3`的请求将被转发到 `NGINX`并且原始的客户端IP将被保留，但是请求到`host-1`的`Node`的请求将被丢弃，因为在该`Node`上没有`NGINX`副本集。\n\t\n  - **Ingress status**\n    因为`NodePort`类型的`Service`没有按定义分配`LoadBalancerIP`，`NGINX Ingress controller`不会更新`Ingress`对象的状态。\n\t```\n\t$ kubectl get ingress\n    NAME           HOSTS               ADDRESS   PORTS\n    test-ingress   myapp.example.com             80\n\t```\n\t尽管没有负载均衡器为`NGINX Ingress Controller`提供公共IP地址，但可以通过设置`ingress-nginx Service`的`externalIPs`字段来强制所有管理的Ingress对象的状态更新。\n\t例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n\t```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n\t```\n\t可以编辑`ingress-nginx Service` 添加如下代码片段到到属性域`spec`中：\n\t```\n\t...\n\tspec:\n\t  externalIPs:\n\t  - 203.0.113.1\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n\t...\n\t```\n\t如此，将会在`Ingress`对象上生效：\n\t```\n\t$ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                               PORTS\n\ttest-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80\n\t```\n  - **Redirects**\n  > As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.\n   \n    由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。\n\t举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to www.domain, are generated without NodePort:\n\t```\n\t$ curl -D- http://myapp.example.com:30100\n\tHTTP/1.1 308 Permanent Redirect\n\tServer: nginx/1.15.2\n\tLocation: https://myapp.example.com/  #-> missing NodePort in HTTPS redirect\n\t```\n----\n - ##### Via the host network\n   在没有可用的外部负载均衡器的设置中，但不能使用`NodePorts`。还有一种方法就是，通过设置`ingress-nginx`的Pods使用**主机网络**，而不是专用的网络命名空间(`network namespace`)。该方案的好处就是，在没有额外的`NodePort Service`提供的外部网络转换情况下，`NGINX Ingress controller`可以直接绑定k8s的`Node`网络接口的端口80或443。\n   这可以通过配置Pods属性域`template.spec`的`hostNetwork`选项来实现：\n   ```\n   template:\n\t  spec:\n\t\thostNetwork: true\n   ```\n   注意：\n   启用此选项会将所有系统守护进程暴露给任何网络接口上的`NGINX Ingress Controller`，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。\n   例如：`nginx-ingress-controller`Deployment有两个副本集，`NGINX` PodsN继承其主机的IP地址，而不是内部 Pod IP\n   ```\n   $ kubectl get pod -o wide -n ingress-nginx\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n   ```\n   该部署方式的主要限制是：每个群集节点上只能安排一个`NGINX Ingress Controller` Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，\n   ```\n   $ kubectl -n ingress-nginx describe pod <unschedulable-nginx-ingress-controller-pod>\n\t...\n\tEvents:\n\t  Type     Reason            From               Message\n\t  ----     ------            ----               -------\n\t  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn't have free ports for the requested pod ports.\n   ```\n   确保仅创建可调度Pod的一种方法是将`NGINX Ingress Controller`部署为`DaemonSet`而不是传统的`Deployment`。\n   ![hostnetwork](/images/hostnetwork.jpg)\n   与NodePorts一样，这种方法有一些怪癖，重要的是要注意\n     - **DNS resolution**\n     如果Pods配置了`hostNetwork: true`属性，则不使用内部DNS解析器(`kube-dns`或`CoreDns`)，除非Pods的`spec.dnsPolicy`配置了`ClusterFirstWithHostNet`属性。\n\t \n     - **Ingress status**\n     由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认--publish-service标志不适用，并且所有Ingress对象的状态保持空白。\n\t ```\n\t $ kubectl get ingress\n\tNAME           HOSTS               ADDRESS   PORTS\n\ttest-ingress   myapp.example.com             80\n\t ```\n\t 相反，由于`bare-metal`Node通常没有`Extral IP`，因此必须启用`--report-node-internal-ip-address`，它将所有Ingress对象的状态设置为运行`NGINX Ingress Controller`的所有节点的内部IP地址。\n\t Given a nginx-ingress-controller DaemonSet composed of 2 replicas\n\t ```\n\t $ kubectl -n ingress-nginx get pod -o wide\n\tNAME                                       READY   STATUS    IP            NODE\n\tdefault-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2\n\tnginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3\n\tnginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2\n\t ```\n\t 控制器将其管理的所有Ingress对象的状态设置为以下值：\n\t ```\n\t $ kubectl get ingress -o wide\n\tNAME           HOSTS               ADDRESS                   PORTS\n\ttest-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80\n\t ```\n - ##### Using a self-provisioned edge\n   与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。\n   此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。\n   边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：\n   ![Using a self-provisioned edge](/images/user_edge.jpg)\n   根据官方Kubernetes文档的“服务”页面，`externalIPs`选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的`endpoints`。这些IP地址必须属于目标节点(target node)。\n   > 例如：一个集群中有三个`Node`，(`external IP`只是一个举例, 在大部分 bare-metal环境中该值是`<None>`)\n    ```\n\t$ kubectl describe node\n\tNAME     STATUS   ROLES    EXTERNAL-IP\n\thost-1   Ready    master   203.0.113.1\n\thost-2   Ready    node     203.0.113.2\n\thost-3   Ready    node     203.0.113.3\n    ```\n   and the following ingress-nginx NodePort Service\n   ```\n   $ kubectl -n ingress-nginx get svc\n   NAME                   TYPE        CLUSTER-IP     PORT(S)\n   ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP\n   ```\n   我们可以在`Service`的`spec.externalIPs`属性域中设置**externalIPs**, 则**NGINX**通过`NodePort`和`Service Port`变的可达：\n   ```\n   spec:\n\t  externalIPs:\n\t  - 203.0.113.2\n\t  - 203.0.113.3\n   ```\n   ```\n   $ curl -D- http://myapp.example.com:30100\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   $ curl -D- http://myapp.example.com\n   HTTP/1.1 200 OK\n   Server: nginx/1.15.2\n   ```\n   我们假设 `myapp.example.com` 域名解析成IP地址：203.0.113.2 和 203.0.113.3。\n\n\n\n","slug":"nginx-ingress-controller-introduct","published":1,"updated":"2019-03-25T08:37:21.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oz6001ot2xur8k3628j","content":"<h2 id=\"NGINX-Ingress-Controller\"><a href=\"#NGINX-Ingress-Controller\" class=\"headerlink\" title=\"NGINX Ingress Controller\"></a>NGINX Ingress Controller</h2><p>[TOC]</p>\n<h3 id=\"Bare-metal-considerations\"><a href=\"#Bare-metal-considerations\" class=\"headerlink\" title=\"Bare-metal considerations\"></a>Bare-metal considerations</h3><ul>\n<li>MetalLB<br><code>MetalLB</code>提供了一个不仅仅只有云服务商才可提供的在<code>kubernetes</code>集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。<br>本教程介绍使用<a href=\"https://metallb.universe.tf/tutorial/layer2/\" target=\"_blank\" rel=\"noopener\"> <strong>Layer 2 configuration mode</strong></a> <a href=\"https://metallb.universe.tf/\" target=\"_blank\" rel=\"noopener\"><strong>MetalLB</strong></a>和<code>NGINX Ingress controller</code>在集群中有公开访问的节点。在此模式下，一个节点吸引<code>ingress-nginx</code>服务IP的所有流量。<br><strong>MetalLB:Layer2</strong><br><img src=\"/images/metallb.jpg\" alt=\"MetalLB:Layer2\"><br>例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <none>)<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</none></li>\n</ul>\n<p>依照下方<code>yaml</code>文件创建<code>ComfigMap</code>, MetalLB获得池中其中一个IP地址的所有权，并相应地更新<code>ingress-nginx</code>服务的<code>loadBalancer IP</code>字段。.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: metallb-system</span><br><span class=\"line\">  name: config</span><br><span class=\"line\">data:</span><br><span class=\"line\">  config: |</span><br><span class=\"line\">    address-pools:</span><br><span class=\"line\">    - name: default</span><br><span class=\"line\">      protocol: layer2</span><br><span class=\"line\">      addresses:</span><br><span class=\"line\">      - 203.0.113.2-203.0.113.3</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP     10.0.64.249    &lt;none&gt;       80/TCP</span><br><span class=\"line\">ingress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li><h5 id=\"Over-a-NodePort-Service\"><a href=\"#Over-a-NodePort-Service\" class=\"headerlink\" title=\"Over a NodePort Service\"></a>Over a NodePort Service</h5><p>在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配<code>ingress-nginx service</code>的<code>Type</code>为<code>Nodeport</code>。<br><img src=\"/images/nodeport.jpg\" alt=\"Over a NodePort Service\"><br>例如：Given the NodePort 30100 allocated to the ingress-nginx Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get svc -n ingress-nginx</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP   10.0.64.249    80/TCP</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>其中一个<code>Node</code>节点的IP地址为203.0.113.2 (<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>客户端可通过<code>http://myapp.example.com:30100</code>与配置<code>host</code>:<code>myapp.example.com</code>的<code>Ingress</code>进行通信，<code>myapp.example.com</code> 子域解析为203.0.113.2地址。<br>这种方法还有一些应该注意的其他限制</p>\n<ul>\n<li><p><strong>Source IP address</strong><br>Services of type NodePort perform source address translation by default。这意味着：HTTP请求的<code>source IP</code>始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。<br>建议通过设置<code>ingress-nginx Service</code>的<code>spec.externalTrafficPolicy</code>的属性域为<code>local</code>（<a href=\"https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14\" target=\"_blank\" rel=\"noopener\">例如</a>），来保留<code>source IP</code></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"comment\"># this setting is t make sure the source IP address is preserved.</span></span><br><span class=\"line\"><span class=\"attr\">  externalTrafficPolicy:</span> <span class=\"string\">Local</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">LoadBalancer</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">  ports:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">http</span></span><br><span class=\"line\">\t<span class=\"attr\">port:</span> <span class=\"number\">80</span></span><br><span class=\"line\">\t<span class=\"attr\">targetPort:</span> <span class=\"string\">http</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>例如一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>nginx-ingress-controller的Deployment 有两个副本集<code>replicas</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP           NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2</span><br></pre></td></tr></table></figure>\n<p>到<code>host-2</code>和<code>host-3</code>的请求将被转发到 <code>NGINX</code>并且原始的客户端IP将被保留，但是请求到<code>host-1</code>的<code>Node</code>的请求将被丢弃，因为在该<code>Node</code>上没有<code>NGINX</code>副本集。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>因为<code>NodePort</code>类型的<code>Service</code>没有按定义分配<code>LoadBalancerIP</code>，<code>NGINX Ingress controller</code>不会更新<code>Ingress</code>对象的状态。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress</span><br><span class=\"line\">   NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">   test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>尽管没有负载均衡器为<code>NGINX Ingress Controller</code>提供公共IP地址，但可以通过设置<code>ingress-nginx Service</code>的<code>externalIPs</code>字段来强制所有管理的Ingress对象的状态更新。<br>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>可以编辑<code>ingress-nginx Service</code> 添加如下代码片段到到属性域<code>spec</code>中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  externalIPs:</span><br><span class=\"line\">  - 203.0.113.1</span><br><span class=\"line\">  - 203.0.113.2</span><br><span class=\"line\">  - 203.0.113.3</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>如此，将会在<code>Ingress</code>对象上生效：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                               PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>Redirects</strong></p>\n<blockquote>\n<p>As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.</p>\n</blockquote>\n<p>由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。<br>举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to <a href=\"http://www.domain\" target=\"_blank\" rel=\"noopener\">www.domain</a>, are generated without NodePort:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 308 Permanent Redirect</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">Location: https://myapp.example.com/  #-&gt; missing NodePort in HTTPS redirect</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h5 id=\"Via-the-host-network\"><a href=\"#Via-the-host-network\" class=\"headerlink\" title=\"Via the host network\"></a>Via the host network</h5><p>在没有可用的外部负载均衡器的设置中，但不能使用<code>NodePorts</code>。还有一种方法就是，通过设置<code>ingress-nginx</code>的Pods使用<strong>主机网络</strong>，而不是专用的网络命名空间(<code>network namespace</code>)。该方案的好处就是，在没有额外的<code>NodePort Service</code>提供的外部网络转换情况下，<code>NGINX Ingress controller</code>可以直接绑定k8s的<code>Node</code>网络接口的端口80或443。<br>这可以通过配置Pods属性域<code>template.spec</code>的<code>hostNetwork</code>选项来实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> template:</span><br><span class=\"line\"> spec:</span><br><span class=\"line\">hostNetwork: true</span><br></pre></td></tr></table></figure>\n<p>注意：<br>启用此选项会将所有系统守护进程暴露给任何网络接口上的<code>NGINX Ingress Controller</code>，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。<br>例如：<code>nginx-ingress-controller</code>Deployment有两个副本集，<code>NGINX</code> PodsN继承其主机的IP地址，而不是内部 Pod IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>该部署方式的主要限制是：每个群集节点上只能安排一个<code>NGINX Ingress Controller</code> Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl -n ingress-nginx describe pod &lt;unschedulable-nginx-ingress-controller-pod&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason            From               Message</span><br><span class=\"line\">  ----     ------            ----               -------</span><br><span class=\"line\">  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn&apos;t have free ports for the requested pod ports.</span><br></pre></td></tr></table></figure>\n<p>确保仅创建可调度Pod的一种方法是将<code>NGINX Ingress Controller</code>部署为<code>DaemonSet</code>而不是传统的<code>Deployment</code>。<br><img src=\"/images/hostnetwork.jpg\" alt=\"hostnetwork\"><br>与NodePorts一样，这种方法有一些怪癖，重要的是要注意</p>\n<ul>\n<li><p><strong>DNS resolution</strong><br>如果Pods配置了<code>hostNetwork: true</code>属性，则不使用内部DNS解析器(<code>kube-dns</code>或<code>CoreDns</code>)，除非Pods的<code>spec.dnsPolicy</code>配置了<code>ClusterFirstWithHostNet</code>属性。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认–publish-service标志不适用，并且所有Ingress对象的状态保持空白。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress</span><br><span class=\"line\">NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>相反，由于<code>bare-metal</code>Node通常没有<code>Extral IP</code>，因此必须启用<code>--report-node-internal-ip-address</code>，它将所有Ingress对象的状态设置为运行<code>NGINX Ingress Controller</code>的所有节点的内部IP地址。<br>Given a nginx-ingress-controller DaemonSet composed of 2 replicas</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl -n ingress-nginx get pod -o wide</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>控制器将其管理的所有Ingress对象的状态设置为以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><h5 id=\"Using-a-self-provisioned-edge\"><a href=\"#Using-a-self-provisioned-edge\" class=\"headerlink\" title=\"Using a self-provisioned edge\"></a>Using a self-provisioned edge</h5><p>与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。<br>此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。<br>边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：<br><img src=\"/images/user_edge.jpg\" alt=\"Using a self-provisioned edge\"><br>根据官方Kubernetes文档的“服务”页面，<code>externalIPs</code>选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的<code>endpoints</code>。这些IP地址必须属于目标节点(target node)。</p>\n<blockquote>\n<p>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>and the following ingress-nginx NodePort Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>我们可以在<code>Service</code>的<code>spec.externalIPs</code>属性域中设置<strong>externalIPs</strong>, 则<strong>NGINX</strong>通过<code>NodePort</code>和<code>Service Port</code>变的可达：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">externalIPs:</span><br><span class=\"line\">- 203.0.113.2</span><br><span class=\"line\">- 203.0.113.3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">$ curl -D- http://myapp.example.com</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br></pre></td></tr></table></figure>\n<p>我们假设 <code>myapp.example.com</code> 域名解析成IP地址：203.0.113.2 和 203.0.113.3。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"NGINX-Ingress-Controller\"><a href=\"#NGINX-Ingress-Controller\" class=\"headerlink\" title=\"NGINX Ingress Controller\"></a>NGINX Ingress Controller</h2><p>[TOC]</p>\n<h3 id=\"Bare-metal-considerations\"><a href=\"#Bare-metal-considerations\" class=\"headerlink\" title=\"Bare-metal considerations\"></a>Bare-metal considerations</h3><ul>\n<li>MetalLB<br><code>MetalLB</code>提供了一个不仅仅只有云服务商才可提供的在<code>kubernetes</code>集群上的网络负载均衡实现。有效地允许在任何集群中使用 LoadBalancer 服务。<br>本教程介绍使用<a href=\"https://metallb.universe.tf/tutorial/layer2/\" target=\"_blank\" rel=\"noopener\"> <strong>Layer 2 configuration mode</strong></a> <a href=\"https://metallb.universe.tf/\" target=\"_blank\" rel=\"noopener\"><strong>MetalLB</strong></a>和<code>NGINX Ingress controller</code>在集群中有公开访问的节点。在此模式下，一个节点吸引<code>ingress-nginx</code>服务IP的所有流量。<br><strong>MetalLB:Layer2</strong><br><img src=\"/images/metallb.jpg\" alt=\"MetalLB:Layer2\"><br>例如：Given the following 3-node Kubernetes cluster (the external IP is added as an example, in most bare-metal environments this value is <none>)<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</none></li>\n</ul>\n<p>依照下方<code>yaml</code>文件创建<code>ComfigMap</code>, MetalLB获得池中其中一个IP地址的所有权，并相应地更新<code>ingress-nginx</code>服务的<code>loadBalancer IP</code>字段。.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ConfigMap</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  namespace: metallb-system</span><br><span class=\"line\">  name: config</span><br><span class=\"line\">data:</span><br><span class=\"line\">  config: |</span><br><span class=\"line\">    address-pools:</span><br><span class=\"line\">    - name: default</span><br><span class=\"line\">      protocol: layer2</span><br><span class=\"line\">      addresses:</span><br><span class=\"line\">      - 203.0.113.2-203.0.113.3</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP     10.0.64.249    &lt;none&gt;       80/TCP</span><br><span class=\"line\">ingress-nginx          LoadBalancer  10.0.220.217   203.0.113.3  80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<hr>\n<ul>\n<li><h5 id=\"Over-a-NodePort-Service\"><a href=\"#Over-a-NodePort-Service\" class=\"headerlink\" title=\"Over a NodePort Service\"></a>Over a NodePort Service</h5><p>在该配置下，NGINX 容器与主机网络保持隔离。因此，它可以安全地绑定到任何端口，包括标准HTTP端口80和443.但是，由于容器命名空间隔离，位于群集网络外部的客户端（例如，在公共Internet上）无法直接通过端口80和443访问Ingress。因此，必须分配<code>ingress-nginx service</code>的<code>Type</code>为<code>Nodeport</code>。<br><img src=\"/images/nodeport.jpg\" alt=\"Over a NodePort Service\"><br>例如：Given the NodePort 30100 allocated to the ingress-nginx Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get svc -n ingress-nginx</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">default-http-backend   ClusterIP   10.0.64.249    80/TCP</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>其中一个<code>Node</code>节点的IP地址为203.0.113.2 (<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>客户端可通过<code>http://myapp.example.com:30100</code>与配置<code>host</code>:<code>myapp.example.com</code>的<code>Ingress</code>进行通信，<code>myapp.example.com</code> 子域解析为203.0.113.2地址。<br>这种方法还有一些应该注意的其他限制</p>\n<ul>\n<li><p><strong>Source IP address</strong><br>Services of type NodePort perform source address translation by default。这意味着：HTTP请求的<code>source IP</code>始终是从NGINX的角度接收请求的Kubernetes节点的IP地址。<br>建议通过设置<code>ingress-nginx Service</code>的<code>spec.externalTrafficPolicy</code>的属性域为<code>local</code>（<a href=\"https://github.com/kubernetes/ingress-nginx/blob/nginx-0.19.0/deploy/provider/aws/service-nlb.yaml#L12-L14\" target=\"_blank\" rel=\"noopener\">例如</a>），来保留<code>source IP</code></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">ingress-nginx</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"comment\"># this setting is t make sure the source IP address is preserved.</span></span><br><span class=\"line\"><span class=\"attr\">  externalTrafficPolicy:</span> <span class=\"string\">Local</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">LoadBalancer</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"attr\">  ports:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">http</span></span><br><span class=\"line\">\t<span class=\"attr\">port:</span> <span class=\"number\">80</span></span><br><span class=\"line\">\t<span class=\"attr\">targetPort:</span> <span class=\"string\">http</span></span><br><span class=\"line\">  <span class=\"string\">...</span></span><br></pre></td></tr></table></figure>\n<p>例如一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>nginx-ingress-controller的Deployment 有两个副本集<code>replicas</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP           NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1   host-2</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-8vvf8   1/1     Running   172.17.0.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-cf9ff8c96-pxsds   1/1     Running   172.17.1.4   host-2</span><br></pre></td></tr></table></figure>\n<p>到<code>host-2</code>和<code>host-3</code>的请求将被转发到 <code>NGINX</code>并且原始的客户端IP将被保留，但是请求到<code>host-1</code>的<code>Node</code>的请求将被丢弃，因为在该<code>Node</code>上没有<code>NGINX</code>副本集。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>因为<code>NodePort</code>类型的<code>Service</code>没有按定义分配<code>LoadBalancerIP</code>，<code>NGINX Ingress controller</code>不会更新<code>Ingress</code>对象的状态。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress</span><br><span class=\"line\">   NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">   test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>尽管没有负载均衡器为<code>NGINX Ingress Controller</code>提供公共IP地址，但可以通过设置<code>ingress-nginx Service</code>的<code>externalIPs</code>字段来强制所有管理的Ingress对象的状态更新。<br>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n<p>可以编辑<code>ingress-nginx Service</code> 添加如下代码片段到到属性域<code>spec</code>中：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  externalIPs:</span><br><span class=\"line\">  - 203.0.113.1</span><br><span class=\"line\">  - 203.0.113.2</span><br><span class=\"line\">  - 203.0.113.3</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>如此，将会在<code>Ingress</code>对象上生效：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                               PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.1,203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>Redirects</strong></p>\n<blockquote>\n<p>As NGINX is not aware of the port translation operated by the NodePort Service, backend applications are responsible for generating redirect URLs that take into account the URL used by external clients, including the NodePort.</p>\n</blockquote>\n<p>由于NGINX不知道NodePort服务运营的端口转换，后端应用程序负责生成考虑外部客户端（包括NodePort）使用的URL的重定向URL。<br>举例：Redirects generated by NGINX, for instance HTTP to HTTPS or domain to <a href=\"http://www.domain\" target=\"_blank\" rel=\"noopener\">www.domain</a>, are generated without NodePort:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 308 Permanent Redirect</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">Location: https://myapp.example.com/  #-&gt; missing NodePort in HTTPS redirect</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li><h5 id=\"Via-the-host-network\"><a href=\"#Via-the-host-network\" class=\"headerlink\" title=\"Via the host network\"></a>Via the host network</h5><p>在没有可用的外部负载均衡器的设置中，但不能使用<code>NodePorts</code>。还有一种方法就是，通过设置<code>ingress-nginx</code>的Pods使用<strong>主机网络</strong>，而不是专用的网络命名空间(<code>network namespace</code>)。该方案的好处就是，在没有额外的<code>NodePort Service</code>提供的外部网络转换情况下，<code>NGINX Ingress controller</code>可以直接绑定k8s的<code>Node</code>网络接口的端口80或443。<br>这可以通过配置Pods属性域<code>template.spec</code>的<code>hostNetwork</code>选项来实现：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> template:</span><br><span class=\"line\"> spec:</span><br><span class=\"line\">hostNetwork: true</span><br></pre></td></tr></table></figure>\n<p>注意：<br>启用此选项会将所有系统守护进程暴露给任何网络接口上的<code>NGINX Ingress Controller</code>，包括主机的环回地址。请仔细评估这可能对您系统的安全性产生的影响。<br>例如：<code>nginx-ingress-controller</code>Deployment有两个副本集，<code>NGINX</code> PodsN继承其主机的IP地址，而不是内部 Pod IP</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl get pod -o wide -n ingress-nginx</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>该部署方式的主要限制是：每个群集节点上只能安排一个<code>NGINX Ingress Controller</code> Pod，这是因为在同一网络接口上多次绑定同一个端口在技术上是不可能的。举例：因此方式导致的 Pods 不可调度，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  $ kubectl -n ingress-nginx describe pod &lt;unschedulable-nginx-ingress-controller-pod&gt;</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason            From               Message</span><br><span class=\"line\">  ----     ------            ----               -------</span><br><span class=\"line\">  Warning  FailedScheduling  default-scheduler  0/3 nodes are available: 3 node(s) didn&apos;t have free ports for the requested pod ports.</span><br></pre></td></tr></table></figure>\n<p>确保仅创建可调度Pod的一种方法是将<code>NGINX Ingress Controller</code>部署为<code>DaemonSet</code>而不是传统的<code>Deployment</code>。<br><img src=\"/images/hostnetwork.jpg\" alt=\"hostnetwork\"><br>与NodePorts一样，这种方法有一些怪癖，重要的是要注意</p>\n<ul>\n<li><p><strong>DNS resolution</strong><br>如果Pods配置了<code>hostNetwork: true</code>属性，则不使用内部DNS解析器(<code>kube-dns</code>或<code>CoreDns</code>)，除非Pods的<code>spec.dnsPolicy</code>配置了<code>ClusterFirstWithHostNet</code>属性。</p>\n</li>\n<li><p><strong>Ingress status</strong><br>由于在使用主机网络的配置中没有服务公开NGINX Ingress控制器，因此标准云设置中使用的默认–publish-service标志不适用，并且所有Ingress对象的状态保持空白。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress</span><br><span class=\"line\">NAME           HOSTS               ADDRESS   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com             80</span><br></pre></td></tr></table></figure>\n<p>相反，由于<code>bare-metal</code>Node通常没有<code>Extral IP</code>，因此必须启用<code>--report-node-internal-ip-address</code>，它将所有Ingress对象的状态设置为运行<code>NGINX Ingress Controller</code>的所有节点的内部IP地址。<br>Given a nginx-ingress-controller DaemonSet composed of 2 replicas</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl -n ingress-nginx get pod -o wide</span><br><span class=\"line\">NAME                                       READY   STATUS    IP            NODE</span><br><span class=\"line\">default-http-backend-7c5bc89cc9-p86md      1/1     Running   172.17.1.1    host-2</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-7lg6c   1/1     Running   203.0.113.3   host-3</span><br><span class=\"line\">nginx-ingress-controller-5b4cf5fc6-lzrls   1/1     Running   203.0.113.2   host-2</span><br></pre></td></tr></table></figure>\n<p>控制器将其管理的所有Ingress对象的状态设置为以下值：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> $ kubectl get ingress -o wide</span><br><span class=\"line\">NAME           HOSTS               ADDRESS                   PORTS</span><br><span class=\"line\">test-ingress   myapp.example.com   203.0.113.2,203.0.113.3   80</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><h5 id=\"Using-a-self-provisioned-edge\"><a href=\"#Using-a-self-provisioned-edge\" class=\"headerlink\" title=\"Using a self-provisioned edge\"></a>Using a self-provisioned edge</h5><p>与云环境类似，该部署方式需要边缘网络组件（edge network component ）为Kubernetes集群提供公共入口点。该边缘组件可以是硬件（例如供应商设备）或软件（例如HAproxy），并且通常由运营团队在Kubernetes范围之外进行管理。<br>此类部署基于上面在Over NodePort服务中描述的NodePort服务构建，但有一个显着区别：外部客户端不直接访问集群节点，只有边缘组件才能访问集群节点。这特别适用于没有节点具有公共IP地址的私有Kubernetes集群。<br>边缘网络外部，唯一的先决条件是专用一个公共IP地址，将所有HTTP流量转发到Kubernetes节点和/或主节点。 TCP端口80和443上的传入流量将转发到目标节点上的相应HTTP和HTTPS NodePort，如下图所示：<br><img src=\"/images/user_edge.jpg\" alt=\"Using a self-provisioned edge\"><br>根据官方Kubernetes文档的“服务”页面，<code>externalIPs</code>选项使kube-proxy将发送到任意IP地址和服务端口的流量路由到该服务的<code>endpoints</code>。这些IP地址必须属于目标节点(target node)。</p>\n<blockquote>\n<p>例如：一个集群中有三个<code>Node</code>，(<code>external IP</code>只是一个举例, 在大部分 bare-metal环境中该值是<code>&lt;None&gt;</code>)</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe node</span><br><span class=\"line\">NAME     STATUS   ROLES    EXTERNAL-IP</span><br><span class=\"line\">host-1   Ready    master   203.0.113.1</span><br><span class=\"line\">host-2   Ready    node     203.0.113.2</span><br><span class=\"line\">host-3   Ready    node     203.0.113.3</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>and the following ingress-nginx NodePort Service</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl -n ingress-nginx get svc</span><br><span class=\"line\">NAME                   TYPE        CLUSTER-IP     PORT(S)</span><br><span class=\"line\">ingress-nginx          NodePort    10.0.220.217   80:30100/TCP,443:30101/TCP</span><br></pre></td></tr></table></figure>\n<p>我们可以在<code>Service</code>的<code>spec.externalIPs</code>属性域中设置<strong>externalIPs</strong>, 则<strong>NGINX</strong>通过<code>NodePort</code>和<code>Service Port</code>变的可达：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">spec:</span><br><span class=\"line\">externalIPs:</span><br><span class=\"line\">- 203.0.113.2</span><br><span class=\"line\">- 203.0.113.3</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -D- http://myapp.example.com:30100</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br><span class=\"line\">$ curl -D- http://myapp.example.com</span><br><span class=\"line\">HTTP/1.1 200 OK</span><br><span class=\"line\">Server: nginx/1.15.2</span><br></pre></td></tr></table></figure>\n<p>我们假设 <code>myapp.example.com</code> 域名解析成IP地址：203.0.113.2 和 203.0.113.3。</p>\n</li>\n</ul>\n"},{"title":"gRPC教程—— gRPC 简单实现Server和Client","date":"2019-03-27T16:36:54.000Z","_content":"\n### 前言\n> 在[上篇教程](http://www.weshzhu.com/2019/03/26/grpc-introduction/) 简述了 `RPC` 和 `gRPC` 的概念，初步了解了 `gRPC` 的工作原理，这篇文章将使用 Python 语言对 `gRPC` 进行简单的实现。可以加深对 `gRPC` 概念的理解。\n\n本教程实验环境\n\n - OS: Centos7.4\n - Python: 2.7\n\n### 安装grocio工具\n\n假设已经安装了 `virtualenv` 工具，具体安装教程见 [ virtualenv 16.4.3 documentation](https://virtualenv.pypa.io/en/stable/installation/)。\n\n首先，创建 python 独立运行环境：\n\n```\n$ mkdir grpc_tutorial \n$ cd grpc_tutorial\n$ virtualenv venv\n$ source venv/bin/activate\n$ mkdir -p demo/client demo/server demo/protos demo/generate_src\n$ touch requirements.txt\n```\n\n然后，安装编译工具： `grpcio` 和 `grpcio-tools`：\n\n将如下内容添加到文本文件 requirements.txt 中，\n\n```\ngrpcio\ngrpcio-tools\n```\n\n使用 pip 安装\n\n```\npip install -r requirements.txt\n```\n\n完整的 gRPC service 包含三部分：\n \n - Proto File: 包含当前包的所有服务的定义。将用于生成 `gRPC` 服务器和客户端使用的`Stubs`。\n \n - gRPC Server: gRPC 服务，用于接收客户端发来的 request , 类似于HTTP Server\n \n - gRPC Client: gRPC 客户端，分布于各个主机中，用于访问远程 gRPC 服务器。从本质上讲，这使得 gRPC 调用就像在同一代码库本身中调用本机函数。\n\n\n### 编写 Proto 文件\n\n为 `gRPC` 服务创建一个 `proto` 文件：`digestor.proto`\n\n```\nsyntax = 'proto3';\n\n// You can ignore these for now\n//option java_multiple_files = true;\n//option java_package = \"example-digestor.resource.grpc.digestor\";\n//option java_outer_classname = \"DigestorProto\";\n//option objc_class_prefix = \"DIGEST\";\n\npackage digestor;\n\nservice Digestor{\n    // 定义一个 gRPC 服务方法， 在此也可以定义多个方法\n    // rpc DoSomething(ClassType1) returns (ClassType2) {};\n    rpc GetDigestor(DigestMessage) returns (DigestedMessage) {};\n}\n\n\nmessage DigestMessage{\n    string ToDigest = 1;\n}\n\nmessage DigestedMessage{\n    string Digested = 1;\n    bool WasDigest = 2;\n}\n\n```\n\n下面对上述 `proto file`进行详解:  \n\n该文件的第一行 `syntax = \"proto3\"` 声明了 `proto` 类型和方言。\n\n以上被注释的代码是Java的包定义，我们也需要为java生成存根（因为gRPC提供了多语言实现）。最后一行声明了gRPC包的名称。\n\n```\n// You can ignore these for now\n//option java_multiple_files = true;\n//option java_package = \"example-digestor.resource.grpc.digestor\";\n//option java_outer_classname = \"DigestorProto\";\n//option objc_class_prefix = \"DIGEST\";\npackage digestor;\n```\n\n\n下述代码声明了名称为 `Digestor` 的 `gRPC` 服务，该服务提供了一个方法 `GetDigest` 用于接收 `DigestMessage` 类型的消息，返回 `DigestedMessage` 类型的消息。也可以声明多个服务方法，用于处理不同的业务逻辑。\n\n对`GetDigest` 方法要使用的数据类型 `DigestMessage` 和 `DigestedMessage` 进行定义。其中 `DigestMessage` 数据结构包含了一个 `string` 类型的变量 `ToDigest`。 `DigestedMessage` 数据结构包含了 `string` 类型的变量 `Digested` 和 `bool` 类型的变量 `WasDigested` 。数字 `1` 和 `2` 表示了变量的顺序。\n\n\n```\nservice Digestor{\n    rpc GetDigest(DigestMessage) returns (DigestedMessage) {};\n}\nmessage DigestMessage{\n string ToDigest=1;\n}\n \nmessage DigestedMessage{\n string Digested=1;\n bool WasDigested=2;\n}\n```\n\n\n### 生成 Stubs \n\n通过 `proto` 文件 `digestor.proto` 生成 `gRPC Stubs`\n\n```\n$ cd demo/protos\n$ python -m grpc_tools.protoc --proto_path=. ./digestor.proto --grpc_python_out=../generate_src --python_out=../generate_src\n```\n\n该命令可以在目录 `generate_src` 生成两个文件：`digestor_pb2.py` 和 `digestor_pb2_grpc.py `。 后续编写 **服务端** 和 **客户端** 代码时，需要用到生成的 `Stubs`。\n\n`--proto_path`： 指定要搜索 proto 文件的目录。可指定多个目录, 目录将按顺序搜索。如果没有给出，则默认当前工作目录。\n`--python_out`: 生成的 python 源码。 在此例子中，生成的源码为 `digestor_pb2.py`\n`--grpc_python_out`: 生成的 python 源码。 在此例子中，生成的源码为 `digestor_pb2_grpc.py`\n\n具体 `grpc_tools.protoc` 参数，请使用 `python -m grpc_tools.protoc --help` 查看\n\n\n### 编写 gRPC 服务端代码\n\n创建一个 `digester_server.py` 文件：\n\n```\n#! /usr/bin/env python\n# -*- coding:utf-8 -*-\n# @Author: weshzhu\n# @Date: 2019-03-27 14-29\n# @FUNCTION: \nfrom concurrent.futures import ThreadPoolExecutor\nimport grpc\nimport time\nimport hashlib\nfrom demo.generate_src import digestor_pb2\nfrom demo.generate_src import digestor_pb2_grpc\n\n\nclass DigestorServicer(digestor_pb2_grpc.DigestorServicer):\n    \"\"\"\n    gRPC server for Digestor Service\n    digestor_pb2_grpc.DigestorServicer 类 根据 `digestor.proto` 文件声明的 `service Digestor`生成\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        self.server_port = 5001\n\n    def GetDigestor(self, request, context):\n        \"\"\"\n        重写digestor_pb2_grpc.DigestorServicer 方法 GetDigestor\n        :param request: 接收 请求参数\n        :param context: 上下文\n        :return: DigestedMessage类型\n        \"\"\"\n        tobeDigested = request.ToDigest\n        hasher = hashlib.sha256()\n        hasher.update(tobeDigested.encode())\n        digested = hasher.hexdigest()\n        print digested\n        # result 即为 digestor.proto 文件声明的DigestedMessage 类型\n        # 保证变量名称(Digested, WasDigest)与 DigestedMessage 声明的一致\n        result = {'Digested': digested, 'WasDigest': True}\n        return digestor_pb2.DigestedMessage(**result)\n\n    def start_server(self):\n        \"\"\"\n        start gRPC server and receive the clients witch will connect to it\n        :return:\n        \"\"\"\n        # 实例化 server 对象，接收指定大小的线程池\n        digestor_server = grpc.server(ThreadPoolExecutor(max_workers=5))\n\n        # 将服务添加到 server 对象中\n        digestor_pb2_grpc.add_DigestorServicer_to_server(DigestorServicer(), digestor_server)\n\n        # 绑定 server 到 端口号\n        digestor_server.add_insecure_port('[::]:{port}'.format(port=self.server_port))\n        # start the server\n        digestor_server.start()\n        print ('Digestor Server running ...')\n        try:\n            # need an infinite loop since the above\n            # code is non blocking, and if I don't do this\n            # the program will exit\n            while True:\n                time.sleep(60 * 60 * 60)\n        except KeyboardInterrupt:\n            digestor_server.stop(0)\n            print('Digestor Server Stopped ...')\n\n\nif __name__ == '__main__':\n    curr_server = DigestorServicer()\n    curr_server.start_server()\n\n\n```\n\n执行 `digester_server.py` 脚本，启动 gRPC 服务\n\n\n\n### 编写 gRPC 客户端代码\n\n在 demo/client中编写客户端脚本 `digestor_client.py` ，内容如下：\n\n```\n#! /usr/bin/env python\n# -*- coding:utf-8 -*-\n# @Author: zsd\n# @Email: zsd498537806@gmail.com\n# @Date: 2019-03-27 15-17\n# @FUNCTION: \nimport grpc\nfrom demo.generate_src import digestor_pb2_grpc\nfrom demo.generate_src import digestor_pb2\n\n\nclass DigestorClient(object):\n    def __init__(self):\n        self.server_host = 'localhost'\n        self.server_port = 5001\n\n        # 初始化一个 channel 用于建立client 和 server 之间的通信管道\n        self.channel = grpc.insecure_channel(\n            '{ip}:{port}'.format(ip=self.server_host, port=self.server_port))\n\n        # 绑定 client 到 gRPC server 的 channel\n        self.stub = digestor_pb2_grpc.DigestorStub(self.channel)\n\n    def get_digest(self, message):\n        # 实例化 DigestMessage 对象\n        to_digest_message = digestor_pb2.DigestMessage(ToDigest=message)\n        return self.stub.GetDigestor(to_digest_message)\n\n```\n\n该客户端在初始化函数中，建立了从 客户端 到 服务端 的连接， 直接执行 `get_digest` 方法即可调用 `gRPC` 服务端的方法 `GetDigestor`。\n\n\n### 测试\n\n在不同的 Terminal 分别执行执行 `digestor_server` 和 `digestor_client`\n\nserver 端\n```\n$ python\n\n>>> from demo.server import digestor_server\n>>> Digestor_server = digestor_server.DigestorServicer()\n>>> digestor_server = digestor_server.DigestorServicer()\n>>> digestor_server.start_server()\nDigestor Server running ...\n532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25\n```\n\nclient端\n\n```\n$ python\n>>> from demo.client.digestor_client import DigestorClient\n>>> digestor_client = DigestorClient()\n>>> digestor_client.get_digest('Test')\nDigested: \"532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25\"\nWasDigest: true\n```\n\n可以看到，服务端接收客户端的请求数据，并将处理结果返回给客户端。对于客户端来说，仅仅调用本地的 `get_digest` 方法。\n\n本文涉及的源码请访问 [github-grpc_tutorial](https://github.com/DemonZSD/grpc_tutorial)\n\n### 总结\n\n使用 `Simple gRPC` 有以下不足：\n - 在数据包过大时，会对 client 和 server 端造成压力。\n - 服务端接收数据包时，在数据包完全接收完成后，才能响应给客户端，并无法一边接收客户端的请求数据，一边响应给客户端。\n\n后续章节将继续介绍 [基于 Stream 的 gRPC](https://segmentfault.com/a/1190000016503114)。\n\n\n\n### 参考链接\n\n - [Writing your first gRPC service in Python](https://technokeeda.com/programming/grpc-python-tutorial/)\n - [官方文档](https://grpc.io/docs/guides/)\n\n\n","source":"_posts/2019-03-27-first-grpc-example.md","raw":"---\ntitle: gRPC教程—— gRPC 简单实现Server和Client\ndate: 2019-03-27 16:36:54\ntags:\n  - gRPC\ncategories:\n  - gRPC\n---\n\n### 前言\n> 在[上篇教程](http://www.weshzhu.com/2019/03/26/grpc-introduction/) 简述了 `RPC` 和 `gRPC` 的概念，初步了解了 `gRPC` 的工作原理，这篇文章将使用 Python 语言对 `gRPC` 进行简单的实现。可以加深对 `gRPC` 概念的理解。\n\n本教程实验环境\n\n - OS: Centos7.4\n - Python: 2.7\n\n### 安装grocio工具\n\n假设已经安装了 `virtualenv` 工具，具体安装教程见 [ virtualenv 16.4.3 documentation](https://virtualenv.pypa.io/en/stable/installation/)。\n\n首先，创建 python 独立运行环境：\n\n```\n$ mkdir grpc_tutorial \n$ cd grpc_tutorial\n$ virtualenv venv\n$ source venv/bin/activate\n$ mkdir -p demo/client demo/server demo/protos demo/generate_src\n$ touch requirements.txt\n```\n\n然后，安装编译工具： `grpcio` 和 `grpcio-tools`：\n\n将如下内容添加到文本文件 requirements.txt 中，\n\n```\ngrpcio\ngrpcio-tools\n```\n\n使用 pip 安装\n\n```\npip install -r requirements.txt\n```\n\n完整的 gRPC service 包含三部分：\n \n - Proto File: 包含当前包的所有服务的定义。将用于生成 `gRPC` 服务器和客户端使用的`Stubs`。\n \n - gRPC Server: gRPC 服务，用于接收客户端发来的 request , 类似于HTTP Server\n \n - gRPC Client: gRPC 客户端，分布于各个主机中，用于访问远程 gRPC 服务器。从本质上讲，这使得 gRPC 调用就像在同一代码库本身中调用本机函数。\n\n\n### 编写 Proto 文件\n\n为 `gRPC` 服务创建一个 `proto` 文件：`digestor.proto`\n\n```\nsyntax = 'proto3';\n\n// You can ignore these for now\n//option java_multiple_files = true;\n//option java_package = \"example-digestor.resource.grpc.digestor\";\n//option java_outer_classname = \"DigestorProto\";\n//option objc_class_prefix = \"DIGEST\";\n\npackage digestor;\n\nservice Digestor{\n    // 定义一个 gRPC 服务方法， 在此也可以定义多个方法\n    // rpc DoSomething(ClassType1) returns (ClassType2) {};\n    rpc GetDigestor(DigestMessage) returns (DigestedMessage) {};\n}\n\n\nmessage DigestMessage{\n    string ToDigest = 1;\n}\n\nmessage DigestedMessage{\n    string Digested = 1;\n    bool WasDigest = 2;\n}\n\n```\n\n下面对上述 `proto file`进行详解:  \n\n该文件的第一行 `syntax = \"proto3\"` 声明了 `proto` 类型和方言。\n\n以上被注释的代码是Java的包定义，我们也需要为java生成存根（因为gRPC提供了多语言实现）。最后一行声明了gRPC包的名称。\n\n```\n// You can ignore these for now\n//option java_multiple_files = true;\n//option java_package = \"example-digestor.resource.grpc.digestor\";\n//option java_outer_classname = \"DigestorProto\";\n//option objc_class_prefix = \"DIGEST\";\npackage digestor;\n```\n\n\n下述代码声明了名称为 `Digestor` 的 `gRPC` 服务，该服务提供了一个方法 `GetDigest` 用于接收 `DigestMessage` 类型的消息，返回 `DigestedMessage` 类型的消息。也可以声明多个服务方法，用于处理不同的业务逻辑。\n\n对`GetDigest` 方法要使用的数据类型 `DigestMessage` 和 `DigestedMessage` 进行定义。其中 `DigestMessage` 数据结构包含了一个 `string` 类型的变量 `ToDigest`。 `DigestedMessage` 数据结构包含了 `string` 类型的变量 `Digested` 和 `bool` 类型的变量 `WasDigested` 。数字 `1` 和 `2` 表示了变量的顺序。\n\n\n```\nservice Digestor{\n    rpc GetDigest(DigestMessage) returns (DigestedMessage) {};\n}\nmessage DigestMessage{\n string ToDigest=1;\n}\n \nmessage DigestedMessage{\n string Digested=1;\n bool WasDigested=2;\n}\n```\n\n\n### 生成 Stubs \n\n通过 `proto` 文件 `digestor.proto` 生成 `gRPC Stubs`\n\n```\n$ cd demo/protos\n$ python -m grpc_tools.protoc --proto_path=. ./digestor.proto --grpc_python_out=../generate_src --python_out=../generate_src\n```\n\n该命令可以在目录 `generate_src` 生成两个文件：`digestor_pb2.py` 和 `digestor_pb2_grpc.py `。 后续编写 **服务端** 和 **客户端** 代码时，需要用到生成的 `Stubs`。\n\n`--proto_path`： 指定要搜索 proto 文件的目录。可指定多个目录, 目录将按顺序搜索。如果没有给出，则默认当前工作目录。\n`--python_out`: 生成的 python 源码。 在此例子中，生成的源码为 `digestor_pb2.py`\n`--grpc_python_out`: 生成的 python 源码。 在此例子中，生成的源码为 `digestor_pb2_grpc.py`\n\n具体 `grpc_tools.protoc` 参数，请使用 `python -m grpc_tools.protoc --help` 查看\n\n\n### 编写 gRPC 服务端代码\n\n创建一个 `digester_server.py` 文件：\n\n```\n#! /usr/bin/env python\n# -*- coding:utf-8 -*-\n# @Author: weshzhu\n# @Date: 2019-03-27 14-29\n# @FUNCTION: \nfrom concurrent.futures import ThreadPoolExecutor\nimport grpc\nimport time\nimport hashlib\nfrom demo.generate_src import digestor_pb2\nfrom demo.generate_src import digestor_pb2_grpc\n\n\nclass DigestorServicer(digestor_pb2_grpc.DigestorServicer):\n    \"\"\"\n    gRPC server for Digestor Service\n    digestor_pb2_grpc.DigestorServicer 类 根据 `digestor.proto` 文件声明的 `service Digestor`生成\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        self.server_port = 5001\n\n    def GetDigestor(self, request, context):\n        \"\"\"\n        重写digestor_pb2_grpc.DigestorServicer 方法 GetDigestor\n        :param request: 接收 请求参数\n        :param context: 上下文\n        :return: DigestedMessage类型\n        \"\"\"\n        tobeDigested = request.ToDigest\n        hasher = hashlib.sha256()\n        hasher.update(tobeDigested.encode())\n        digested = hasher.hexdigest()\n        print digested\n        # result 即为 digestor.proto 文件声明的DigestedMessage 类型\n        # 保证变量名称(Digested, WasDigest)与 DigestedMessage 声明的一致\n        result = {'Digested': digested, 'WasDigest': True}\n        return digestor_pb2.DigestedMessage(**result)\n\n    def start_server(self):\n        \"\"\"\n        start gRPC server and receive the clients witch will connect to it\n        :return:\n        \"\"\"\n        # 实例化 server 对象，接收指定大小的线程池\n        digestor_server = grpc.server(ThreadPoolExecutor(max_workers=5))\n\n        # 将服务添加到 server 对象中\n        digestor_pb2_grpc.add_DigestorServicer_to_server(DigestorServicer(), digestor_server)\n\n        # 绑定 server 到 端口号\n        digestor_server.add_insecure_port('[::]:{port}'.format(port=self.server_port))\n        # start the server\n        digestor_server.start()\n        print ('Digestor Server running ...')\n        try:\n            # need an infinite loop since the above\n            # code is non blocking, and if I don't do this\n            # the program will exit\n            while True:\n                time.sleep(60 * 60 * 60)\n        except KeyboardInterrupt:\n            digestor_server.stop(0)\n            print('Digestor Server Stopped ...')\n\n\nif __name__ == '__main__':\n    curr_server = DigestorServicer()\n    curr_server.start_server()\n\n\n```\n\n执行 `digester_server.py` 脚本，启动 gRPC 服务\n\n\n\n### 编写 gRPC 客户端代码\n\n在 demo/client中编写客户端脚本 `digestor_client.py` ，内容如下：\n\n```\n#! /usr/bin/env python\n# -*- coding:utf-8 -*-\n# @Author: zsd\n# @Email: zsd498537806@gmail.com\n# @Date: 2019-03-27 15-17\n# @FUNCTION: \nimport grpc\nfrom demo.generate_src import digestor_pb2_grpc\nfrom demo.generate_src import digestor_pb2\n\n\nclass DigestorClient(object):\n    def __init__(self):\n        self.server_host = 'localhost'\n        self.server_port = 5001\n\n        # 初始化一个 channel 用于建立client 和 server 之间的通信管道\n        self.channel = grpc.insecure_channel(\n            '{ip}:{port}'.format(ip=self.server_host, port=self.server_port))\n\n        # 绑定 client 到 gRPC server 的 channel\n        self.stub = digestor_pb2_grpc.DigestorStub(self.channel)\n\n    def get_digest(self, message):\n        # 实例化 DigestMessage 对象\n        to_digest_message = digestor_pb2.DigestMessage(ToDigest=message)\n        return self.stub.GetDigestor(to_digest_message)\n\n```\n\n该客户端在初始化函数中，建立了从 客户端 到 服务端 的连接， 直接执行 `get_digest` 方法即可调用 `gRPC` 服务端的方法 `GetDigestor`。\n\n\n### 测试\n\n在不同的 Terminal 分别执行执行 `digestor_server` 和 `digestor_client`\n\nserver 端\n```\n$ python\n\n>>> from demo.server import digestor_server\n>>> Digestor_server = digestor_server.DigestorServicer()\n>>> digestor_server = digestor_server.DigestorServicer()\n>>> digestor_server.start_server()\nDigestor Server running ...\n532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25\n```\n\nclient端\n\n```\n$ python\n>>> from demo.client.digestor_client import DigestorClient\n>>> digestor_client = DigestorClient()\n>>> digestor_client.get_digest('Test')\nDigested: \"532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25\"\nWasDigest: true\n```\n\n可以看到，服务端接收客户端的请求数据，并将处理结果返回给客户端。对于客户端来说，仅仅调用本地的 `get_digest` 方法。\n\n本文涉及的源码请访问 [github-grpc_tutorial](https://github.com/DemonZSD/grpc_tutorial)\n\n### 总结\n\n使用 `Simple gRPC` 有以下不足：\n - 在数据包过大时，会对 client 和 server 端造成压力。\n - 服务端接收数据包时，在数据包完全接收完成后，才能响应给客户端，并无法一边接收客户端的请求数据，一边响应给客户端。\n\n后续章节将继续介绍 [基于 Stream 的 gRPC](https://segmentfault.com/a/1190000016503114)。\n\n\n\n### 参考链接\n\n - [Writing your first gRPC service in Python](https://technokeeda.com/programming/grpc-python-tutorial/)\n - [官方文档](https://grpc.io/docs/guides/)\n\n\n","slug":"first-grpc-example","published":1,"updated":"2019-03-27T08:58:42.035Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09oz7001rt2xuhl7emx4g","content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><blockquote>\n<p>在<a href=\"http://www.weshzhu.com/2019/03/26/grpc-introduction/\" target=\"_blank\" rel=\"noopener\">上篇教程</a> 简述了 <code>RPC</code> 和 <code>gRPC</code> 的概念，初步了解了 <code>gRPC</code> 的工作原理，这篇文章将使用 Python 语言对 <code>gRPC</code> 进行简单的实现。可以加深对 <code>gRPC</code> 概念的理解。</p>\n</blockquote>\n<p>本教程实验环境</p>\n<ul>\n<li>OS: Centos7.4</li>\n<li>Python: 2.7</li>\n</ul>\n<h3 id=\"安装grocio工具\"><a href=\"#安装grocio工具\" class=\"headerlink\" title=\"安装grocio工具\"></a>安装grocio工具</h3><p>假设已经安装了 <code>virtualenv</code> 工具，具体安装教程见 <a href=\"https://virtualenv.pypa.io/en/stable/installation/\" target=\"_blank\" rel=\"noopener\"> virtualenv 16.4.3 documentation</a>。</p>\n<p>首先，创建 python 独立运行环境：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir grpc_tutorial </span><br><span class=\"line\">$ cd grpc_tutorial</span><br><span class=\"line\">$ virtualenv venv</span><br><span class=\"line\">$ source venv/bin/activate</span><br><span class=\"line\">$ mkdir -p demo/client demo/server demo/protos demo/generate_src</span><br><span class=\"line\">$ touch requirements.txt</span><br></pre></td></tr></table></figure>\n<p>然后，安装编译工具： <code>grpcio</code> 和 <code>grpcio-tools</code>：</p>\n<p>将如下内容添加到文本文件 requirements.txt 中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grpcio</span><br><span class=\"line\">grpcio-tools</span><br></pre></td></tr></table></figure>\n<p>使用 pip 安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n<p>完整的 gRPC service 包含三部分：</p>\n<ul>\n<li><p>Proto File: 包含当前包的所有服务的定义。将用于生成 <code>gRPC</code> 服务器和客户端使用的<code>Stubs</code>。</p>\n</li>\n<li><p>gRPC Server: gRPC 服务，用于接收客户端发来的 request , 类似于HTTP Server</p>\n</li>\n<li><p>gRPC Client: gRPC 客户端，分布于各个主机中，用于访问远程 gRPC 服务器。从本质上讲，这使得 gRPC 调用就像在同一代码库本身中调用本机函数。</p>\n</li>\n</ul>\n<h3 id=\"编写-Proto-文件\"><a href=\"#编写-Proto-文件\" class=\"headerlink\" title=\"编写 Proto 文件\"></a>编写 Proto 文件</h3><p>为 <code>gRPC</code> 服务创建一个 <code>proto</code> 文件：<code>digestor.proto</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syntax = &apos;proto3&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">// You can ignore these for now</span><br><span class=\"line\">//option java_multiple_files = true;</span><br><span class=\"line\">//option java_package = &quot;example-digestor.resource.grpc.digestor&quot;;</span><br><span class=\"line\">//option java_outer_classname = &quot;DigestorProto&quot;;</span><br><span class=\"line\">//option objc_class_prefix = &quot;DIGEST&quot;;</span><br><span class=\"line\"></span><br><span class=\"line\">package digestor;</span><br><span class=\"line\"></span><br><span class=\"line\">service Digestor&#123;</span><br><span class=\"line\">    // 定义一个 gRPC 服务方法， 在此也可以定义多个方法</span><br><span class=\"line\">    // rpc DoSomething(ClassType1) returns (ClassType2) &#123;&#125;;</span><br><span class=\"line\">    rpc GetDigestor(DigestMessage) returns (DigestedMessage) &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">message DigestMessage&#123;</span><br><span class=\"line\">    string ToDigest = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">message DigestedMessage&#123;</span><br><span class=\"line\">    string Digested = 1;</span><br><span class=\"line\">    bool WasDigest = 2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>下面对上述 <code>proto file</code>进行详解:  </p>\n<p>该文件的第一行 <code>syntax = &quot;proto3&quot;</code> 声明了 <code>proto</code> 类型和方言。</p>\n<p>以上被注释的代码是Java的包定义，我们也需要为java生成存根（因为gRPC提供了多语言实现）。最后一行声明了gRPC包的名称。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// You can ignore these for now</span><br><span class=\"line\">//option java_multiple_files = true;</span><br><span class=\"line\">//option java_package = &quot;example-digestor.resource.grpc.digestor&quot;;</span><br><span class=\"line\">//option java_outer_classname = &quot;DigestorProto&quot;;</span><br><span class=\"line\">//option objc_class_prefix = &quot;DIGEST&quot;;</span><br><span class=\"line\">package digestor;</span><br></pre></td></tr></table></figure>\n<p>下述代码声明了名称为 <code>Digestor</code> 的 <code>gRPC</code> 服务，该服务提供了一个方法 <code>GetDigest</code> 用于接收 <code>DigestMessage</code> 类型的消息，返回 <code>DigestedMessage</code> 类型的消息。也可以声明多个服务方法，用于处理不同的业务逻辑。</p>\n<p>对<code>GetDigest</code> 方法要使用的数据类型 <code>DigestMessage</code> 和 <code>DigestedMessage</code> 进行定义。其中 <code>DigestMessage</code> 数据结构包含了一个 <code>string</code> 类型的变量 <code>ToDigest</code>。 <code>DigestedMessage</code> 数据结构包含了 <code>string</code> 类型的变量 <code>Digested</code> 和 <code>bool</code> 类型的变量 <code>WasDigested</code> 。数字 <code>1</code> 和 <code>2</code> 表示了变量的顺序。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">service Digestor&#123;</span><br><span class=\"line\">    rpc GetDigest(DigestMessage) returns (DigestedMessage) &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">message DigestMessage&#123;</span><br><span class=\"line\"> string ToDigest=1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">message DigestedMessage&#123;</span><br><span class=\"line\"> string Digested=1;</span><br><span class=\"line\"> bool WasDigested=2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"生成-Stubs\"><a href=\"#生成-Stubs\" class=\"headerlink\" title=\"生成 Stubs\"></a>生成 Stubs</h3><p>通过 <code>proto</code> 文件 <code>digestor.proto</code> 生成 <code>gRPC Stubs</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd demo/protos</span><br><span class=\"line\">$ python -m grpc_tools.protoc --proto_path=. ./digestor.proto --grpc_python_out=../generate_src --python_out=../generate_src</span><br></pre></td></tr></table></figure>\n<p>该命令可以在目录 <code>generate_src</code> 生成两个文件：<code>digestor_pb2.py</code> 和 <code>digestor_pb2_grpc.py</code>。 后续编写 <strong>服务端</strong> 和 <strong>客户端</strong> 代码时，需要用到生成的 <code>Stubs</code>。</p>\n<p><code>--proto_path</code>： 指定要搜索 proto 文件的目录。可指定多个目录, 目录将按顺序搜索。如果没有给出，则默认当前工作目录。<br><code>--python_out</code>: 生成的 python 源码。 在此例子中，生成的源码为 <code>digestor_pb2.py</code><br><code>--grpc_python_out</code>: 生成的 python 源码。 在此例子中，生成的源码为 <code>digestor_pb2_grpc.py</code></p>\n<p>具体 <code>grpc_tools.protoc</code> 参数，请使用 <code>python -m grpc_tools.protoc --help</code> 查看</p>\n<h3 id=\"编写-gRPC-服务端代码\"><a href=\"#编写-gRPC-服务端代码\" class=\"headerlink\" title=\"编写 gRPC 服务端代码\"></a>编写 gRPC 服务端代码</h3><p>创建一个 <code>digester_server.py</code> 文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python</span><br><span class=\"line\"># -*- coding:utf-8 -*-</span><br><span class=\"line\"># @Author: weshzhu</span><br><span class=\"line\"># @Date: 2019-03-27 14-29</span><br><span class=\"line\"># @FUNCTION: </span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor</span><br><span class=\"line\">import grpc</span><br><span class=\"line\">import time</span><br><span class=\"line\">import hashlib</span><br><span class=\"line\">from demo.generate_src import digestor_pb2</span><br><span class=\"line\">from demo.generate_src import digestor_pb2_grpc</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class DigestorServicer(digestor_pb2_grpc.DigestorServicer):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    gRPC server for Digestor Service</span><br><span class=\"line\">    digestor_pb2_grpc.DigestorServicer 类 根据 `digestor.proto` 文件声明的 `service Digestor`生成</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    def __init__(self, *args, **kwargs):</span><br><span class=\"line\">        self.server_port = 5001</span><br><span class=\"line\"></span><br><span class=\"line\">    def GetDigestor(self, request, context):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        重写digestor_pb2_grpc.DigestorServicer 方法 GetDigestor</span><br><span class=\"line\">        :param request: 接收 请求参数</span><br><span class=\"line\">        :param context: 上下文</span><br><span class=\"line\">        :return: DigestedMessage类型</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        tobeDigested = request.ToDigest</span><br><span class=\"line\">        hasher = hashlib.sha256()</span><br><span class=\"line\">        hasher.update(tobeDigested.encode())</span><br><span class=\"line\">        digested = hasher.hexdigest()</span><br><span class=\"line\">        print digested</span><br><span class=\"line\">        # result 即为 digestor.proto 文件声明的DigestedMessage 类型</span><br><span class=\"line\">        # 保证变量名称(Digested, WasDigest)与 DigestedMessage 声明的一致</span><br><span class=\"line\">        result = &#123;&apos;Digested&apos;: digested, &apos;WasDigest&apos;: True&#125;</span><br><span class=\"line\">        return digestor_pb2.DigestedMessage(**result)</span><br><span class=\"line\"></span><br><span class=\"line\">    def start_server(self):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        start gRPC server and receive the clients witch will connect to it</span><br><span class=\"line\">        :return:</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        # 实例化 server 对象，接收指定大小的线程池</span><br><span class=\"line\">        digestor_server = grpc.server(ThreadPoolExecutor(max_workers=5))</span><br><span class=\"line\"></span><br><span class=\"line\">        # 将服务添加到 server 对象中</span><br><span class=\"line\">        digestor_pb2_grpc.add_DigestorServicer_to_server(DigestorServicer(), digestor_server)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 绑定 server 到 端口号</span><br><span class=\"line\">        digestor_server.add_insecure_port(&apos;[::]:&#123;port&#125;&apos;.format(port=self.server_port))</span><br><span class=\"line\">        # start the server</span><br><span class=\"line\">        digestor_server.start()</span><br><span class=\"line\">        print (&apos;Digestor Server running ...&apos;)</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            # need an infinite loop since the above</span><br><span class=\"line\">            # code is non blocking, and if I don&apos;t do this</span><br><span class=\"line\">            # the program will exit</span><br><span class=\"line\">            while True:</span><br><span class=\"line\">                time.sleep(60 * 60 * 60)</span><br><span class=\"line\">        except KeyboardInterrupt:</span><br><span class=\"line\">            digestor_server.stop(0)</span><br><span class=\"line\">            print(&apos;Digestor Server Stopped ...&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &apos;__main__&apos;:</span><br><span class=\"line\">    curr_server = DigestorServicer()</span><br><span class=\"line\">    curr_server.start_server()</span><br></pre></td></tr></table></figure>\n<p>执行 <code>digester_server.py</code> 脚本，启动 gRPC 服务</p>\n<h3 id=\"编写-gRPC-客户端代码\"><a href=\"#编写-gRPC-客户端代码\" class=\"headerlink\" title=\"编写 gRPC 客户端代码\"></a>编写 gRPC 客户端代码</h3><p>在 demo/client中编写客户端脚本 <code>digestor_client.py</code> ，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python</span><br><span class=\"line\"># -*- coding:utf-8 -*-</span><br><span class=\"line\"># @Author: zsd</span><br><span class=\"line\"># @Email: zsd498537806@gmail.com</span><br><span class=\"line\"># @Date: 2019-03-27 15-17</span><br><span class=\"line\"># @FUNCTION: </span><br><span class=\"line\">import grpc</span><br><span class=\"line\">from demo.generate_src import digestor_pb2_grpc</span><br><span class=\"line\">from demo.generate_src import digestor_pb2</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class DigestorClient(object):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        self.server_host = &apos;localhost&apos;</span><br><span class=\"line\">        self.server_port = 5001</span><br><span class=\"line\"></span><br><span class=\"line\">        # 初始化一个 channel 用于建立client 和 server 之间的通信管道</span><br><span class=\"line\">        self.channel = grpc.insecure_channel(</span><br><span class=\"line\">            &apos;&#123;ip&#125;:&#123;port&#125;&apos;.format(ip=self.server_host, port=self.server_port))</span><br><span class=\"line\"></span><br><span class=\"line\">        # 绑定 client 到 gRPC server 的 channel</span><br><span class=\"line\">        self.stub = digestor_pb2_grpc.DigestorStub(self.channel)</span><br><span class=\"line\"></span><br><span class=\"line\">    def get_digest(self, message):</span><br><span class=\"line\">        # 实例化 DigestMessage 对象</span><br><span class=\"line\">        to_digest_message = digestor_pb2.DigestMessage(ToDigest=message)</span><br><span class=\"line\">        return self.stub.GetDigestor(to_digest_message)</span><br></pre></td></tr></table></figure>\n<p>该客户端在初始化函数中，建立了从 客户端 到 服务端 的连接， 直接执行 <code>get_digest</code> 方法即可调用 <code>gRPC</code> 服务端的方法 <code>GetDigestor</code>。</p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><p>在不同的 Terminal 分别执行执行 <code>digestor_server</code> 和 <code>digestor_client</code></p>\n<p>server 端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; from demo.server import digestor_server</span><br><span class=\"line\">&gt;&gt;&gt; Digestor_server = digestor_server.DigestorServicer()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_server = digestor_server.DigestorServicer()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_server.start_server()</span><br><span class=\"line\">Digestor Server running ...</span><br><span class=\"line\">532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25</span><br></pre></td></tr></table></figure></p>\n<p>client端</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; from demo.client.digestor_client import DigestorClient</span><br><span class=\"line\">&gt;&gt;&gt; digestor_client = DigestorClient()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_client.get_digest(&apos;Test&apos;)</span><br><span class=\"line\">Digested: &quot;532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25&quot;</span><br><span class=\"line\">WasDigest: true</span><br></pre></td></tr></table></figure>\n<p>可以看到，服务端接收客户端的请求数据，并将处理结果返回给客户端。对于客户端来说，仅仅调用本地的 <code>get_digest</code> 方法。</p>\n<p>本文涉及的源码请访问 <a href=\"https://github.com/DemonZSD/grpc_tutorial\" target=\"_blank\" rel=\"noopener\">github-grpc_tutorial</a></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>使用 <code>Simple gRPC</code> 有以下不足：</p>\n<ul>\n<li>在数据包过大时，会对 client 和 server 端造成压力。</li>\n<li>服务端接收数据包时，在数据包完全接收完成后，才能响应给客户端，并无法一边接收客户端的请求数据，一边响应给客户端。</li>\n</ul>\n<p>后续章节将继续介绍 <a href=\"https://segmentfault.com/a/1190000016503114\" target=\"_blank\" rel=\"noopener\">基于 Stream 的 gRPC</a>。</p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h3><ul>\n<li><a href=\"https://technokeeda.com/programming/grpc-python-tutorial/\" target=\"_blank\" rel=\"noopener\">Writing your first gRPC service in Python</a></li>\n<li><a href=\"https://grpc.io/docs/guides/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><blockquote>\n<p>在<a href=\"http://www.weshzhu.com/2019/03/26/grpc-introduction/\" target=\"_blank\" rel=\"noopener\">上篇教程</a> 简述了 <code>RPC</code> 和 <code>gRPC</code> 的概念，初步了解了 <code>gRPC</code> 的工作原理，这篇文章将使用 Python 语言对 <code>gRPC</code> 进行简单的实现。可以加深对 <code>gRPC</code> 概念的理解。</p>\n</blockquote>\n<p>本教程实验环境</p>\n<ul>\n<li>OS: Centos7.4</li>\n<li>Python: 2.7</li>\n</ul>\n<h3 id=\"安装grocio工具\"><a href=\"#安装grocio工具\" class=\"headerlink\" title=\"安装grocio工具\"></a>安装grocio工具</h3><p>假设已经安装了 <code>virtualenv</code> 工具，具体安装教程见 <a href=\"https://virtualenv.pypa.io/en/stable/installation/\" target=\"_blank\" rel=\"noopener\"> virtualenv 16.4.3 documentation</a>。</p>\n<p>首先，创建 python 独立运行环境：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir grpc_tutorial </span><br><span class=\"line\">$ cd grpc_tutorial</span><br><span class=\"line\">$ virtualenv venv</span><br><span class=\"line\">$ source venv/bin/activate</span><br><span class=\"line\">$ mkdir -p demo/client demo/server demo/protos demo/generate_src</span><br><span class=\"line\">$ touch requirements.txt</span><br></pre></td></tr></table></figure>\n<p>然后，安装编译工具： <code>grpcio</code> 和 <code>grpcio-tools</code>：</p>\n<p>将如下内容添加到文本文件 requirements.txt 中，</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grpcio</span><br><span class=\"line\">grpcio-tools</span><br></pre></td></tr></table></figure>\n<p>使用 pip 安装</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>\n<p>完整的 gRPC service 包含三部分：</p>\n<ul>\n<li><p>Proto File: 包含当前包的所有服务的定义。将用于生成 <code>gRPC</code> 服务器和客户端使用的<code>Stubs</code>。</p>\n</li>\n<li><p>gRPC Server: gRPC 服务，用于接收客户端发来的 request , 类似于HTTP Server</p>\n</li>\n<li><p>gRPC Client: gRPC 客户端，分布于各个主机中，用于访问远程 gRPC 服务器。从本质上讲，这使得 gRPC 调用就像在同一代码库本身中调用本机函数。</p>\n</li>\n</ul>\n<h3 id=\"编写-Proto-文件\"><a href=\"#编写-Proto-文件\" class=\"headerlink\" title=\"编写 Proto 文件\"></a>编写 Proto 文件</h3><p>为 <code>gRPC</code> 服务创建一个 <code>proto</code> 文件：<code>digestor.proto</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">syntax = &apos;proto3&apos;;</span><br><span class=\"line\"></span><br><span class=\"line\">// You can ignore these for now</span><br><span class=\"line\">//option java_multiple_files = true;</span><br><span class=\"line\">//option java_package = &quot;example-digestor.resource.grpc.digestor&quot;;</span><br><span class=\"line\">//option java_outer_classname = &quot;DigestorProto&quot;;</span><br><span class=\"line\">//option objc_class_prefix = &quot;DIGEST&quot;;</span><br><span class=\"line\"></span><br><span class=\"line\">package digestor;</span><br><span class=\"line\"></span><br><span class=\"line\">service Digestor&#123;</span><br><span class=\"line\">    // 定义一个 gRPC 服务方法， 在此也可以定义多个方法</span><br><span class=\"line\">    // rpc DoSomething(ClassType1) returns (ClassType2) &#123;&#125;;</span><br><span class=\"line\">    rpc GetDigestor(DigestMessage) returns (DigestedMessage) &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">message DigestMessage&#123;</span><br><span class=\"line\">    string ToDigest = 1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">message DigestedMessage&#123;</span><br><span class=\"line\">    string Digested = 1;</span><br><span class=\"line\">    bool WasDigest = 2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>下面对上述 <code>proto file</code>进行详解:  </p>\n<p>该文件的第一行 <code>syntax = &quot;proto3&quot;</code> 声明了 <code>proto</code> 类型和方言。</p>\n<p>以上被注释的代码是Java的包定义，我们也需要为java生成存根（因为gRPC提供了多语言实现）。最后一行声明了gRPC包的名称。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// You can ignore these for now</span><br><span class=\"line\">//option java_multiple_files = true;</span><br><span class=\"line\">//option java_package = &quot;example-digestor.resource.grpc.digestor&quot;;</span><br><span class=\"line\">//option java_outer_classname = &quot;DigestorProto&quot;;</span><br><span class=\"line\">//option objc_class_prefix = &quot;DIGEST&quot;;</span><br><span class=\"line\">package digestor;</span><br></pre></td></tr></table></figure>\n<p>下述代码声明了名称为 <code>Digestor</code> 的 <code>gRPC</code> 服务，该服务提供了一个方法 <code>GetDigest</code> 用于接收 <code>DigestMessage</code> 类型的消息，返回 <code>DigestedMessage</code> 类型的消息。也可以声明多个服务方法，用于处理不同的业务逻辑。</p>\n<p>对<code>GetDigest</code> 方法要使用的数据类型 <code>DigestMessage</code> 和 <code>DigestedMessage</code> 进行定义。其中 <code>DigestMessage</code> 数据结构包含了一个 <code>string</code> 类型的变量 <code>ToDigest</code>。 <code>DigestedMessage</code> 数据结构包含了 <code>string</code> 类型的变量 <code>Digested</code> 和 <code>bool</code> 类型的变量 <code>WasDigested</code> 。数字 <code>1</code> 和 <code>2</code> 表示了变量的顺序。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">service Digestor&#123;</span><br><span class=\"line\">    rpc GetDigest(DigestMessage) returns (DigestedMessage) &#123;&#125;;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">message DigestMessage&#123;</span><br><span class=\"line\"> string ToDigest=1;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br><span class=\"line\">message DigestedMessage&#123;</span><br><span class=\"line\"> string Digested=1;</span><br><span class=\"line\"> bool WasDigested=2;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"生成-Stubs\"><a href=\"#生成-Stubs\" class=\"headerlink\" title=\"生成 Stubs\"></a>生成 Stubs</h3><p>通过 <code>proto</code> 文件 <code>digestor.proto</code> 生成 <code>gRPC Stubs</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cd demo/protos</span><br><span class=\"line\">$ python -m grpc_tools.protoc --proto_path=. ./digestor.proto --grpc_python_out=../generate_src --python_out=../generate_src</span><br></pre></td></tr></table></figure>\n<p>该命令可以在目录 <code>generate_src</code> 生成两个文件：<code>digestor_pb2.py</code> 和 <code>digestor_pb2_grpc.py</code>。 后续编写 <strong>服务端</strong> 和 <strong>客户端</strong> 代码时，需要用到生成的 <code>Stubs</code>。</p>\n<p><code>--proto_path</code>： 指定要搜索 proto 文件的目录。可指定多个目录, 目录将按顺序搜索。如果没有给出，则默认当前工作目录。<br><code>--python_out</code>: 生成的 python 源码。 在此例子中，生成的源码为 <code>digestor_pb2.py</code><br><code>--grpc_python_out</code>: 生成的 python 源码。 在此例子中，生成的源码为 <code>digestor_pb2_grpc.py</code></p>\n<p>具体 <code>grpc_tools.protoc</code> 参数，请使用 <code>python -m grpc_tools.protoc --help</code> 查看</p>\n<h3 id=\"编写-gRPC-服务端代码\"><a href=\"#编写-gRPC-服务端代码\" class=\"headerlink\" title=\"编写 gRPC 服务端代码\"></a>编写 gRPC 服务端代码</h3><p>创建一个 <code>digester_server.py</code> 文件：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python</span><br><span class=\"line\"># -*- coding:utf-8 -*-</span><br><span class=\"line\"># @Author: weshzhu</span><br><span class=\"line\"># @Date: 2019-03-27 14-29</span><br><span class=\"line\"># @FUNCTION: </span><br><span class=\"line\">from concurrent.futures import ThreadPoolExecutor</span><br><span class=\"line\">import grpc</span><br><span class=\"line\">import time</span><br><span class=\"line\">import hashlib</span><br><span class=\"line\">from demo.generate_src import digestor_pb2</span><br><span class=\"line\">from demo.generate_src import digestor_pb2_grpc</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class DigestorServicer(digestor_pb2_grpc.DigestorServicer):</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    gRPC server for Digestor Service</span><br><span class=\"line\">    digestor_pb2_grpc.DigestorServicer 类 根据 `digestor.proto` 文件声明的 `service Digestor`生成</span><br><span class=\"line\">    &quot;&quot;&quot;</span><br><span class=\"line\">    def __init__(self, *args, **kwargs):</span><br><span class=\"line\">        self.server_port = 5001</span><br><span class=\"line\"></span><br><span class=\"line\">    def GetDigestor(self, request, context):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        重写digestor_pb2_grpc.DigestorServicer 方法 GetDigestor</span><br><span class=\"line\">        :param request: 接收 请求参数</span><br><span class=\"line\">        :param context: 上下文</span><br><span class=\"line\">        :return: DigestedMessage类型</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        tobeDigested = request.ToDigest</span><br><span class=\"line\">        hasher = hashlib.sha256()</span><br><span class=\"line\">        hasher.update(tobeDigested.encode())</span><br><span class=\"line\">        digested = hasher.hexdigest()</span><br><span class=\"line\">        print digested</span><br><span class=\"line\">        # result 即为 digestor.proto 文件声明的DigestedMessage 类型</span><br><span class=\"line\">        # 保证变量名称(Digested, WasDigest)与 DigestedMessage 声明的一致</span><br><span class=\"line\">        result = &#123;&apos;Digested&apos;: digested, &apos;WasDigest&apos;: True&#125;</span><br><span class=\"line\">        return digestor_pb2.DigestedMessage(**result)</span><br><span class=\"line\"></span><br><span class=\"line\">    def start_server(self):</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        start gRPC server and receive the clients witch will connect to it</span><br><span class=\"line\">        :return:</span><br><span class=\"line\">        &quot;&quot;&quot;</span><br><span class=\"line\">        # 实例化 server 对象，接收指定大小的线程池</span><br><span class=\"line\">        digestor_server = grpc.server(ThreadPoolExecutor(max_workers=5))</span><br><span class=\"line\"></span><br><span class=\"line\">        # 将服务添加到 server 对象中</span><br><span class=\"line\">        digestor_pb2_grpc.add_DigestorServicer_to_server(DigestorServicer(), digestor_server)</span><br><span class=\"line\"></span><br><span class=\"line\">        # 绑定 server 到 端口号</span><br><span class=\"line\">        digestor_server.add_insecure_port(&apos;[::]:&#123;port&#125;&apos;.format(port=self.server_port))</span><br><span class=\"line\">        # start the server</span><br><span class=\"line\">        digestor_server.start()</span><br><span class=\"line\">        print (&apos;Digestor Server running ...&apos;)</span><br><span class=\"line\">        try:</span><br><span class=\"line\">            # need an infinite loop since the above</span><br><span class=\"line\">            # code is non blocking, and if I don&apos;t do this</span><br><span class=\"line\">            # the program will exit</span><br><span class=\"line\">            while True:</span><br><span class=\"line\">                time.sleep(60 * 60 * 60)</span><br><span class=\"line\">        except KeyboardInterrupt:</span><br><span class=\"line\">            digestor_server.stop(0)</span><br><span class=\"line\">            print(&apos;Digestor Server Stopped ...&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">if __name__ == &apos;__main__&apos;:</span><br><span class=\"line\">    curr_server = DigestorServicer()</span><br><span class=\"line\">    curr_server.start_server()</span><br></pre></td></tr></table></figure>\n<p>执行 <code>digester_server.py</code> 脚本，启动 gRPC 服务</p>\n<h3 id=\"编写-gRPC-客户端代码\"><a href=\"#编写-gRPC-客户端代码\" class=\"headerlink\" title=\"编写 gRPC 客户端代码\"></a>编写 gRPC 客户端代码</h3><p>在 demo/client中编写客户端脚本 <code>digestor_client.py</code> ，内容如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /usr/bin/env python</span><br><span class=\"line\"># -*- coding:utf-8 -*-</span><br><span class=\"line\"># @Author: zsd</span><br><span class=\"line\"># @Email: zsd498537806@gmail.com</span><br><span class=\"line\"># @Date: 2019-03-27 15-17</span><br><span class=\"line\"># @FUNCTION: </span><br><span class=\"line\">import grpc</span><br><span class=\"line\">from demo.generate_src import digestor_pb2_grpc</span><br><span class=\"line\">from demo.generate_src import digestor_pb2</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">class DigestorClient(object):</span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        self.server_host = &apos;localhost&apos;</span><br><span class=\"line\">        self.server_port = 5001</span><br><span class=\"line\"></span><br><span class=\"line\">        # 初始化一个 channel 用于建立client 和 server 之间的通信管道</span><br><span class=\"line\">        self.channel = grpc.insecure_channel(</span><br><span class=\"line\">            &apos;&#123;ip&#125;:&#123;port&#125;&apos;.format(ip=self.server_host, port=self.server_port))</span><br><span class=\"line\"></span><br><span class=\"line\">        # 绑定 client 到 gRPC server 的 channel</span><br><span class=\"line\">        self.stub = digestor_pb2_grpc.DigestorStub(self.channel)</span><br><span class=\"line\"></span><br><span class=\"line\">    def get_digest(self, message):</span><br><span class=\"line\">        # 实例化 DigestMessage 对象</span><br><span class=\"line\">        to_digest_message = digestor_pb2.DigestMessage(ToDigest=message)</span><br><span class=\"line\">        return self.stub.GetDigestor(to_digest_message)</span><br></pre></td></tr></table></figure>\n<p>该客户端在初始化函数中，建立了从 客户端 到 服务端 的连接， 直接执行 <code>get_digest</code> 方法即可调用 <code>gRPC</code> 服务端的方法 <code>GetDigestor</code>。</p>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><p>在不同的 Terminal 分别执行执行 <code>digestor_server</code> 和 <code>digestor_client</code></p>\n<p>server 端<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; from demo.server import digestor_server</span><br><span class=\"line\">&gt;&gt;&gt; Digestor_server = digestor_server.DigestorServicer()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_server = digestor_server.DigestorServicer()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_server.start_server()</span><br><span class=\"line\">Digestor Server running ...</span><br><span class=\"line\">532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25</span><br></pre></td></tr></table></figure></p>\n<p>client端</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; from demo.client.digestor_client import DigestorClient</span><br><span class=\"line\">&gt;&gt;&gt; digestor_client = DigestorClient()</span><br><span class=\"line\">&gt;&gt;&gt; digestor_client.get_digest(&apos;Test&apos;)</span><br><span class=\"line\">Digested: &quot;532eaabd9574880dbf76b9b8cc00832c20a6ec113d682299550d7a6e0f345e25&quot;</span><br><span class=\"line\">WasDigest: true</span><br></pre></td></tr></table></figure>\n<p>可以看到，服务端接收客户端的请求数据，并将处理结果返回给客户端。对于客户端来说，仅仅调用本地的 <code>get_digest</code> 方法。</p>\n<p>本文涉及的源码请访问 <a href=\"https://github.com/DemonZSD/grpc_tutorial\" target=\"_blank\" rel=\"noopener\">github-grpc_tutorial</a></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>使用 <code>Simple gRPC</code> 有以下不足：</p>\n<ul>\n<li>在数据包过大时，会对 client 和 server 端造成压力。</li>\n<li>服务端接收数据包时，在数据包完全接收完成后，才能响应给客户端，并无法一边接收客户端的请求数据，一边响应给客户端。</li>\n</ul>\n<p>后续章节将继续介绍 <a href=\"https://segmentfault.com/a/1190000016503114\" target=\"_blank\" rel=\"noopener\">基于 Stream 的 gRPC</a>。</p>\n<h3 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h3><ul>\n<li><a href=\"https://technokeeda.com/programming/grpc-python-tutorial/\" target=\"_blank\" rel=\"noopener\">Writing your first gRPC service in Python</a></li>\n<li><a href=\"https://grpc.io/docs/guides/\" target=\"_blank\" rel=\"noopener\">官方文档</a></li>\n</ul>\n"},{"title":"Fabric2.4 Tutorial","date":"2019-03-26T09:26:59.000Z","_content":"\n## Network\n\n### SSH连接网关\n#### 背景\n\n出于安全考虑，服务器经常会加一道防火墙，从而阻止从互联网直接访问服务器。如果需要连接防火墙内部的网络，通常是通过中间主机（被称为“跳转机”、“堡垒机”、“网关或代理”、“弹跳”）\n\n网关需要与网关系统建立初始/外部SSH连接，然后使用该连接作为到最终/内部主机的“真实”连接的传输。\n\n则可以通过 `ssh gatewayhost`去真正连接 `ssh internalhost `，这适用于长时间运行的会话。但在频繁进行时，会成为负担。\n\n\nFabric中有两种网关解决方案，可以反映OpenSSH客户端的功能：`ProxyJump`（更容易，更少开销，可以嵌套）; `ProxyCommand` （更多开销，不能嵌套，有时更灵活）。两者都支持通常的配置源：Fabric自己的配置框架，SSH配置文件或运行时参数\n\n##### `ProxyJump`\n\n这种类型的网关使用SSH协议的direct-tcpip通道类型 - 一种轻量级方法，用于请求网关的sshd开启一个到远程服务器的连接。\n\n`paramiko.channel.Channel` 实例实现了Python的 `socket` API，因此可用于代替几乎任何Python代码的实际操作系统套接字。\n\n`ProxyJump`类型的网关，使用简单：\n\n```\nfrom fabric import Connection\n\nc = Connection('internalhost', gateway=Connection('gatewayhost'))\n```\n\n该 `gateway` 连接(`Connection('gatewayhost')`)，需要配置 gatewayhost的登录用户名，端口号等等。\n\n\n##### `ProxyCommand`\n\n传统的OpenSSH命令行客户端长期提供了一个`ProxyCommand`指令（请参阅[man ssh_config](http://man.openbsd.org/ssh_config)），该指令通过任意本地子进程管理内部连接的输入和输出。\n\n与 `ProxyJump`类型的网关相比，这种方式增加了开销（额外的子进程），并且无法轻松嵌套。在数据传输中，它允许使用`SOCKS`代理或者自定义过滤等高级功能，相对来说更加灵活。\n\n`ProxyCommand`子进程通常是另一个ssh命令，例如`ssh -W ％h：％p gatewayhost`;或者（在缺少`-W`选项的SSH版本上）广泛使用的`netcat`，通过`ssh gatewayhost nc ％h％p`。\n\nFabric支持ProxyCommand接受gatewaykwarg中的命令字符串对象 Connection; 这用于paramiko.proxy.ProxyCommand在连接时填充 对象。\n\n\n\n#### 其他问题\n\n如果您不确定使用哪两种方法：使用`ProxyJump`方式。它性能更好，在本地系统上使用更少的资源，并且具有更易于使用的API。\n\n> **警告**\n> \n> 同时请求两种类型的网关到相同的主机（即，以`Connection`作为`gateway`的`kwarg`或`config`参数，并且加载包含配置文件`ProxyCommand`）将导致异常。\n\n---\n\n## Configuration\n\n### 基础\n\nFabric配置系统，主要依赖于Invoke功能（`invoke.config.Config`），严格来说是`invoke.config.Config`的子类 `fabric.config.Config`。\n\n俩类的主要区别：\n- 配置文件命名全部以fabric.\\*，而不是原来的invoke.\\*，  比如：`/etc/fabric.yml` 取代 `/etc/invoke.yml`, `~/.fabric.py` 取代 `~/.invoke.py`\n- Fabric在`invoke.config.Config`基础上，新增了其他的配置属性，比如：SSH默认连接端口为22\n- Fabric有加载SSH配置文件的特殊机制。并将根据每个`Connection`，自动创建或更新配置子树。并使用该特定主机的加载ssh配置。\n- Fabric提供一个Framework或者进行管理per-host或者per-host-connection配置。\n  - 该功能，将会补充所述的ssh配置加载的功能。我们预计大多数用户倾向于通过SSH配置文件来进行配置。\n\n\n\n\n### 配置默认值\n\n#### 重写Invoke-level\n\n- `run.replace_env: True`，在远程服务器执行的shell命令，将不会继承当前线程的环境变量。\n  \n  处于安全考虑：默认情况下远程泄漏本地环境数据是不推荐的。\n\n#### 扩展Invoke-level\n\n`runners.remote`:在Invoke中，`runner`拥有单独键：`local`(mapping to `Local`)，Fabric添加新的键`remote`（mapping to `Remote`）\n\n#### Fabric自定义默认值\n\n> **注意**\n> \n> 大部分所有的设置（settings）也适用于`Connection`\n\n\n> **警告**\n> 大部分的设置也可以通过ssh_config_files进行配置，这些值优先于通过核心配置进行配置的值，\n\n- `connect_kwargs`:\n\n  关键字参数，这是许多与ssh相关的选项的主要配置向量，例如选择私钥、切换ssh代理的转发等。默认值：`{}`。\n\n- `forward_agent`:\n\n  是否尝试将本地ssh身份验证代理转发到远程端。默认： `False`\n\n- `gateway`:\n\n  用作 `Connection` 对象的 `gateway` 属性的默认值，默认：`None`\n\n- `load_ssh_configs`:\n\n  是否自动搜索SSH配置文件，当值为`False`，不自动加载配置文件。默认：`True`\n\n- `port`:\n\n  TCP端口号，用于`Connection`对象的连接，默认:22\n\n- `inline_ssh_env`:\n\n  Boolean用作`Connection`的`inline-ssh-env`参数值的全局默认值；有关详细信息，请参阅其文档。默认值：false。\n\n- `ssh_config_path`:\n  \n  运行时（Runtime）SSH配置路径，默认：None\n\n- `timeouts`:\n\n  - `connection`：连接超时，以秒为单位；默认：`None`，表示永远没有`timeout/block`。\n\n- `user`:\n  \n  指定通过ssh连接的用户名，默认值使用本地主机的用户名\n\n\n### 加载并使用ssh_config文件\n\n#### 加载哪些文件\n\n**Fabric** 使用 **Paramiko** 的`SSH config`文件，加载并解析 `ssh_config`格式的文件\n\n - 已经被解析的 `SSHConfig` 对象，将会通过 `ssh_config` 关键字参数传给 `Config.__init__`。如果给定该值，则不再加载其他任何配置文件。\n - 运行时文件路径，通过`configuration `中的`ssh_config_path`进行设置，该路径将被`SSHConfig`对象加载。\n   \n   - 同 `fab` CLI 命令中的 `--ssh-config`\n\n - 如果 `Config.__init__` 没有运行时配置（包括对象或者路径），其会自动按顺序去搜索并加载 `~/.ssh/config and/`或 `/etc/ssh/ssh_config`\n - 如果上述都没有产生SSH配置数据，则空 `SSHConfig` 是最终结果\n\n - 无论对象是如何生成的，它都以 `Config.base_ssh_config` 形式公开。\n\n##### Connection使用ssh_config文件\n\n`Connection`对象将其配置的SSH数据（通过 `lookup` 获得）的每个主机“views”公开为`Connection.ssh_config`。 `Connection` 本身引用这些值，如以下小节所述，通常作为相应配置键或参数的简单默认值(例如：`port`, `forward_agent`)\n\n\n除非另有说明，否则这些值会覆盖相同键的常规配置值，但可能会被 `Connection.__ init__` 参数覆盖。\n\n比如：`~/.fabric.yaml`\n\n```\nuser: foo\n```\n\n如果没有任何其他配置，`Connection（'myhost'）`将作为 `foo` 用户连接。\n\n如果我们还有其他配置：`~/.ssh/config`\n\n```\nHost *\n    User bar\n```\n`Connection（'myhost'）`将作为 `bar` 用户连接。\n\n可见，`SSH config` 优先于`Fabric config`\n\n然而，`Connection（'myhost', user='biz'）`，将用`biz`用户进行连接。\n\n> **注意**\n> \n> 以下部分使用`ssh_config`键的大写版本以便更轻松地与`man ssh_config`进行关联，但实际的`SSHConfig`数据结构规范化为小写键，因为SSH配置文件在技术上不区分大小写。\n\n\n##### Connection参数\n\n- `Hostname` ：替换 `host` 的原始值（保留为`.original_host`。）\n- `Port`：提供 `port`  config 选项/参数的默认值。\n- `User`：提供 `user` config 选项/参数的默认值。\n- `ConnectTimeout` ：设置`timeouts.connect` config 选项/超时参数的默认值。\n\n\n##### 代理(Proxying)\n\n- `ProxyCommand` : 为`gateway`提供默认字符串值\n- `ProxyJump` : 为`gateway`提供默认`Connection`对象\n  - 嵌套式`ProxyJump`，即`user1@hop1.host，user2@hop2.host，...`，将导致一系列适当的嵌套`gateway`值 - 就好像用户手动指定了`Connecton(...，gateway) = Connection('user1@hop1.host'，gateway = Connection('user2@hop2.host'，gateway = ...)))`。\n\n> **注意**\n> \n> 如果为给定主机指定了两者，则`ProxyJump`将覆盖`ProxyCommand`。这与OpenSSH略有不同，OpenSSH指令的加载顺序决定了哪一个获胜。我们这样做（将配置视为字典结构）需要额外的工作。\n\n##### 认证（Authentication）\n\n- `ForwardAgent`: 控制`forward_agent`参数行为\n- `IdentityFile`: 追加 `connect_kwargs`字段 `key_filename`，类似于 `--identity`\n\n#### 禁用`ssh_config`加载\n\n需要更严格控制其环境配置方式的用户可能希望禁用系统/用户级SSH配置文件的自动加载；这可以防止难以预料的错误，例如新用户的 `~/.ssh/config` 覆盖在常规配置层次结构中设置的值。\n\n为此，只需将顶级配置选项 `load_ssh_configs` 设置为`False`即可。\n\n> **注意**\n> 更改此设置不会禁用运行时级别（`runtime-level`）配置文件的加载，如果用户明确指定加载哪个文件，我们则认为他们知道他们要干什么。\n\n\n---\n\n## connection\n\n```\nclass fabric.connection.Connection(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)¶\n```\n用于与ssh守护进程的连接，包含shell命令和文件传输。\n\n### 基础\n\n该类继承自`Invoke.context`，在该`context`中，可以进行命令、任务（task）操作。该类封装了Paramiko `SSHClient`实例，通过该类生成的`sshclient`和`channel`实例执行的高级操作。\n\n> **注意**\n> \n> 特定于SSH的选项——例如指定密钥（private key）和密码口令（passphrases）、timeouts、禁用SSH代理等，可通过构造函数的`connect_kwargs`参数指定，由paramiko直接处理。\n> \n> \n>     c = connection(host='localhost',user='root', connect_kwargs={'passwrd':'123456'}\n\n\n\n\n### 生命周期\n\n`Connection`有`create, connect/open, do work, disconnect/close`生命周期。\n\n- `Instantiation `持久影响对象连接参数。但并不真正建立连接。\n  - 可选的构造方式：[upgrading piecemeal from Fabric 1](http://www.fabfile.org/upgrading.html#from-v1) `from_v1(env)`\n- `run`、`get` 等方法会自动触发`connection`的`open`，用户也可手动执行`open`\n- `Connection`无需手动关闭。大部分情况下连接的关闭操作交给Paramiko的**垃圾回收钩子**或者python自带的关闭序列。当然也有特殊情况（当退出时，session挂起），此时需要手动进行关闭(close)。\n\n  这可以通过手动调用`Close`或借助`with`用作ContextManager来完成：\n  \n  ```\n  with Connection('host') as c:\n    c.run('command')\n    c.put('file')\n  ```\n\n> Note\n> \n> 该类将`invoke.context.Context.run`方法重新绑定到`local`方法，远程命令和本地命令均可执行。\n\n### Configuration\n\n大部分的`Connection`参数，遵循[` Invoke-style configuration`](http://docs.fabfile.org/en/2.4/concepts/configuration.html)和[`SSH Config`](http://docs.fabfile.org/en/2.4/concepts/configuration.html#connection-ssh-config)。例如连接到远程机器` admin@myhost`，可以使用下述方法进行连接：\n- 使用`build-in`配置机制，比如` /etc/fabric.yml, ~/.fabric.json`，`user: admin` ( 或`{\"user\": \"admin\"}`)。这样，`Connection('myhost')`就可以通过用户为`admin`进行连接。\n- 在任何适用的`Host`开头（`Host myhost`、`Host *`等）中隐式使用包含`User admin`的SSH Config配置文件。`Connection('myhost')` 将默认使用用户名为`admin`的用户进行连接。\n- 利用主机参数简写，例如`Connection('admin@myhost')`\n- 显示指定连接参数: `Connection('myhost', user='admin')`\n\n```\n__init__(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)\n```\n创建服务器连接对象。\n\n#### 构建函数参数说明\n- **`host(str)`**\n  连接服务器的主机名或者IP地址，也可以是主机IP地址，端口号，用户名组合的简写形式：\n  `user@host`, `host:port`, 或` user@host:port`\n  > 注意\n  >\n  > 如果`host`与SSH Config配置文件中`Host`项相匹配，并且`Host`项包含`Hostname`属性，则`Connection`对象认为host与Hostname值相等。\n  > \n  > 在所有情况下，主机的原始值都会保留为原始主机属性。\n  > s\n  > 给定SSH config文件内容如下：\n  >\n  >      Host myalias\n  >          Hostname realhostname\n  > 使用 `Connection(host='myalias')`调用，将返回一个对象：`host`值为`realhostname`，`original_host`值为`myalias`\n\n- **`user(str)`**\n  远程服务器登录用户名，默认值为`config.user`\n- **`port(int)`**\n  远程服务器的ssh端口号，默认值为`config.port`\n- **`config(object)`**\n  配置对象，该对象类型为`Config`或`invoke.config.Config`(类型转换为`Config`)\n\n- **`gateway(object)`**\n  用作此连接的代理或网关的对象。\n  该参数可接受值：\n   - 另一个`Connection`对象(`ProxyJump`类型网关)\n   - shell命令字符串（` ProxyCommand`类型网关）\n  默认值为：`None`，\n\n- **`forward_agent(boolean)`**\n  是否开启SSH代理转发，默认值为:`config.forward_agent`\n\n- **`connect_timeout(int)`**\n  连接超时时间（秒）\n\n#### 类属性\n\n- **`connect_kwargs(dict)`**\n\n   `connect_kwargs`中的键值对将会被`SSHClient.connect`逐个解析。例如：\n   ```\n   c = Connection(\n       host=\"hostname\",\n       user=\"admin\",\n       connect_kwargs={\n           \"key_filename\": \"/home/myuser/.ssh/private.key\",config.connect_kwargs\n       },\n   )\n   ```\n  **默认值：`config.connect_kwargs.`**\n- **`inline_ssh_env(boolean)`**\n\n  是否将“内置”环境变量作为前缀发送到命令字符串前面（`export VARNAME=value && mycommand here`），而不是通过`SSH` 协议提交该命令。如果远程服务器具有受限的`acceptenv`设置，则需要执行此操作。\n\n  **默认值：` False`**\n\n\n\n\n#### Raise\n\n\n#### 方法\n\n- `close()`:\n  \n  关闭与远程服务器的SSH连接，如果连接已完毕，则该方法什么也不做。\n\n- `forward_local()`:\n  \n  打开一个通道（tunnel）建立`local_port `到服务器环境的连接。\n\n  例如，假设您想连接到一个远程 PostgreSQL 数据库，该数据库被锁定，只能通过运行它的操作系统访问。您可以通过ssh访问此服务器，因此可以临时使本地系统上的端口5432与服务器上的端口5432类似：\n  ```\n  import psycopg2\n  from fabric import Connection\n\n  with Connection('my-db-server').forward_local(5432):\n    db = psycopg2.connect(\n        # 通过本地端口5432区连接数据库，通过本地端口5432的数据会转发到\n        # `my-db-server`服务器，然后在`my-db-server`服务器上真正的通过\n        # 端口号5432去连接数据库\n        host='localhost', port=5432, database='mydb'\n        # 我们为什么用 localhost 而不是 IP 地址或者主机名呢？其实这个取决于我\n        # 们之前是如何限制 PostgreSQL 只有本机才能访问。如果只允许 lookback 接口访问\n        # 的话，那么自然就只有 localhost 或者 IP 为 127.0.0.1 才能访问了，而# 不能用真实 IP 或者主机名。\n    )\n    # Do things with 'db' here\n  ```\n\n  该方法类似于OpenSSH命令中的`ssh -L `\n\n  - 参数：\n    \n    `local_port (int) `:\n\n    本地监听端口号\n\n    `remote_port (int) `:\n\n    远程服务器端口号，默认同`local_port`\n\n    `local_host (str) `:\n\n    要侦听的本地主机名/接口。默认值：localhost\n\n    `remote_host (str) `:\n\n    为转发的远程端口提供服务的远程主机名。默认值：localhost（即`Connection`所连接的主机）\n\n\n  - 返回值：无\n    \n    此方法仅用作影响本地操作系统状态的上下文管理器。\n  \n\n- `forward_remote()`: \n  \n  该方法对应SSH的 forward remote，`$ ssh -R <local port>:<remote host>:<remote port> <SSH hostname>`\n  - 参数\n    - `remote_port（int）` - 要监听的远程端口号。\n\n    - `local_port（int）`- 本地端口号。默认值与`remote_port`相同。\n\n    - `local_host （str）`–转发连接所使用的本地主机名/接口。默认值：localhost。\n\n    - `remote_host （str）`–转发连接时要监听的远程接口地址。默认值：127.0.0.1（即仅侦听`localhost`）。\n\n\n  \n\n- *classmethod* `from_v1(env, **kwargs)`:\n\n  使用Fabric 1版本的 `env`参数值。\n  \n  `env`: Fabric 1版本的 `env`变量\n\n  `kwargs`: 除了env之外，所有的关键字参数都是直接传递到主构造函数中。\n\n  > 注意\n  >\n  > `kwargs`中的参数会覆盖`env`相同的参数值。\n\n- `get(*args, **kwargs)`:\n  \n  将远程文件下载到本地文件系统或`file-like`对象\n\n- `is_connected()`：\n  \n  连接是否open\n\n- `local(*args, **kwargs)`:\n  \n  在本地机器上执行shell命令\n\n- `open()`:\n  \n  启动与此对象绑定到的主机/端口的ssh连接。\n\n\n\n- `open_gateway()`:\n\n  从gateway中获取`socket-like `对象。\n\n  返回值：\n\n  如果`gateway`是一个`Connection`，则返回` paramiko.channel.Channel`；如果`gateway`是一个字符串，则返回[`ProxyCommand`](http://docs.paramiko.org/en/latest/api/proxy.html#paramiko.proxy.ProxyCommand)对象\n\n- `put(*args, **kwargs)`:\n  \n  上传文件或者`file-like`对象到远程服务器\n\n- `run(command, **kwargs)`:\n\n  在远程服务器上执行shell命令，该方法是对[` invoke.runners.Runner.run`](http://docs.pyinvoke.org/en/latest/api/runners.html#invoke.runners.Runner.run)的封装，具体实现可参考` invoke.runners.Runner.run`的API文档\n\n\n- `sftp()`:\n  \n  返回一个`SFTPClient`对象\n\n  如果多次调用，则会记住第一个结果；因此，任何给定的`Connection`实例都将只具有一个`sftp client`，并且状态（如chdir管理的状态）将被保留。\n\n- `sudo(command, **kwargs)`:\n  \n  在远程服务器上执行sudo命令\n\n\n","source":"_posts/2019-03-26-fabric2-tutorial.md","raw":"---\ntitle: Fabric2.4 Tutorial\ndate: 2019-03-26 09:26:59\ntags:\n  - Fabric\n  - Python\ncategories:\n  - 运维\n  - Fabric\n---\n\n## Network\n\n### SSH连接网关\n#### 背景\n\n出于安全考虑，服务器经常会加一道防火墙，从而阻止从互联网直接访问服务器。如果需要连接防火墙内部的网络，通常是通过中间主机（被称为“跳转机”、“堡垒机”、“网关或代理”、“弹跳”）\n\n网关需要与网关系统建立初始/外部SSH连接，然后使用该连接作为到最终/内部主机的“真实”连接的传输。\n\n则可以通过 `ssh gatewayhost`去真正连接 `ssh internalhost `，这适用于长时间运行的会话。但在频繁进行时，会成为负担。\n\n\nFabric中有两种网关解决方案，可以反映OpenSSH客户端的功能：`ProxyJump`（更容易，更少开销，可以嵌套）; `ProxyCommand` （更多开销，不能嵌套，有时更灵活）。两者都支持通常的配置源：Fabric自己的配置框架，SSH配置文件或运行时参数\n\n##### `ProxyJump`\n\n这种类型的网关使用SSH协议的direct-tcpip通道类型 - 一种轻量级方法，用于请求网关的sshd开启一个到远程服务器的连接。\n\n`paramiko.channel.Channel` 实例实现了Python的 `socket` API，因此可用于代替几乎任何Python代码的实际操作系统套接字。\n\n`ProxyJump`类型的网关，使用简单：\n\n```\nfrom fabric import Connection\n\nc = Connection('internalhost', gateway=Connection('gatewayhost'))\n```\n\n该 `gateway` 连接(`Connection('gatewayhost')`)，需要配置 gatewayhost的登录用户名，端口号等等。\n\n\n##### `ProxyCommand`\n\n传统的OpenSSH命令行客户端长期提供了一个`ProxyCommand`指令（请参阅[man ssh_config](http://man.openbsd.org/ssh_config)），该指令通过任意本地子进程管理内部连接的输入和输出。\n\n与 `ProxyJump`类型的网关相比，这种方式增加了开销（额外的子进程），并且无法轻松嵌套。在数据传输中，它允许使用`SOCKS`代理或者自定义过滤等高级功能，相对来说更加灵活。\n\n`ProxyCommand`子进程通常是另一个ssh命令，例如`ssh -W ％h：％p gatewayhost`;或者（在缺少`-W`选项的SSH版本上）广泛使用的`netcat`，通过`ssh gatewayhost nc ％h％p`。\n\nFabric支持ProxyCommand接受gatewaykwarg中的命令字符串对象 Connection; 这用于paramiko.proxy.ProxyCommand在连接时填充 对象。\n\n\n\n#### 其他问题\n\n如果您不确定使用哪两种方法：使用`ProxyJump`方式。它性能更好，在本地系统上使用更少的资源，并且具有更易于使用的API。\n\n> **警告**\n> \n> 同时请求两种类型的网关到相同的主机（即，以`Connection`作为`gateway`的`kwarg`或`config`参数，并且加载包含配置文件`ProxyCommand`）将导致异常。\n\n---\n\n## Configuration\n\n### 基础\n\nFabric配置系统，主要依赖于Invoke功能（`invoke.config.Config`），严格来说是`invoke.config.Config`的子类 `fabric.config.Config`。\n\n俩类的主要区别：\n- 配置文件命名全部以fabric.\\*，而不是原来的invoke.\\*，  比如：`/etc/fabric.yml` 取代 `/etc/invoke.yml`, `~/.fabric.py` 取代 `~/.invoke.py`\n- Fabric在`invoke.config.Config`基础上，新增了其他的配置属性，比如：SSH默认连接端口为22\n- Fabric有加载SSH配置文件的特殊机制。并将根据每个`Connection`，自动创建或更新配置子树。并使用该特定主机的加载ssh配置。\n- Fabric提供一个Framework或者进行管理per-host或者per-host-connection配置。\n  - 该功能，将会补充所述的ssh配置加载的功能。我们预计大多数用户倾向于通过SSH配置文件来进行配置。\n\n\n\n\n### 配置默认值\n\n#### 重写Invoke-level\n\n- `run.replace_env: True`，在远程服务器执行的shell命令，将不会继承当前线程的环境变量。\n  \n  处于安全考虑：默认情况下远程泄漏本地环境数据是不推荐的。\n\n#### 扩展Invoke-level\n\n`runners.remote`:在Invoke中，`runner`拥有单独键：`local`(mapping to `Local`)，Fabric添加新的键`remote`（mapping to `Remote`）\n\n#### Fabric自定义默认值\n\n> **注意**\n> \n> 大部分所有的设置（settings）也适用于`Connection`\n\n\n> **警告**\n> 大部分的设置也可以通过ssh_config_files进行配置，这些值优先于通过核心配置进行配置的值，\n\n- `connect_kwargs`:\n\n  关键字参数，这是许多与ssh相关的选项的主要配置向量，例如选择私钥、切换ssh代理的转发等。默认值：`{}`。\n\n- `forward_agent`:\n\n  是否尝试将本地ssh身份验证代理转发到远程端。默认： `False`\n\n- `gateway`:\n\n  用作 `Connection` 对象的 `gateway` 属性的默认值，默认：`None`\n\n- `load_ssh_configs`:\n\n  是否自动搜索SSH配置文件，当值为`False`，不自动加载配置文件。默认：`True`\n\n- `port`:\n\n  TCP端口号，用于`Connection`对象的连接，默认:22\n\n- `inline_ssh_env`:\n\n  Boolean用作`Connection`的`inline-ssh-env`参数值的全局默认值；有关详细信息，请参阅其文档。默认值：false。\n\n- `ssh_config_path`:\n  \n  运行时（Runtime）SSH配置路径，默认：None\n\n- `timeouts`:\n\n  - `connection`：连接超时，以秒为单位；默认：`None`，表示永远没有`timeout/block`。\n\n- `user`:\n  \n  指定通过ssh连接的用户名，默认值使用本地主机的用户名\n\n\n### 加载并使用ssh_config文件\n\n#### 加载哪些文件\n\n**Fabric** 使用 **Paramiko** 的`SSH config`文件，加载并解析 `ssh_config`格式的文件\n\n - 已经被解析的 `SSHConfig` 对象，将会通过 `ssh_config` 关键字参数传给 `Config.__init__`。如果给定该值，则不再加载其他任何配置文件。\n - 运行时文件路径，通过`configuration `中的`ssh_config_path`进行设置，该路径将被`SSHConfig`对象加载。\n   \n   - 同 `fab` CLI 命令中的 `--ssh-config`\n\n - 如果 `Config.__init__` 没有运行时配置（包括对象或者路径），其会自动按顺序去搜索并加载 `~/.ssh/config and/`或 `/etc/ssh/ssh_config`\n - 如果上述都没有产生SSH配置数据，则空 `SSHConfig` 是最终结果\n\n - 无论对象是如何生成的，它都以 `Config.base_ssh_config` 形式公开。\n\n##### Connection使用ssh_config文件\n\n`Connection`对象将其配置的SSH数据（通过 `lookup` 获得）的每个主机“views”公开为`Connection.ssh_config`。 `Connection` 本身引用这些值，如以下小节所述，通常作为相应配置键或参数的简单默认值(例如：`port`, `forward_agent`)\n\n\n除非另有说明，否则这些值会覆盖相同键的常规配置值，但可能会被 `Connection.__ init__` 参数覆盖。\n\n比如：`~/.fabric.yaml`\n\n```\nuser: foo\n```\n\n如果没有任何其他配置，`Connection（'myhost'）`将作为 `foo` 用户连接。\n\n如果我们还有其他配置：`~/.ssh/config`\n\n```\nHost *\n    User bar\n```\n`Connection（'myhost'）`将作为 `bar` 用户连接。\n\n可见，`SSH config` 优先于`Fabric config`\n\n然而，`Connection（'myhost', user='biz'）`，将用`biz`用户进行连接。\n\n> **注意**\n> \n> 以下部分使用`ssh_config`键的大写版本以便更轻松地与`man ssh_config`进行关联，但实际的`SSHConfig`数据结构规范化为小写键，因为SSH配置文件在技术上不区分大小写。\n\n\n##### Connection参数\n\n- `Hostname` ：替换 `host` 的原始值（保留为`.original_host`。）\n- `Port`：提供 `port`  config 选项/参数的默认值。\n- `User`：提供 `user` config 选项/参数的默认值。\n- `ConnectTimeout` ：设置`timeouts.connect` config 选项/超时参数的默认值。\n\n\n##### 代理(Proxying)\n\n- `ProxyCommand` : 为`gateway`提供默认字符串值\n- `ProxyJump` : 为`gateway`提供默认`Connection`对象\n  - 嵌套式`ProxyJump`，即`user1@hop1.host，user2@hop2.host，...`，将导致一系列适当的嵌套`gateway`值 - 就好像用户手动指定了`Connecton(...，gateway) = Connection('user1@hop1.host'，gateway = Connection('user2@hop2.host'，gateway = ...)))`。\n\n> **注意**\n> \n> 如果为给定主机指定了两者，则`ProxyJump`将覆盖`ProxyCommand`。这与OpenSSH略有不同，OpenSSH指令的加载顺序决定了哪一个获胜。我们这样做（将配置视为字典结构）需要额外的工作。\n\n##### 认证（Authentication）\n\n- `ForwardAgent`: 控制`forward_agent`参数行为\n- `IdentityFile`: 追加 `connect_kwargs`字段 `key_filename`，类似于 `--identity`\n\n#### 禁用`ssh_config`加载\n\n需要更严格控制其环境配置方式的用户可能希望禁用系统/用户级SSH配置文件的自动加载；这可以防止难以预料的错误，例如新用户的 `~/.ssh/config` 覆盖在常规配置层次结构中设置的值。\n\n为此，只需将顶级配置选项 `load_ssh_configs` 设置为`False`即可。\n\n> **注意**\n> 更改此设置不会禁用运行时级别（`runtime-level`）配置文件的加载，如果用户明确指定加载哪个文件，我们则认为他们知道他们要干什么。\n\n\n---\n\n## connection\n\n```\nclass fabric.connection.Connection(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)¶\n```\n用于与ssh守护进程的连接，包含shell命令和文件传输。\n\n### 基础\n\n该类继承自`Invoke.context`，在该`context`中，可以进行命令、任务（task）操作。该类封装了Paramiko `SSHClient`实例，通过该类生成的`sshclient`和`channel`实例执行的高级操作。\n\n> **注意**\n> \n> 特定于SSH的选项——例如指定密钥（private key）和密码口令（passphrases）、timeouts、禁用SSH代理等，可通过构造函数的`connect_kwargs`参数指定，由paramiko直接处理。\n> \n> \n>     c = connection(host='localhost',user='root', connect_kwargs={'passwrd':'123456'}\n\n\n\n\n### 生命周期\n\n`Connection`有`create, connect/open, do work, disconnect/close`生命周期。\n\n- `Instantiation `持久影响对象连接参数。但并不真正建立连接。\n  - 可选的构造方式：[upgrading piecemeal from Fabric 1](http://www.fabfile.org/upgrading.html#from-v1) `from_v1(env)`\n- `run`、`get` 等方法会自动触发`connection`的`open`，用户也可手动执行`open`\n- `Connection`无需手动关闭。大部分情况下连接的关闭操作交给Paramiko的**垃圾回收钩子**或者python自带的关闭序列。当然也有特殊情况（当退出时，session挂起），此时需要手动进行关闭(close)。\n\n  这可以通过手动调用`Close`或借助`with`用作ContextManager来完成：\n  \n  ```\n  with Connection('host') as c:\n    c.run('command')\n    c.put('file')\n  ```\n\n> Note\n> \n> 该类将`invoke.context.Context.run`方法重新绑定到`local`方法，远程命令和本地命令均可执行。\n\n### Configuration\n\n大部分的`Connection`参数，遵循[` Invoke-style configuration`](http://docs.fabfile.org/en/2.4/concepts/configuration.html)和[`SSH Config`](http://docs.fabfile.org/en/2.4/concepts/configuration.html#connection-ssh-config)。例如连接到远程机器` admin@myhost`，可以使用下述方法进行连接：\n- 使用`build-in`配置机制，比如` /etc/fabric.yml, ~/.fabric.json`，`user: admin` ( 或`{\"user\": \"admin\"}`)。这样，`Connection('myhost')`就可以通过用户为`admin`进行连接。\n- 在任何适用的`Host`开头（`Host myhost`、`Host *`等）中隐式使用包含`User admin`的SSH Config配置文件。`Connection('myhost')` 将默认使用用户名为`admin`的用户进行连接。\n- 利用主机参数简写，例如`Connection('admin@myhost')`\n- 显示指定连接参数: `Connection('myhost', user='admin')`\n\n```\n__init__(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)\n```\n创建服务器连接对象。\n\n#### 构建函数参数说明\n- **`host(str)`**\n  连接服务器的主机名或者IP地址，也可以是主机IP地址，端口号，用户名组合的简写形式：\n  `user@host`, `host:port`, 或` user@host:port`\n  > 注意\n  >\n  > 如果`host`与SSH Config配置文件中`Host`项相匹配，并且`Host`项包含`Hostname`属性，则`Connection`对象认为host与Hostname值相等。\n  > \n  > 在所有情况下，主机的原始值都会保留为原始主机属性。\n  > s\n  > 给定SSH config文件内容如下：\n  >\n  >      Host myalias\n  >          Hostname realhostname\n  > 使用 `Connection(host='myalias')`调用，将返回一个对象：`host`值为`realhostname`，`original_host`值为`myalias`\n\n- **`user(str)`**\n  远程服务器登录用户名，默认值为`config.user`\n- **`port(int)`**\n  远程服务器的ssh端口号，默认值为`config.port`\n- **`config(object)`**\n  配置对象，该对象类型为`Config`或`invoke.config.Config`(类型转换为`Config`)\n\n- **`gateway(object)`**\n  用作此连接的代理或网关的对象。\n  该参数可接受值：\n   - 另一个`Connection`对象(`ProxyJump`类型网关)\n   - shell命令字符串（` ProxyCommand`类型网关）\n  默认值为：`None`，\n\n- **`forward_agent(boolean)`**\n  是否开启SSH代理转发，默认值为:`config.forward_agent`\n\n- **`connect_timeout(int)`**\n  连接超时时间（秒）\n\n#### 类属性\n\n- **`connect_kwargs(dict)`**\n\n   `connect_kwargs`中的键值对将会被`SSHClient.connect`逐个解析。例如：\n   ```\n   c = Connection(\n       host=\"hostname\",\n       user=\"admin\",\n       connect_kwargs={\n           \"key_filename\": \"/home/myuser/.ssh/private.key\",config.connect_kwargs\n       },\n   )\n   ```\n  **默认值：`config.connect_kwargs.`**\n- **`inline_ssh_env(boolean)`**\n\n  是否将“内置”环境变量作为前缀发送到命令字符串前面（`export VARNAME=value && mycommand here`），而不是通过`SSH` 协议提交该命令。如果远程服务器具有受限的`acceptenv`设置，则需要执行此操作。\n\n  **默认值：` False`**\n\n\n\n\n#### Raise\n\n\n#### 方法\n\n- `close()`:\n  \n  关闭与远程服务器的SSH连接，如果连接已完毕，则该方法什么也不做。\n\n- `forward_local()`:\n  \n  打开一个通道（tunnel）建立`local_port `到服务器环境的连接。\n\n  例如，假设您想连接到一个远程 PostgreSQL 数据库，该数据库被锁定，只能通过运行它的操作系统访问。您可以通过ssh访问此服务器，因此可以临时使本地系统上的端口5432与服务器上的端口5432类似：\n  ```\n  import psycopg2\n  from fabric import Connection\n\n  with Connection('my-db-server').forward_local(5432):\n    db = psycopg2.connect(\n        # 通过本地端口5432区连接数据库，通过本地端口5432的数据会转发到\n        # `my-db-server`服务器，然后在`my-db-server`服务器上真正的通过\n        # 端口号5432去连接数据库\n        host='localhost', port=5432, database='mydb'\n        # 我们为什么用 localhost 而不是 IP 地址或者主机名呢？其实这个取决于我\n        # 们之前是如何限制 PostgreSQL 只有本机才能访问。如果只允许 lookback 接口访问\n        # 的话，那么自然就只有 localhost 或者 IP 为 127.0.0.1 才能访问了，而# 不能用真实 IP 或者主机名。\n    )\n    # Do things with 'db' here\n  ```\n\n  该方法类似于OpenSSH命令中的`ssh -L `\n\n  - 参数：\n    \n    `local_port (int) `:\n\n    本地监听端口号\n\n    `remote_port (int) `:\n\n    远程服务器端口号，默认同`local_port`\n\n    `local_host (str) `:\n\n    要侦听的本地主机名/接口。默认值：localhost\n\n    `remote_host (str) `:\n\n    为转发的远程端口提供服务的远程主机名。默认值：localhost（即`Connection`所连接的主机）\n\n\n  - 返回值：无\n    \n    此方法仅用作影响本地操作系统状态的上下文管理器。\n  \n\n- `forward_remote()`: \n  \n  该方法对应SSH的 forward remote，`$ ssh -R <local port>:<remote host>:<remote port> <SSH hostname>`\n  - 参数\n    - `remote_port（int）` - 要监听的远程端口号。\n\n    - `local_port（int）`- 本地端口号。默认值与`remote_port`相同。\n\n    - `local_host （str）`–转发连接所使用的本地主机名/接口。默认值：localhost。\n\n    - `remote_host （str）`–转发连接时要监听的远程接口地址。默认值：127.0.0.1（即仅侦听`localhost`）。\n\n\n  \n\n- *classmethod* `from_v1(env, **kwargs)`:\n\n  使用Fabric 1版本的 `env`参数值。\n  \n  `env`: Fabric 1版本的 `env`变量\n\n  `kwargs`: 除了env之外，所有的关键字参数都是直接传递到主构造函数中。\n\n  > 注意\n  >\n  > `kwargs`中的参数会覆盖`env`相同的参数值。\n\n- `get(*args, **kwargs)`:\n  \n  将远程文件下载到本地文件系统或`file-like`对象\n\n- `is_connected()`：\n  \n  连接是否open\n\n- `local(*args, **kwargs)`:\n  \n  在本地机器上执行shell命令\n\n- `open()`:\n  \n  启动与此对象绑定到的主机/端口的ssh连接。\n\n\n\n- `open_gateway()`:\n\n  从gateway中获取`socket-like `对象。\n\n  返回值：\n\n  如果`gateway`是一个`Connection`，则返回` paramiko.channel.Channel`；如果`gateway`是一个字符串，则返回[`ProxyCommand`](http://docs.paramiko.org/en/latest/api/proxy.html#paramiko.proxy.ProxyCommand)对象\n\n- `put(*args, **kwargs)`:\n  \n  上传文件或者`file-like`对象到远程服务器\n\n- `run(command, **kwargs)`:\n\n  在远程服务器上执行shell命令，该方法是对[` invoke.runners.Runner.run`](http://docs.pyinvoke.org/en/latest/api/runners.html#invoke.runners.Runner.run)的封装，具体实现可参考` invoke.runners.Runner.run`的API文档\n\n\n- `sftp()`:\n  \n  返回一个`SFTPClient`对象\n\n  如果多次调用，则会记住第一个结果；因此，任何给定的`Connection`实例都将只具有一个`sftp client`，并且状态（如chdir管理的状态）将被保留。\n\n- `sudo(command, **kwargs)`:\n  \n  在远程服务器上执行sudo命令\n\n\n","slug":"fabric2-tutorial","published":1,"updated":"2019-03-27T09:26:46.405Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtr09p5w0026t2xupiwxnmyd","content":"<h2 id=\"Network\"><a href=\"#Network\" class=\"headerlink\" title=\"Network\"></a>Network</h2><h3 id=\"SSH连接网关\"><a href=\"#SSH连接网关\" class=\"headerlink\" title=\"SSH连接网关\"></a>SSH连接网关</h3><h4 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h4><p>出于安全考虑，服务器经常会加一道防火墙，从而阻止从互联网直接访问服务器。如果需要连接防火墙内部的网络，通常是通过中间主机（被称为“跳转机”、“堡垒机”、“网关或代理”、“弹跳”）</p>\n<p>网关需要与网关系统建立初始/外部SSH连接，然后使用该连接作为到最终/内部主机的“真实”连接的传输。</p>\n<p>则可以通过 <code>ssh gatewayhost</code>去真正连接 <code>ssh internalhost</code>，这适用于长时间运行的会话。但在频繁进行时，会成为负担。</p>\n<p>Fabric中有两种网关解决方案，可以反映OpenSSH客户端的功能：<code>ProxyJump</code>（更容易，更少开销，可以嵌套）; <code>ProxyCommand</code> （更多开销，不能嵌套，有时更灵活）。两者都支持通常的配置源：Fabric自己的配置框架，SSH配置文件或运行时参数</p>\n<h5 id=\"ProxyJump\"><a href=\"#ProxyJump\" class=\"headerlink\" title=\"ProxyJump\"></a><code>ProxyJump</code></h5><p>这种类型的网关使用SSH协议的direct-tcpip通道类型 - 一种轻量级方法，用于请求网关的sshd开启一个到远程服务器的连接。</p>\n<p><code>paramiko.channel.Channel</code> 实例实现了Python的 <code>socket</code> API，因此可用于代替几乎任何Python代码的实际操作系统套接字。</p>\n<p><code>ProxyJump</code>类型的网关，使用简单：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from fabric import Connection</span><br><span class=\"line\"></span><br><span class=\"line\">c = Connection(&apos;internalhost&apos;, gateway=Connection(&apos;gatewayhost&apos;))</span><br></pre></td></tr></table></figure>\n<p>该 <code>gateway</code> 连接(<code>Connection(&#39;gatewayhost&#39;)</code>)，需要配置 gatewayhost的登录用户名，端口号等等。</p>\n<h5 id=\"ProxyCommand\"><a href=\"#ProxyCommand\" class=\"headerlink\" title=\"ProxyCommand\"></a><code>ProxyCommand</code></h5><p>传统的OpenSSH命令行客户端长期提供了一个<code>ProxyCommand</code>指令（请参阅<a href=\"http://man.openbsd.org/ssh_config\" target=\"_blank\" rel=\"noopener\">man ssh_config</a>），该指令通过任意本地子进程管理内部连接的输入和输出。</p>\n<p>与 <code>ProxyJump</code>类型的网关相比，这种方式增加了开销（额外的子进程），并且无法轻松嵌套。在数据传输中，它允许使用<code>SOCKS</code>代理或者自定义过滤等高级功能，相对来说更加灵活。</p>\n<p><code>ProxyCommand</code>子进程通常是另一个ssh命令，例如<code>ssh -W ％h：％p gatewayhost</code>;或者（在缺少<code>-W</code>选项的SSH版本上）广泛使用的<code>netcat</code>，通过<code>ssh gatewayhost nc ％h％p</code>。</p>\n<p>Fabric支持ProxyCommand接受gatewaykwarg中的命令字符串对象 Connection; 这用于paramiko.proxy.ProxyCommand在连接时填充 对象。</p>\n<h4 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h4><p>如果您不确定使用哪两种方法：使用<code>ProxyJump</code>方式。它性能更好，在本地系统上使用更少的资源，并且具有更易于使用的API。</p>\n<blockquote>\n<p><strong>警告</strong></p>\n<p>同时请求两种类型的网关到相同的主机（即，以<code>Connection</code>作为<code>gateway</code>的<code>kwarg</code>或<code>config</code>参数，并且加载包含配置文件<code>ProxyCommand</code>）将导致异常。</p>\n</blockquote>\n<hr>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>Fabric配置系统，主要依赖于Invoke功能（<code>invoke.config.Config</code>），严格来说是<code>invoke.config.Config</code>的子类 <code>fabric.config.Config</code>。</p>\n<p>俩类的主要区别：</p>\n<ul>\n<li>配置文件命名全部以fabric.*，而不是原来的invoke.*，  比如：<code>/etc/fabric.yml</code> 取代 <code>/etc/invoke.yml</code>, <code>~/.fabric.py</code> 取代 <code>~/.invoke.py</code></li>\n<li>Fabric在<code>invoke.config.Config</code>基础上，新增了其他的配置属性，比如：SSH默认连接端口为22</li>\n<li>Fabric有加载SSH配置文件的特殊机制。并将根据每个<code>Connection</code>，自动创建或更新配置子树。并使用该特定主机的加载ssh配置。</li>\n<li>Fabric提供一个Framework或者进行管理per-host或者per-host-connection配置。<ul>\n<li>该功能，将会补充所述的ssh配置加载的功能。我们预计大多数用户倾向于通过SSH配置文件来进行配置。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"配置默认值\"><a href=\"#配置默认值\" class=\"headerlink\" title=\"配置默认值\"></a>配置默认值</h3><h4 id=\"重写Invoke-level\"><a href=\"#重写Invoke-level\" class=\"headerlink\" title=\"重写Invoke-level\"></a>重写Invoke-level</h4><ul>\n<li><p><code>run.replace_env: True</code>，在远程服务器执行的shell命令，将不会继承当前线程的环境变量。</p>\n<p>处于安全考虑：默认情况下远程泄漏本地环境数据是不推荐的。</p>\n</li>\n</ul>\n<h4 id=\"扩展Invoke-level\"><a href=\"#扩展Invoke-level\" class=\"headerlink\" title=\"扩展Invoke-level\"></a>扩展Invoke-level</h4><p><code>runners.remote</code>:在Invoke中，<code>runner</code>拥有单独键：<code>local</code>(mapping to <code>Local</code>)，Fabric添加新的键<code>remote</code>（mapping to <code>Remote</code>）</p>\n<h4 id=\"Fabric自定义默认值\"><a href=\"#Fabric自定义默认值\" class=\"headerlink\" title=\"Fabric自定义默认值\"></a>Fabric自定义默认值</h4><blockquote>\n<p><strong>注意</strong></p>\n<p>大部分所有的设置（settings）也适用于<code>Connection</code></p>\n</blockquote>\n<blockquote>\n<p><strong>警告</strong><br>大部分的设置也可以通过ssh_config_files进行配置，这些值优先于通过核心配置进行配置的值，</p>\n</blockquote>\n<ul>\n<li><p><code>connect_kwargs</code>:</p>\n<p>关键字参数，这是许多与ssh相关的选项的主要配置向量，例如选择私钥、切换ssh代理的转发等。默认值：<code>{}</code>。</p>\n</li>\n<li><p><code>forward_agent</code>:</p>\n<p>是否尝试将本地ssh身份验证代理转发到远程端。默认： <code>False</code></p>\n</li>\n<li><p><code>gateway</code>:</p>\n<p>用作 <code>Connection</code> 对象的 <code>gateway</code> 属性的默认值，默认：<code>None</code></p>\n</li>\n<li><p><code>load_ssh_configs</code>:</p>\n<p>是否自动搜索SSH配置文件，当值为<code>False</code>，不自动加载配置文件。默认：<code>True</code></p>\n</li>\n<li><p><code>port</code>:</p>\n<p>TCP端口号，用于<code>Connection</code>对象的连接，默认:22</p>\n</li>\n<li><p><code>inline_ssh_env</code>:</p>\n<p>Boolean用作<code>Connection</code>的<code>inline-ssh-env</code>参数值的全局默认值；有关详细信息，请参阅其文档。默认值：false。</p>\n</li>\n<li><p><code>ssh_config_path</code>:</p>\n<p>运行时（Runtime）SSH配置路径，默认：None</p>\n</li>\n<li><p><code>timeouts</code>:</p>\n<ul>\n<li><code>connection</code>：连接超时，以秒为单位；默认：<code>None</code>，表示永远没有<code>timeout/block</code>。</li>\n</ul>\n</li>\n<li><p><code>user</code>:</p>\n<p>指定通过ssh连接的用户名，默认值使用本地主机的用户名</p>\n</li>\n</ul>\n<h3 id=\"加载并使用ssh-config文件\"><a href=\"#加载并使用ssh-config文件\" class=\"headerlink\" title=\"加载并使用ssh_config文件\"></a>加载并使用ssh_config文件</h3><h4 id=\"加载哪些文件\"><a href=\"#加载哪些文件\" class=\"headerlink\" title=\"加载哪些文件\"></a>加载哪些文件</h4><p><strong>Fabric</strong> 使用 <strong>Paramiko</strong> 的<code>SSH config</code>文件，加载并解析 <code>ssh_config</code>格式的文件</p>\n<ul>\n<li>已经被解析的 <code>SSHConfig</code> 对象，将会通过 <code>ssh_config</code> 关键字参数传给 <code>Config.__init__</code>。如果给定该值，则不再加载其他任何配置文件。</li>\n<li><p>运行时文件路径，通过<code>configuration</code>中的<code>ssh_config_path</code>进行设置，该路径将被<code>SSHConfig</code>对象加载。</p>\n<ul>\n<li>同 <code>fab</code> CLI 命令中的 <code>--ssh-config</code></li>\n</ul>\n</li>\n<li><p>如果 <code>Config.__init__</code> 没有运行时配置（包括对象或者路径），其会自动按顺序去搜索并加载 <code>~/.ssh/config and/</code>或 <code>/etc/ssh/ssh_config</code></p>\n</li>\n<li><p>如果上述都没有产生SSH配置数据，则空 <code>SSHConfig</code> 是最终结果</p>\n</li>\n<li><p>无论对象是如何生成的，它都以 <code>Config.base_ssh_config</code> 形式公开。</p>\n</li>\n</ul>\n<h5 id=\"Connection使用ssh-config文件\"><a href=\"#Connection使用ssh-config文件\" class=\"headerlink\" title=\"Connection使用ssh_config文件\"></a>Connection使用ssh_config文件</h5><p><code>Connection</code>对象将其配置的SSH数据（通过 <code>lookup</code> 获得）的每个主机“views”公开为<code>Connection.ssh_config</code>。 <code>Connection</code> 本身引用这些值，如以下小节所述，通常作为相应配置键或参数的简单默认值(例如：<code>port</code>, <code>forward_agent</code>)</p>\n<p>除非另有说明，否则这些值会覆盖相同键的常规配置值，但可能会被 <code>Connection.__ init__</code> 参数覆盖。</p>\n<p>比如：<code>~/.fabric.yaml</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user: foo</span><br></pre></td></tr></table></figure>\n<p>如果没有任何其他配置，<code>Connection（&#39;myhost&#39;）</code>将作为 <code>foo</code> 用户连接。</p>\n<p>如果我们还有其他配置：<code>~/.ssh/config</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host *</span><br><span class=\"line\">    User bar</span><br></pre></td></tr></table></figure>\n<p><code>Connection（&#39;myhost&#39;）</code>将作为 <code>bar</code> 用户连接。</p>\n<p>可见，<code>SSH config</code> 优先于<code>Fabric config</code></p>\n<p>然而，<code>Connection（&#39;myhost&#39;, user=&#39;biz&#39;）</code>，将用<code>biz</code>用户进行连接。</p>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>以下部分使用<code>ssh_config</code>键的大写版本以便更轻松地与<code>man ssh_config</code>进行关联，但实际的<code>SSHConfig</code>数据结构规范化为小写键，因为SSH配置文件在技术上不区分大小写。</p>\n</blockquote>\n<h5 id=\"Connection参数\"><a href=\"#Connection参数\" class=\"headerlink\" title=\"Connection参数\"></a>Connection参数</h5><ul>\n<li><code>Hostname</code> ：替换 <code>host</code> 的原始值（保留为<code>.original_host</code>。）</li>\n<li><code>Port</code>：提供 <code>port</code>  config 选项/参数的默认值。</li>\n<li><code>User</code>：提供 <code>user</code> config 选项/参数的默认值。</li>\n<li><code>ConnectTimeout</code> ：设置<code>timeouts.connect</code> config 选项/超时参数的默认值。</li>\n</ul>\n<h5 id=\"代理-Proxying\"><a href=\"#代理-Proxying\" class=\"headerlink\" title=\"代理(Proxying)\"></a>代理(Proxying)</h5><ul>\n<li><code>ProxyCommand</code> : 为<code>gateway</code>提供默认字符串值</li>\n<li><code>ProxyJump</code> : 为<code>gateway</code>提供默认<code>Connection</code>对象<ul>\n<li>嵌套式<code>ProxyJump</code>，即<a href=\"mailto:`user1@hop1.host\" target=\"_blank\" rel=\"noopener\">`user1@hop1.host</a>，<a href=\"mailto:user2@hop2.host\" target=\"_blank\" rel=\"noopener\">user2@hop2.host</a>，…<code>，将导致一系列适当的嵌套</code>gateway<code>值 - 就好像用户手动指定了</code>Connecton(…，gateway) = Connection(<a href=\"mailto:&#39;user1@hop1.host\" target=\"_blank\" rel=\"noopener\">&#39;user1@hop1.host</a>‘，gateway = Connection(<a href=\"mailto:&#39;user2@hop2.host\" target=\"_blank\" rel=\"noopener\">&#39;user2@hop2.host</a>‘，gateway = …)))`。</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>如果为给定主机指定了两者，则<code>ProxyJump</code>将覆盖<code>ProxyCommand</code>。这与OpenSSH略有不同，OpenSSH指令的加载顺序决定了哪一个获胜。我们这样做（将配置视为字典结构）需要额外的工作。</p>\n</blockquote>\n<h5 id=\"认证（Authentication）\"><a href=\"#认证（Authentication）\" class=\"headerlink\" title=\"认证（Authentication）\"></a>认证（Authentication）</h5><ul>\n<li><code>ForwardAgent</code>: 控制<code>forward_agent</code>参数行为</li>\n<li><code>IdentityFile</code>: 追加 <code>connect_kwargs</code>字段 <code>key_filename</code>，类似于 <code>--identity</code></li>\n</ul>\n<h4 id=\"禁用ssh-config加载\"><a href=\"#禁用ssh-config加载\" class=\"headerlink\" title=\"禁用ssh_config加载\"></a>禁用<code>ssh_config</code>加载</h4><p>需要更严格控制其环境配置方式的用户可能希望禁用系统/用户级SSH配置文件的自动加载；这可以防止难以预料的错误，例如新用户的 <code>~/.ssh/config</code> 覆盖在常规配置层次结构中设置的值。</p>\n<p>为此，只需将顶级配置选项 <code>load_ssh_configs</code> 设置为<code>False</code>即可。</p>\n<blockquote>\n<p><strong>注意</strong><br>更改此设置不会禁用运行时级别（<code>runtime-level</code>）配置文件的加载，如果用户明确指定加载哪个文件，我们则认为他们知道他们要干什么。</p>\n</blockquote>\n<hr>\n<h2 id=\"connection\"><a href=\"#connection\" class=\"headerlink\" title=\"connection\"></a>connection</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class fabric.connection.Connection(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)¶</span><br></pre></td></tr></table></figure>\n<p>用于与ssh守护进程的连接，包含shell命令和文件传输。</p>\n<h3 id=\"基础-1\"><a href=\"#基础-1\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>该类继承自<code>Invoke.context</code>，在该<code>context</code>中，可以进行命令、任务（task）操作。该类封装了Paramiko <code>SSHClient</code>实例，通过该类生成的<code>sshclient</code>和<code>channel</code>实例执行的高级操作。</p>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>特定于SSH的选项——例如指定密钥（private key）和密码口令（passphrases）、timeouts、禁用SSH代理等，可通过构造函数的<code>connect_kwargs</code>参数指定，由paramiko直接处理。</p>\n<pre><code>c = connection(host=&apos;localhost&apos;,user=&apos;root&apos;, connect_kwargs={&apos;passwrd&apos;:&apos;123456&apos;}\n</code></pre></blockquote>\n<h3 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a>生命周期</h3><p><code>Connection</code>有<code>create, connect/open, do work, disconnect/close</code>生命周期。</p>\n<ul>\n<li><code>Instantiation</code>持久影响对象连接参数。但并不真正建立连接。<ul>\n<li>可选的构造方式：<a href=\"http://www.fabfile.org/upgrading.html#from-v1\" target=\"_blank\" rel=\"noopener\">upgrading piecemeal from Fabric 1</a> <code>from_v1(env)</code></li>\n</ul>\n</li>\n<li><code>run</code>、<code>get</code> 等方法会自动触发<code>connection</code>的<code>open</code>，用户也可手动执行<code>open</code></li>\n<li><p><code>Connection</code>无需手动关闭。大部分情况下连接的关闭操作交给Paramiko的<strong>垃圾回收钩子</strong>或者python自带的关闭序列。当然也有特殊情况（当退出时，session挂起），此时需要手动进行关闭(close)。</p>\n<p>这可以通过手动调用<code>Close</code>或借助<code>with</code>用作ContextManager来完成：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">with Connection(&apos;host&apos;) as c:</span><br><span class=\"line\">  c.run(&apos;command&apos;)</span><br><span class=\"line\">  c.put(&apos;file&apos;)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>Note</p>\n<p>该类将<code>invoke.context.Context.run</code>方法重新绑定到<code>local</code>方法，远程命令和本地命令均可执行。</p>\n</blockquote>\n<h3 id=\"Configuration-1\"><a href=\"#Configuration-1\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h3><p>大部分的<code>Connection</code>参数，遵循<a href=\"http://docs.fabfile.org/en/2.4/concepts/configuration.html\" target=\"_blank\" rel=\"noopener\"><code>Invoke-style configuration</code></a>和<a href=\"http://docs.fabfile.org/en/2.4/concepts/configuration.html#connection-ssh-config\" target=\"_blank\" rel=\"noopener\"><code>SSH Config</code></a>。例如连接到远程机器<code>admin@myhost</code>，可以使用下述方法进行连接：</p>\n<ul>\n<li>使用<code>build-in</code>配置机制，比如<code>/etc/fabric.yml, ~/.fabric.json</code>，<code>user: admin</code> ( 或<code>{&quot;user&quot;: &quot;admin&quot;}</code>)。这样，<code>Connection(&#39;myhost&#39;)</code>就可以通过用户为<code>admin</code>进行连接。</li>\n<li>在任何适用的<code>Host</code>开头（<code>Host myhost</code>、<code>Host *</code>等）中隐式使用包含<code>User admin</code>的SSH Config配置文件。<code>Connection(&#39;myhost&#39;)</code> 将默认使用用户名为<code>admin</code>的用户进行连接。</li>\n<li>利用主机参数简写，例如<code>Connection(&#39;admin@myhost&#39;)</code></li>\n<li>显示指定连接参数: <code>Connection(&#39;myhost&#39;, user=&#39;admin&#39;)</code></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__init__(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)</span><br></pre></td></tr></table></figure>\n<p>创建服务器连接对象。</p>\n<h4 id=\"构建函数参数说明\"><a href=\"#构建函数参数说明\" class=\"headerlink\" title=\"构建函数参数说明\"></a>构建函数参数说明</h4><ul>\n<li><p><strong><code>host(str)</code></strong><br>连接服务器的主机名或者IP地址，也可以是主机IP地址，端口号，用户名组合的简写形式：<br><code>user@host</code>, <code>host:port</code>, 或<code>user@host:port</code></p>\n<blockquote>\n<p>注意</p>\n<p>如果<code>host</code>与SSH Config配置文件中<code>Host</code>项相匹配，并且<code>Host</code>项包含<code>Hostname</code>属性，则<code>Connection</code>对象认为host与Hostname值相等。</p>\n<p>在所有情况下，主机的原始值都会保留为原始主机属性。<br>s<br>给定SSH config文件内容如下：</p>\n<pre><code>Host myalias\n    Hostname realhostname\n</code></pre><p>使用 <code>Connection(host=&#39;myalias&#39;)</code>调用，将返回一个对象：<code>host</code>值为<code>realhostname</code>，<code>original_host</code>值为<code>myalias</code></p>\n</blockquote>\n</li>\n<li><p><strong><code>user(str)</code></strong><br>远程服务器登录用户名，默认值为<code>config.user</code></p>\n</li>\n<li><strong><code>port(int)</code></strong><br>远程服务器的ssh端口号，默认值为<code>config.port</code></li>\n<li><p><strong><code>config(object)</code></strong><br>配置对象，该对象类型为<code>Config</code>或<code>invoke.config.Config</code>(类型转换为<code>Config</code>)</p>\n</li>\n<li><p><strong><code>gateway(object)</code></strong><br>用作此连接的代理或网关的对象。<br>该参数可接受值：</p>\n<ul>\n<li>另一个<code>Connection</code>对象(<code>ProxyJump</code>类型网关)</li>\n<li>shell命令字符串（<code>ProxyCommand</code>类型网关）<br>默认值为：<code>None</code>，</li>\n</ul>\n</li>\n<li><p><strong><code>forward_agent(boolean)</code></strong><br>是否开启SSH代理转发，默认值为:<code>config.forward_agent</code></p>\n</li>\n<li><p><strong><code>connect_timeout(int)</code></strong><br>连接超时时间（秒）</p>\n</li>\n</ul>\n<h4 id=\"类属性\"><a href=\"#类属性\" class=\"headerlink\" title=\"类属性\"></a>类属性</h4><ul>\n<li><p><strong><code>connect_kwargs(dict)</code></strong></p>\n<p> <code>connect_kwargs</code>中的键值对将会被<code>SSHClient.connect</code>逐个解析。例如：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c = Connection(</span><br><span class=\"line\">    host=&quot;hostname&quot;,</span><br><span class=\"line\">    user=&quot;admin&quot;,</span><br><span class=\"line\">    connect_kwargs=&#123;</span><br><span class=\"line\">        &quot;key_filename&quot;: &quot;/home/myuser/.ssh/private.key&quot;,config.connect_kwargs</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><strong>默认值：<code>config.connect_kwargs.</code></strong></p>\n</li>\n<li><p><strong><code>inline_ssh_env(boolean)</code></strong></p>\n<p>是否将“内置”环境变量作为前缀发送到命令字符串前面（<code>export VARNAME=value &amp;&amp; mycommand here</code>），而不是通过<code>SSH</code> 协议提交该命令。如果远程服务器具有受限的<code>acceptenv</code>设置，则需要执行此操作。</p>\n<p><strong>默认值：<code>False</code></strong></p>\n</li>\n</ul>\n<h4 id=\"Raise\"><a href=\"#Raise\" class=\"headerlink\" title=\"Raise\"></a>Raise</h4><h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li><p><code>close()</code>:</p>\n<p>关闭与远程服务器的SSH连接，如果连接已完毕，则该方法什么也不做。</p>\n</li>\n<li><p><code>forward_local()</code>:</p>\n<p>打开一个通道（tunnel）建立<code>local_port</code>到服务器环境的连接。</p>\n<p>例如，假设您想连接到一个远程 PostgreSQL 数据库，该数据库被锁定，只能通过运行它的操作系统访问。您可以通过ssh访问此服务器，因此可以临时使本地系统上的端口5432与服务器上的端口5432类似：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import psycopg2</span><br><span class=\"line\">from fabric import Connection</span><br><span class=\"line\"></span><br><span class=\"line\">with Connection(&apos;my-db-server&apos;).forward_local(5432):</span><br><span class=\"line\">  db = psycopg2.connect(</span><br><span class=\"line\">      # 通过本地端口5432区连接数据库，通过本地端口5432的数据会转发到</span><br><span class=\"line\">      # `my-db-server`服务器，然后在`my-db-server`服务器上真正的通过</span><br><span class=\"line\">      # 端口号5432去连接数据库</span><br><span class=\"line\">      host=&apos;localhost&apos;, port=5432, database=&apos;mydb&apos;</span><br><span class=\"line\">      # 我们为什么用 localhost 而不是 IP 地址或者主机名呢？其实这个取决于我</span><br><span class=\"line\">      # 们之前是如何限制 PostgreSQL 只有本机才能访问。如果只允许 lookback 接口访问</span><br><span class=\"line\">      # 的话，那么自然就只有 localhost 或者 IP 为 127.0.0.1 才能访问了，而# 不能用真实 IP 或者主机名。</span><br><span class=\"line\">  )</span><br><span class=\"line\">  # Do things with &apos;db&apos; here</span><br></pre></td></tr></table></figure>\n<p>该方法类似于OpenSSH命令中的<code>ssh -L</code></p>\n<ul>\n<li><p>参数：</p>\n<p><code>local_port (int)</code>:</p>\n<p>本地监听端口号</p>\n<p><code>remote_port (int)</code>:</p>\n<p>远程服务器端口号，默认同<code>local_port</code></p>\n<p><code>local_host (str)</code>:</p>\n<p>要侦听的本地主机名/接口。默认值：localhost</p>\n<p><code>remote_host (str)</code>:</p>\n<p>为转发的远程端口提供服务的远程主机名。默认值：localhost（即<code>Connection</code>所连接的主机）</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>返回值：无</p>\n<p>此方法仅用作影响本地操作系统状态的上下文管理器。</p>\n</li>\n</ul>\n<ul>\n<li><p><code>forward_remote()</code>: </p>\n<p>该方法对应SSH的 forward remote，<code>$ ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;</code></p>\n<ul>\n<li><p>参数</p>\n<ul>\n<li><p><code>remote_port（int）</code> - 要监听的远程端口号。</p>\n</li>\n<li><p><code>local_port（int）</code>- 本地端口号。默认值与<code>remote_port</code>相同。</p>\n</li>\n<li><p><code>local_host （str）</code>–转发连接所使用的本地主机名/接口。默认值：localhost。</p>\n</li>\n<li><p><code>remote_host （str）</code>–转发连接时要监听的远程接口地址。默认值：127.0.0.1（即仅侦听<code>localhost</code>）。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><em>classmethod</em> <code>from_v1(env, **kwargs)</code>:</p>\n<p>使用Fabric 1版本的 <code>env</code>参数值。</p>\n<p><code>env</code>: Fabric 1版本的 <code>env</code>变量</p>\n<p><code>kwargs</code>: 除了env之外，所有的关键字参数都是直接传递到主构造函数中。</p>\n<blockquote>\n<p>注意</p>\n<p><code>kwargs</code>中的参数会覆盖<code>env</code>相同的参数值。</p>\n</blockquote>\n</li>\n<li><p><code>get(*args, **kwargs)</code>:</p>\n<p>将远程文件下载到本地文件系统或<code>file-like</code>对象</p>\n</li>\n<li><p><code>is_connected()</code>：</p>\n<p>连接是否open</p>\n</li>\n<li><p><code>local(*args, **kwargs)</code>:</p>\n<p>在本地机器上执行shell命令</p>\n</li>\n<li><p><code>open()</code>:</p>\n<p>启动与此对象绑定到的主机/端口的ssh连接。</p>\n</li>\n</ul>\n<ul>\n<li><p><code>open_gateway()</code>:</p>\n<p>从gateway中获取<code>socket-like</code>对象。</p>\n<p>返回值：</p>\n<p>如果<code>gateway</code>是一个<code>Connection</code>，则返回<code>paramiko.channel.Channel</code>；如果<code>gateway</code>是一个字符串，则返回<a href=\"http://docs.paramiko.org/en/latest/api/proxy.html#paramiko.proxy.ProxyCommand\" target=\"_blank\" rel=\"noopener\"><code>ProxyCommand</code></a>对象</p>\n</li>\n<li><p><code>put(*args, **kwargs)</code>:</p>\n<p>上传文件或者<code>file-like</code>对象到远程服务器</p>\n</li>\n<li><p><code>run(command, **kwargs)</code>:</p>\n<p>在远程服务器上执行shell命令，该方法是对<a href=\"http://docs.pyinvoke.org/en/latest/api/runners.html#invoke.runners.Runner.run\" target=\"_blank\" rel=\"noopener\"><code>invoke.runners.Runner.run</code></a>的封装，具体实现可参考<code>invoke.runners.Runner.run</code>的API文档</p>\n</li>\n</ul>\n<ul>\n<li><p><code>sftp()</code>:</p>\n<p>返回一个<code>SFTPClient</code>对象</p>\n<p>如果多次调用，则会记住第一个结果；因此，任何给定的<code>Connection</code>实例都将只具有一个<code>sftp client</code>，并且状态（如chdir管理的状态）将被保留。</p>\n</li>\n<li><p><code>sudo(command, **kwargs)</code>:</p>\n<p>在远程服务器上执行sudo命令</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Network\"><a href=\"#Network\" class=\"headerlink\" title=\"Network\"></a>Network</h2><h3 id=\"SSH连接网关\"><a href=\"#SSH连接网关\" class=\"headerlink\" title=\"SSH连接网关\"></a>SSH连接网关</h3><h4 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h4><p>出于安全考虑，服务器经常会加一道防火墙，从而阻止从互联网直接访问服务器。如果需要连接防火墙内部的网络，通常是通过中间主机（被称为“跳转机”、“堡垒机”、“网关或代理”、“弹跳”）</p>\n<p>网关需要与网关系统建立初始/外部SSH连接，然后使用该连接作为到最终/内部主机的“真实”连接的传输。</p>\n<p>则可以通过 <code>ssh gatewayhost</code>去真正连接 <code>ssh internalhost</code>，这适用于长时间运行的会话。但在频繁进行时，会成为负担。</p>\n<p>Fabric中有两种网关解决方案，可以反映OpenSSH客户端的功能：<code>ProxyJump</code>（更容易，更少开销，可以嵌套）; <code>ProxyCommand</code> （更多开销，不能嵌套，有时更灵活）。两者都支持通常的配置源：Fabric自己的配置框架，SSH配置文件或运行时参数</p>\n<h5 id=\"ProxyJump\"><a href=\"#ProxyJump\" class=\"headerlink\" title=\"ProxyJump\"></a><code>ProxyJump</code></h5><p>这种类型的网关使用SSH协议的direct-tcpip通道类型 - 一种轻量级方法，用于请求网关的sshd开启一个到远程服务器的连接。</p>\n<p><code>paramiko.channel.Channel</code> 实例实现了Python的 <code>socket</code> API，因此可用于代替几乎任何Python代码的实际操作系统套接字。</p>\n<p><code>ProxyJump</code>类型的网关，使用简单：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from fabric import Connection</span><br><span class=\"line\"></span><br><span class=\"line\">c = Connection(&apos;internalhost&apos;, gateway=Connection(&apos;gatewayhost&apos;))</span><br></pre></td></tr></table></figure>\n<p>该 <code>gateway</code> 连接(<code>Connection(&#39;gatewayhost&#39;)</code>)，需要配置 gatewayhost的登录用户名，端口号等等。</p>\n<h5 id=\"ProxyCommand\"><a href=\"#ProxyCommand\" class=\"headerlink\" title=\"ProxyCommand\"></a><code>ProxyCommand</code></h5><p>传统的OpenSSH命令行客户端长期提供了一个<code>ProxyCommand</code>指令（请参阅<a href=\"http://man.openbsd.org/ssh_config\" target=\"_blank\" rel=\"noopener\">man ssh_config</a>），该指令通过任意本地子进程管理内部连接的输入和输出。</p>\n<p>与 <code>ProxyJump</code>类型的网关相比，这种方式增加了开销（额外的子进程），并且无法轻松嵌套。在数据传输中，它允许使用<code>SOCKS</code>代理或者自定义过滤等高级功能，相对来说更加灵活。</p>\n<p><code>ProxyCommand</code>子进程通常是另一个ssh命令，例如<code>ssh -W ％h：％p gatewayhost</code>;或者（在缺少<code>-W</code>选项的SSH版本上）广泛使用的<code>netcat</code>，通过<code>ssh gatewayhost nc ％h％p</code>。</p>\n<p>Fabric支持ProxyCommand接受gatewaykwarg中的命令字符串对象 Connection; 这用于paramiko.proxy.ProxyCommand在连接时填充 对象。</p>\n<h4 id=\"其他问题\"><a href=\"#其他问题\" class=\"headerlink\" title=\"其他问题\"></a>其他问题</h4><p>如果您不确定使用哪两种方法：使用<code>ProxyJump</code>方式。它性能更好，在本地系统上使用更少的资源，并且具有更易于使用的API。</p>\n<blockquote>\n<p><strong>警告</strong></p>\n<p>同时请求两种类型的网关到相同的主机（即，以<code>Connection</code>作为<code>gateway</code>的<code>kwarg</code>或<code>config</code>参数，并且加载包含配置文件<code>ProxyCommand</code>）将导致异常。</p>\n</blockquote>\n<hr>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>Fabric配置系统，主要依赖于Invoke功能（<code>invoke.config.Config</code>），严格来说是<code>invoke.config.Config</code>的子类 <code>fabric.config.Config</code>。</p>\n<p>俩类的主要区别：</p>\n<ul>\n<li>配置文件命名全部以fabric.*，而不是原来的invoke.*，  比如：<code>/etc/fabric.yml</code> 取代 <code>/etc/invoke.yml</code>, <code>~/.fabric.py</code> 取代 <code>~/.invoke.py</code></li>\n<li>Fabric在<code>invoke.config.Config</code>基础上，新增了其他的配置属性，比如：SSH默认连接端口为22</li>\n<li>Fabric有加载SSH配置文件的特殊机制。并将根据每个<code>Connection</code>，自动创建或更新配置子树。并使用该特定主机的加载ssh配置。</li>\n<li>Fabric提供一个Framework或者进行管理per-host或者per-host-connection配置。<ul>\n<li>该功能，将会补充所述的ssh配置加载的功能。我们预计大多数用户倾向于通过SSH配置文件来进行配置。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"配置默认值\"><a href=\"#配置默认值\" class=\"headerlink\" title=\"配置默认值\"></a>配置默认值</h3><h4 id=\"重写Invoke-level\"><a href=\"#重写Invoke-level\" class=\"headerlink\" title=\"重写Invoke-level\"></a>重写Invoke-level</h4><ul>\n<li><p><code>run.replace_env: True</code>，在远程服务器执行的shell命令，将不会继承当前线程的环境变量。</p>\n<p>处于安全考虑：默认情况下远程泄漏本地环境数据是不推荐的。</p>\n</li>\n</ul>\n<h4 id=\"扩展Invoke-level\"><a href=\"#扩展Invoke-level\" class=\"headerlink\" title=\"扩展Invoke-level\"></a>扩展Invoke-level</h4><p><code>runners.remote</code>:在Invoke中，<code>runner</code>拥有单独键：<code>local</code>(mapping to <code>Local</code>)，Fabric添加新的键<code>remote</code>（mapping to <code>Remote</code>）</p>\n<h4 id=\"Fabric自定义默认值\"><a href=\"#Fabric自定义默认值\" class=\"headerlink\" title=\"Fabric自定义默认值\"></a>Fabric自定义默认值</h4><blockquote>\n<p><strong>注意</strong></p>\n<p>大部分所有的设置（settings）也适用于<code>Connection</code></p>\n</blockquote>\n<blockquote>\n<p><strong>警告</strong><br>大部分的设置也可以通过ssh_config_files进行配置，这些值优先于通过核心配置进行配置的值，</p>\n</blockquote>\n<ul>\n<li><p><code>connect_kwargs</code>:</p>\n<p>关键字参数，这是许多与ssh相关的选项的主要配置向量，例如选择私钥、切换ssh代理的转发等。默认值：<code>{}</code>。</p>\n</li>\n<li><p><code>forward_agent</code>:</p>\n<p>是否尝试将本地ssh身份验证代理转发到远程端。默认： <code>False</code></p>\n</li>\n<li><p><code>gateway</code>:</p>\n<p>用作 <code>Connection</code> 对象的 <code>gateway</code> 属性的默认值，默认：<code>None</code></p>\n</li>\n<li><p><code>load_ssh_configs</code>:</p>\n<p>是否自动搜索SSH配置文件，当值为<code>False</code>，不自动加载配置文件。默认：<code>True</code></p>\n</li>\n<li><p><code>port</code>:</p>\n<p>TCP端口号，用于<code>Connection</code>对象的连接，默认:22</p>\n</li>\n<li><p><code>inline_ssh_env</code>:</p>\n<p>Boolean用作<code>Connection</code>的<code>inline-ssh-env</code>参数值的全局默认值；有关详细信息，请参阅其文档。默认值：false。</p>\n</li>\n<li><p><code>ssh_config_path</code>:</p>\n<p>运行时（Runtime）SSH配置路径，默认：None</p>\n</li>\n<li><p><code>timeouts</code>:</p>\n<ul>\n<li><code>connection</code>：连接超时，以秒为单位；默认：<code>None</code>，表示永远没有<code>timeout/block</code>。</li>\n</ul>\n</li>\n<li><p><code>user</code>:</p>\n<p>指定通过ssh连接的用户名，默认值使用本地主机的用户名</p>\n</li>\n</ul>\n<h3 id=\"加载并使用ssh-config文件\"><a href=\"#加载并使用ssh-config文件\" class=\"headerlink\" title=\"加载并使用ssh_config文件\"></a>加载并使用ssh_config文件</h3><h4 id=\"加载哪些文件\"><a href=\"#加载哪些文件\" class=\"headerlink\" title=\"加载哪些文件\"></a>加载哪些文件</h4><p><strong>Fabric</strong> 使用 <strong>Paramiko</strong> 的<code>SSH config</code>文件，加载并解析 <code>ssh_config</code>格式的文件</p>\n<ul>\n<li>已经被解析的 <code>SSHConfig</code> 对象，将会通过 <code>ssh_config</code> 关键字参数传给 <code>Config.__init__</code>。如果给定该值，则不再加载其他任何配置文件。</li>\n<li><p>运行时文件路径，通过<code>configuration</code>中的<code>ssh_config_path</code>进行设置，该路径将被<code>SSHConfig</code>对象加载。</p>\n<ul>\n<li>同 <code>fab</code> CLI 命令中的 <code>--ssh-config</code></li>\n</ul>\n</li>\n<li><p>如果 <code>Config.__init__</code> 没有运行时配置（包括对象或者路径），其会自动按顺序去搜索并加载 <code>~/.ssh/config and/</code>或 <code>/etc/ssh/ssh_config</code></p>\n</li>\n<li><p>如果上述都没有产生SSH配置数据，则空 <code>SSHConfig</code> 是最终结果</p>\n</li>\n<li><p>无论对象是如何生成的，它都以 <code>Config.base_ssh_config</code> 形式公开。</p>\n</li>\n</ul>\n<h5 id=\"Connection使用ssh-config文件\"><a href=\"#Connection使用ssh-config文件\" class=\"headerlink\" title=\"Connection使用ssh_config文件\"></a>Connection使用ssh_config文件</h5><p><code>Connection</code>对象将其配置的SSH数据（通过 <code>lookup</code> 获得）的每个主机“views”公开为<code>Connection.ssh_config</code>。 <code>Connection</code> 本身引用这些值，如以下小节所述，通常作为相应配置键或参数的简单默认值(例如：<code>port</code>, <code>forward_agent</code>)</p>\n<p>除非另有说明，否则这些值会覆盖相同键的常规配置值，但可能会被 <code>Connection.__ init__</code> 参数覆盖。</p>\n<p>比如：<code>~/.fabric.yaml</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">user: foo</span><br></pre></td></tr></table></figure>\n<p>如果没有任何其他配置，<code>Connection（&#39;myhost&#39;）</code>将作为 <code>foo</code> 用户连接。</p>\n<p>如果我们还有其他配置：<code>~/.ssh/config</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host *</span><br><span class=\"line\">    User bar</span><br></pre></td></tr></table></figure>\n<p><code>Connection（&#39;myhost&#39;）</code>将作为 <code>bar</code> 用户连接。</p>\n<p>可见，<code>SSH config</code> 优先于<code>Fabric config</code></p>\n<p>然而，<code>Connection（&#39;myhost&#39;, user=&#39;biz&#39;）</code>，将用<code>biz</code>用户进行连接。</p>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>以下部分使用<code>ssh_config</code>键的大写版本以便更轻松地与<code>man ssh_config</code>进行关联，但实际的<code>SSHConfig</code>数据结构规范化为小写键，因为SSH配置文件在技术上不区分大小写。</p>\n</blockquote>\n<h5 id=\"Connection参数\"><a href=\"#Connection参数\" class=\"headerlink\" title=\"Connection参数\"></a>Connection参数</h5><ul>\n<li><code>Hostname</code> ：替换 <code>host</code> 的原始值（保留为<code>.original_host</code>。）</li>\n<li><code>Port</code>：提供 <code>port</code>  config 选项/参数的默认值。</li>\n<li><code>User</code>：提供 <code>user</code> config 选项/参数的默认值。</li>\n<li><code>ConnectTimeout</code> ：设置<code>timeouts.connect</code> config 选项/超时参数的默认值。</li>\n</ul>\n<h5 id=\"代理-Proxying\"><a href=\"#代理-Proxying\" class=\"headerlink\" title=\"代理(Proxying)\"></a>代理(Proxying)</h5><ul>\n<li><code>ProxyCommand</code> : 为<code>gateway</code>提供默认字符串值</li>\n<li><code>ProxyJump</code> : 为<code>gateway</code>提供默认<code>Connection</code>对象<ul>\n<li>嵌套式<code>ProxyJump</code>，即<a href=\"mailto:`user1@hop1.host\" target=\"_blank\" rel=\"noopener\">`user1@hop1.host</a>，<a href=\"mailto:user2@hop2.host\" target=\"_blank\" rel=\"noopener\">user2@hop2.host</a>，…<code>，将导致一系列适当的嵌套</code>gateway<code>值 - 就好像用户手动指定了</code>Connecton(…，gateway) = Connection(<a href=\"mailto:&#39;user1@hop1.host\" target=\"_blank\" rel=\"noopener\">&#39;user1@hop1.host</a>‘，gateway = Connection(<a href=\"mailto:&#39;user2@hop2.host\" target=\"_blank\" rel=\"noopener\">&#39;user2@hop2.host</a>‘，gateway = …)))`。</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>如果为给定主机指定了两者，则<code>ProxyJump</code>将覆盖<code>ProxyCommand</code>。这与OpenSSH略有不同，OpenSSH指令的加载顺序决定了哪一个获胜。我们这样做（将配置视为字典结构）需要额外的工作。</p>\n</blockquote>\n<h5 id=\"认证（Authentication）\"><a href=\"#认证（Authentication）\" class=\"headerlink\" title=\"认证（Authentication）\"></a>认证（Authentication）</h5><ul>\n<li><code>ForwardAgent</code>: 控制<code>forward_agent</code>参数行为</li>\n<li><code>IdentityFile</code>: 追加 <code>connect_kwargs</code>字段 <code>key_filename</code>，类似于 <code>--identity</code></li>\n</ul>\n<h4 id=\"禁用ssh-config加载\"><a href=\"#禁用ssh-config加载\" class=\"headerlink\" title=\"禁用ssh_config加载\"></a>禁用<code>ssh_config</code>加载</h4><p>需要更严格控制其环境配置方式的用户可能希望禁用系统/用户级SSH配置文件的自动加载；这可以防止难以预料的错误，例如新用户的 <code>~/.ssh/config</code> 覆盖在常规配置层次结构中设置的值。</p>\n<p>为此，只需将顶级配置选项 <code>load_ssh_configs</code> 设置为<code>False</code>即可。</p>\n<blockquote>\n<p><strong>注意</strong><br>更改此设置不会禁用运行时级别（<code>runtime-level</code>）配置文件的加载，如果用户明确指定加载哪个文件，我们则认为他们知道他们要干什么。</p>\n</blockquote>\n<hr>\n<h2 id=\"connection\"><a href=\"#connection\" class=\"headerlink\" title=\"connection\"></a>connection</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class fabric.connection.Connection(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)¶</span><br></pre></td></tr></table></figure>\n<p>用于与ssh守护进程的连接，包含shell命令和文件传输。</p>\n<h3 id=\"基础-1\"><a href=\"#基础-1\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>该类继承自<code>Invoke.context</code>，在该<code>context</code>中，可以进行命令、任务（task）操作。该类封装了Paramiko <code>SSHClient</code>实例，通过该类生成的<code>sshclient</code>和<code>channel</code>实例执行的高级操作。</p>\n<blockquote>\n<p><strong>注意</strong></p>\n<p>特定于SSH的选项——例如指定密钥（private key）和密码口令（passphrases）、timeouts、禁用SSH代理等，可通过构造函数的<code>connect_kwargs</code>参数指定，由paramiko直接处理。</p>\n<pre><code>c = connection(host=&apos;localhost&apos;,user=&apos;root&apos;, connect_kwargs={&apos;passwrd&apos;:&apos;123456&apos;}\n</code></pre></blockquote>\n<h3 id=\"生命周期\"><a href=\"#生命周期\" class=\"headerlink\" title=\"生命周期\"></a>生命周期</h3><p><code>Connection</code>有<code>create, connect/open, do work, disconnect/close</code>生命周期。</p>\n<ul>\n<li><code>Instantiation</code>持久影响对象连接参数。但并不真正建立连接。<ul>\n<li>可选的构造方式：<a href=\"http://www.fabfile.org/upgrading.html#from-v1\" target=\"_blank\" rel=\"noopener\">upgrading piecemeal from Fabric 1</a> <code>from_v1(env)</code></li>\n</ul>\n</li>\n<li><code>run</code>、<code>get</code> 等方法会自动触发<code>connection</code>的<code>open</code>，用户也可手动执行<code>open</code></li>\n<li><p><code>Connection</code>无需手动关闭。大部分情况下连接的关闭操作交给Paramiko的<strong>垃圾回收钩子</strong>或者python自带的关闭序列。当然也有特殊情况（当退出时，session挂起），此时需要手动进行关闭(close)。</p>\n<p>这可以通过手动调用<code>Close</code>或借助<code>with</code>用作ContextManager来完成：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">with Connection(&apos;host&apos;) as c:</span><br><span class=\"line\">  c.run(&apos;command&apos;)</span><br><span class=\"line\">  c.put(&apos;file&apos;)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>Note</p>\n<p>该类将<code>invoke.context.Context.run</code>方法重新绑定到<code>local</code>方法，远程命令和本地命令均可执行。</p>\n</blockquote>\n<h3 id=\"Configuration-1\"><a href=\"#Configuration-1\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h3><p>大部分的<code>Connection</code>参数，遵循<a href=\"http://docs.fabfile.org/en/2.4/concepts/configuration.html\" target=\"_blank\" rel=\"noopener\"><code>Invoke-style configuration</code></a>和<a href=\"http://docs.fabfile.org/en/2.4/concepts/configuration.html#connection-ssh-config\" target=\"_blank\" rel=\"noopener\"><code>SSH Config</code></a>。例如连接到远程机器<code>admin@myhost</code>，可以使用下述方法进行连接：</p>\n<ul>\n<li>使用<code>build-in</code>配置机制，比如<code>/etc/fabric.yml, ~/.fabric.json</code>，<code>user: admin</code> ( 或<code>{&quot;user&quot;: &quot;admin&quot;}</code>)。这样，<code>Connection(&#39;myhost&#39;)</code>就可以通过用户为<code>admin</code>进行连接。</li>\n<li>在任何适用的<code>Host</code>开头（<code>Host myhost</code>、<code>Host *</code>等）中隐式使用包含<code>User admin</code>的SSH Config配置文件。<code>Connection(&#39;myhost&#39;)</code> 将默认使用用户名为<code>admin</code>的用户进行连接。</li>\n<li>利用主机参数简写，例如<code>Connection(&#39;admin@myhost&#39;)</code></li>\n<li>显示指定连接参数: <code>Connection(&#39;myhost&#39;, user=&#39;admin&#39;)</code></li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">__init__(host, user=None, port=None, config=None, gateway=None, forward_agent=None, connect_timeout=None, connect_kwargs=None, inline_ssh_env=None)</span><br></pre></td></tr></table></figure>\n<p>创建服务器连接对象。</p>\n<h4 id=\"构建函数参数说明\"><a href=\"#构建函数参数说明\" class=\"headerlink\" title=\"构建函数参数说明\"></a>构建函数参数说明</h4><ul>\n<li><p><strong><code>host(str)</code></strong><br>连接服务器的主机名或者IP地址，也可以是主机IP地址，端口号，用户名组合的简写形式：<br><code>user@host</code>, <code>host:port</code>, 或<code>user@host:port</code></p>\n<blockquote>\n<p>注意</p>\n<p>如果<code>host</code>与SSH Config配置文件中<code>Host</code>项相匹配，并且<code>Host</code>项包含<code>Hostname</code>属性，则<code>Connection</code>对象认为host与Hostname值相等。</p>\n<p>在所有情况下，主机的原始值都会保留为原始主机属性。<br>s<br>给定SSH config文件内容如下：</p>\n<pre><code>Host myalias\n    Hostname realhostname\n</code></pre><p>使用 <code>Connection(host=&#39;myalias&#39;)</code>调用，将返回一个对象：<code>host</code>值为<code>realhostname</code>，<code>original_host</code>值为<code>myalias</code></p>\n</blockquote>\n</li>\n<li><p><strong><code>user(str)</code></strong><br>远程服务器登录用户名，默认值为<code>config.user</code></p>\n</li>\n<li><strong><code>port(int)</code></strong><br>远程服务器的ssh端口号，默认值为<code>config.port</code></li>\n<li><p><strong><code>config(object)</code></strong><br>配置对象，该对象类型为<code>Config</code>或<code>invoke.config.Config</code>(类型转换为<code>Config</code>)</p>\n</li>\n<li><p><strong><code>gateway(object)</code></strong><br>用作此连接的代理或网关的对象。<br>该参数可接受值：</p>\n<ul>\n<li>另一个<code>Connection</code>对象(<code>ProxyJump</code>类型网关)</li>\n<li>shell命令字符串（<code>ProxyCommand</code>类型网关）<br>默认值为：<code>None</code>，</li>\n</ul>\n</li>\n<li><p><strong><code>forward_agent(boolean)</code></strong><br>是否开启SSH代理转发，默认值为:<code>config.forward_agent</code></p>\n</li>\n<li><p><strong><code>connect_timeout(int)</code></strong><br>连接超时时间（秒）</p>\n</li>\n</ul>\n<h4 id=\"类属性\"><a href=\"#类属性\" class=\"headerlink\" title=\"类属性\"></a>类属性</h4><ul>\n<li><p><strong><code>connect_kwargs(dict)</code></strong></p>\n<p> <code>connect_kwargs</code>中的键值对将会被<code>SSHClient.connect</code>逐个解析。例如：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">c = Connection(</span><br><span class=\"line\">    host=&quot;hostname&quot;,</span><br><span class=\"line\">    user=&quot;admin&quot;,</span><br><span class=\"line\">    connect_kwargs=&#123;</span><br><span class=\"line\">        &quot;key_filename&quot;: &quot;/home/myuser/.ssh/private.key&quot;,config.connect_kwargs</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p><strong>默认值：<code>config.connect_kwargs.</code></strong></p>\n</li>\n<li><p><strong><code>inline_ssh_env(boolean)</code></strong></p>\n<p>是否将“内置”环境变量作为前缀发送到命令字符串前面（<code>export VARNAME=value &amp;&amp; mycommand here</code>），而不是通过<code>SSH</code> 协议提交该命令。如果远程服务器具有受限的<code>acceptenv</code>设置，则需要执行此操作。</p>\n<p><strong>默认值：<code>False</code></strong></p>\n</li>\n</ul>\n<h4 id=\"Raise\"><a href=\"#Raise\" class=\"headerlink\" title=\"Raise\"></a>Raise</h4><h4 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h4><ul>\n<li><p><code>close()</code>:</p>\n<p>关闭与远程服务器的SSH连接，如果连接已完毕，则该方法什么也不做。</p>\n</li>\n<li><p><code>forward_local()</code>:</p>\n<p>打开一个通道（tunnel）建立<code>local_port</code>到服务器环境的连接。</p>\n<p>例如，假设您想连接到一个远程 PostgreSQL 数据库，该数据库被锁定，只能通过运行它的操作系统访问。您可以通过ssh访问此服务器，因此可以临时使本地系统上的端口5432与服务器上的端口5432类似：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import psycopg2</span><br><span class=\"line\">from fabric import Connection</span><br><span class=\"line\"></span><br><span class=\"line\">with Connection(&apos;my-db-server&apos;).forward_local(5432):</span><br><span class=\"line\">  db = psycopg2.connect(</span><br><span class=\"line\">      # 通过本地端口5432区连接数据库，通过本地端口5432的数据会转发到</span><br><span class=\"line\">      # `my-db-server`服务器，然后在`my-db-server`服务器上真正的通过</span><br><span class=\"line\">      # 端口号5432去连接数据库</span><br><span class=\"line\">      host=&apos;localhost&apos;, port=5432, database=&apos;mydb&apos;</span><br><span class=\"line\">      # 我们为什么用 localhost 而不是 IP 地址或者主机名呢？其实这个取决于我</span><br><span class=\"line\">      # 们之前是如何限制 PostgreSQL 只有本机才能访问。如果只允许 lookback 接口访问</span><br><span class=\"line\">      # 的话，那么自然就只有 localhost 或者 IP 为 127.0.0.1 才能访问了，而# 不能用真实 IP 或者主机名。</span><br><span class=\"line\">  )</span><br><span class=\"line\">  # Do things with &apos;db&apos; here</span><br></pre></td></tr></table></figure>\n<p>该方法类似于OpenSSH命令中的<code>ssh -L</code></p>\n<ul>\n<li><p>参数：</p>\n<p><code>local_port (int)</code>:</p>\n<p>本地监听端口号</p>\n<p><code>remote_port (int)</code>:</p>\n<p>远程服务器端口号，默认同<code>local_port</code></p>\n<p><code>local_host (str)</code>:</p>\n<p>要侦听的本地主机名/接口。默认值：localhost</p>\n<p><code>remote_host (str)</code>:</p>\n<p>为转发的远程端口提供服务的远程主机名。默认值：localhost（即<code>Connection</code>所连接的主机）</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>返回值：无</p>\n<p>此方法仅用作影响本地操作系统状态的上下文管理器。</p>\n</li>\n</ul>\n<ul>\n<li><p><code>forward_remote()</code>: </p>\n<p>该方法对应SSH的 forward remote，<code>$ ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;</code></p>\n<ul>\n<li><p>参数</p>\n<ul>\n<li><p><code>remote_port（int）</code> - 要监听的远程端口号。</p>\n</li>\n<li><p><code>local_port（int）</code>- 本地端口号。默认值与<code>remote_port</code>相同。</p>\n</li>\n<li><p><code>local_host （str）</code>–转发连接所使用的本地主机名/接口。默认值：localhost。</p>\n</li>\n<li><p><code>remote_host （str）</code>–转发连接时要监听的远程接口地址。默认值：127.0.0.1（即仅侦听<code>localhost</code>）。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p><em>classmethod</em> <code>from_v1(env, **kwargs)</code>:</p>\n<p>使用Fabric 1版本的 <code>env</code>参数值。</p>\n<p><code>env</code>: Fabric 1版本的 <code>env</code>变量</p>\n<p><code>kwargs</code>: 除了env之外，所有的关键字参数都是直接传递到主构造函数中。</p>\n<blockquote>\n<p>注意</p>\n<p><code>kwargs</code>中的参数会覆盖<code>env</code>相同的参数值。</p>\n</blockquote>\n</li>\n<li><p><code>get(*args, **kwargs)</code>:</p>\n<p>将远程文件下载到本地文件系统或<code>file-like</code>对象</p>\n</li>\n<li><p><code>is_connected()</code>：</p>\n<p>连接是否open</p>\n</li>\n<li><p><code>local(*args, **kwargs)</code>:</p>\n<p>在本地机器上执行shell命令</p>\n</li>\n<li><p><code>open()</code>:</p>\n<p>启动与此对象绑定到的主机/端口的ssh连接。</p>\n</li>\n</ul>\n<ul>\n<li><p><code>open_gateway()</code>:</p>\n<p>从gateway中获取<code>socket-like</code>对象。</p>\n<p>返回值：</p>\n<p>如果<code>gateway</code>是一个<code>Connection</code>，则返回<code>paramiko.channel.Channel</code>；如果<code>gateway</code>是一个字符串，则返回<a href=\"http://docs.paramiko.org/en/latest/api/proxy.html#paramiko.proxy.ProxyCommand\" target=\"_blank\" rel=\"noopener\"><code>ProxyCommand</code></a>对象</p>\n</li>\n<li><p><code>put(*args, **kwargs)</code>:</p>\n<p>上传文件或者<code>file-like</code>对象到远程服务器</p>\n</li>\n<li><p><code>run(command, **kwargs)</code>:</p>\n<p>在远程服务器上执行shell命令，该方法是对<a href=\"http://docs.pyinvoke.org/en/latest/api/runners.html#invoke.runners.Runner.run\" target=\"_blank\" rel=\"noopener\"><code>invoke.runners.Runner.run</code></a>的封装，具体实现可参考<code>invoke.runners.Runner.run</code>的API文档</p>\n</li>\n</ul>\n<ul>\n<li><p><code>sftp()</code>:</p>\n<p>返回一个<code>SFTPClient</code>对象</p>\n<p>如果多次调用，则会记住第一个结果；因此，任何给定的<code>Connection</code>实例都将只具有一个<code>sftp client</code>，并且状态（如chdir管理的状态）将被保留。</p>\n</li>\n<li><p><code>sudo(command, **kwargs)</code>:</p>\n<p>在远程服务器上执行sudo命令</p>\n</li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/2019-03-21-jenkins-docker-command-not-found/example.png","post":"cjtr09oww0000t2xuprnvqyox","slug":"example.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cjtr09ox70008t2xuo3xokjai","category_id":"cjtr09oxf000et2xukk7xjlri","_id":"cjtr09oxo000ot2xu8jrgi1j3"},{"post_id":"cjtr09oww0000t2xuprnvqyox","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oxp000st2xusajp09lg"},{"post_id":"cjtr09oww0000t2xuprnvqyox","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oxq000vt2xu4wp5sj1t"},{"post_id":"cjtr09ox90009t2xux9wvjdzn","category_id":"cjtr09oxo000pt2xunk3kns0q","_id":"cjtr09oxq000zt2xueghh5t0c"},{"post_id":"cjtr09oxc000ct2xur7oqqc9q","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oxr0013t2xuq5xkeyms"},{"post_id":"cjtr09oxc000ct2xur7oqqc9q","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oxr0015t2xu0fn1xeqc"},{"post_id":"cjtr09ox10002t2xuwgjsqfuj","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oxs0017t2xuq9e9y52j"},{"post_id":"cjtr09ox10002t2xuwgjsqfuj","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oxs001at2xu5de95lm4"},{"post_id":"cjtr09oxe000dt2xufeoz863d","category_id":"cjtr09oxr0012t2xu377psg3v","_id":"cjtr09oxt001dt2xugklkydn2"},{"post_id":"cjtr09oxl000ht2xuulfmcgi5","category_id":"cjtr09oxr0012t2xu377psg3v","_id":"cjtr09oxu001ft2xuahajassn"},{"post_id":"cjtr09oxn000jt2xuu3wyj2st","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oxu001gt2xut3u72suw"},{"post_id":"cjtr09oxn000jt2xuu3wyj2st","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oxu001ht2xutuagvoz9"},{"post_id":"cjtr09oz1001jt2xuk2f5jmn9","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oz6001pt2xurdair6v3"},{"post_id":"cjtr09oz1001jt2xuk2f5jmn9","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oz8001st2xufh6yz5of"},{"post_id":"cjtr09oz2001kt2xuxglvu2zw","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oz9001vt2xubqjj0mh2"},{"post_id":"cjtr09oz2001kt2xuxglvu2zw","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oz9001xt2xuo537khvv"},{"post_id":"cjtr09oz4001mt2xusx6hrns2","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oz9001zt2xu0f2f058f"},{"post_id":"cjtr09oz4001mt2xusx6hrns2","category_id":"cjtr09oxn000kt2xu4s93r4kk","_id":"cjtr09oza0021t2xube3a4zjv"},{"post_id":"cjtr09oz7001rt2xuhl7emx4g","category_id":"cjtr09oxo000pt2xunk3kns0q","_id":"cjtr09oza0023t2xualgo08jq"},{"post_id":"cjtr09oz6001ot2xur8k3628j","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09oza0024t2xuvipx25db"},{"post_id":"cjtr09oz6001ot2xur8k3628j","category_id":"cjtr09oz8001tt2xusvzylf67","_id":"cjtr09ozb0025t2xu0blmhp3k"},{"post_id":"cjtr09p5w0026t2xupiwxnmyd","category_id":"cjtr09ox30004t2xulzb3i6tc","_id":"cjtr09p6g002bt2xu25hdzfru"},{"post_id":"cjtr09p5w0026t2xupiwxnmyd","category_id":"cjtr09p5y0028t2xuebtvvymr","_id":"cjtr09p6g002ct2xuuat65ma4"}],"PostTag":[{"post_id":"cjtr09oxc000ct2xur7oqqc9q","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oxg000gt2xu3kfkg3af"},{"post_id":"cjtr09oww0000t2xuprnvqyox","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oxm000it2xugh71njfe"},{"post_id":"cjtr09oww0000t2xuprnvqyox","tag_id":"cjtr09oxa000bt2xuo9irwt2a","_id":"cjtr09oxo000mt2xul04bj35s"},{"post_id":"cjtr09ox10002t2xuwgjsqfuj","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oxo000nt2xucituilpf"},{"post_id":"cjtr09oxn000jt2xuu3wyj2st","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oxp000rt2xuumf77qfx"},{"post_id":"cjtr09ox50006t2xuzopwjnt9","tag_id":"cjtr09oxo000lt2xu4mhcz4v8","_id":"cjtr09oxq000wt2xu5o1zpjuc"},{"post_id":"cjtr09ox50006t2xuzopwjnt9","tag_id":"cjtr09oxp000qt2xuhe3ynrz4","_id":"cjtr09oxq000xt2xu6crc5r2n"},{"post_id":"cjtr09ox70008t2xuo3xokjai","tag_id":"cjtr09oxp000ut2xudy9fuvj2","_id":"cjtr09oxr0011t2xugjcz8z00"},{"post_id":"cjtr09ox90009t2xux9wvjdzn","tag_id":"cjtr09oxq0010t2xuixq69320","_id":"cjtr09oxr0016t2xuijhgsti6"},{"post_id":"cjtr09oxe000dt2xufeoz863d","tag_id":"cjtr09oxr0014t2xuawryrj6k","_id":"cjtr09oxs001bt2xu1b2kyjeu"},{"post_id":"cjtr09oxl000ht2xuulfmcgi5","tag_id":"cjtr09oxr0014t2xuawryrj6k","_id":"cjtr09oxu001et2xusm6ptzim"},{"post_id":"cjtr09oz1001jt2xuk2f5jmn9","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oz4001lt2xulmb2z0yv"},{"post_id":"cjtr09oz4001mt2xusx6hrns2","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oz7001qt2xul64qkuu9"},{"post_id":"cjtr09oz7001rt2xuhl7emx4g","tag_id":"cjtr09oxq0010t2xuixq69320","_id":"cjtr09oz9001wt2xuydj3jb94"},{"post_id":"cjtr09oz2001kt2xuxglvu2zw","tag_id":"cjtr09ox50005t2xu1rj84fsh","_id":"cjtr09oz9001yt2xujt6q681i"},{"post_id":"cjtr09oz2001kt2xuxglvu2zw","tag_id":"cjtr09oz5001nt2xu7dyjb8l9","_id":"cjtr09oza0020t2xuk62xndkt"},{"post_id":"cjtr09oz6001ot2xur8k3628j","tag_id":"cjtr09oz8001ut2xumrx7k6jg","_id":"cjtr09oza0022t2xuolrwo2fd"},{"post_id":"cjtr09p5w0026t2xupiwxnmyd","tag_id":"cjtr09p5y0027t2xu1iwnuuwl","_id":"cjtr09p6f0029t2xuvfr9ux2a"},{"post_id":"cjtr09p5w0026t2xupiwxnmyd","tag_id":"cjtr09oxo000lt2xu4mhcz4v8","_id":"cjtr09p6g002at2xuqk3rgk8q"}],"Tag":[{"name":"docker","_id":"cjtr09ox50005t2xu1rj84fsh"},{"name":"jenkins","_id":"cjtr09oxa000bt2xuo9irwt2a"},{"name":"Python","_id":"cjtr09oxo000lt2xu4mhcz4v8"},{"name":"thread","_id":"cjtr09oxp000qt2xuhe3ynrz4"},{"name":"算法","_id":"cjtr09oxp000ut2xudy9fuvj2"},{"name":"gRPC","_id":"cjtr09oxq0010t2xuixq69320"},{"name":"Oracle","_id":"cjtr09oxr0014t2xuawryrj6k"},{"name":"storage","_id":"cjtr09oz5001nt2xu7dyjb8l9"},{"name":"kubernetes","_id":"cjtr09oz8001ut2xumrx7k6jg"},{"name":"Fabric","_id":"cjtr09p5y0027t2xu1iwnuuwl"}]}}